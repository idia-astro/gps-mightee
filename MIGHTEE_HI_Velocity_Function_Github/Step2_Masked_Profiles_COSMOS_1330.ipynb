{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIGHTEE-HI Data: HI Profile Extraction Analysis\n",
    "***\n",
    "\n",
    "By <b>Wanga Mulaudzi</b> (based on work by Sambatra Rajohnson, Dr Marcin Glowacki and Dr Bradley Frank)\n",
    "\n",
    "<b>Date:</b> 1 August 2021\n",
    "<br>\n",
    "<b>Affiliation:</b> Department of Astronomy, University of Cape Town, Private Bag X3, Rondebosch 7701, South Africa\n",
    "<br>\n",
    "<b>Contact:</b> MLDWAN001@myuct.ac.za\n",
    "<br>\n",
    "<b>Ilifu Jupyter Kernel:</b> ASTRO-PY3 \n",
    "\n",
    "This notebook:\n",
    "<br>\n",
    "* Applies a primary beam correction to the data cube using python, \n",
    "* Extracts spectra from cubelets in the data cube after having performed source finding to get their locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some necessary import statements\n",
    "import aplpy\n",
    "from astropy.io import ascii\n",
    "from astropy.io import fits\n",
    "from astropy import cosmology\n",
    "from astropy.cosmology import WMAP7\n",
    "from astropy.cosmology import LambdaCDM\n",
    "from astropy import units as u\n",
    "from astropy import constants as const\n",
    "from astropy.coordinates import SkyCoord\n",
    "import heapq\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "import math\n",
    "import os\n",
    "from scipy.optimize import curve_fit\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import spectral_cube\n",
    "from spectral_cube import SpectralCube\n",
    "from spectral_cube.cube_utils import Beam\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One can initiate parameters for plotting\n",
    "# This is up to the user\n",
    "pl.rc('axes',titlesize='large')\n",
    "pl.rc('text', usetex=False)\n",
    "pl.rc('font', **{'family':'serif','size':20})\n",
    "pl.rc('axes', labelsize=16)\n",
    "pl.rc('xtick',labelsize=16)\n",
    "pl.rc('ytick',labelsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Defining directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''For this example, we will use the COSMOS 123 data cubes'''\n",
    "# Directory to where the data cubes are\n",
    "data_dir = '/idia/projects/mightee/mightee-hi/COSMOS/123/'\n",
    "\n",
    "# In this case, the COSMOS data cubes are in a public directiory\n",
    "# Define your own personal directory that you can store your output cubes\n",
    "my_data_dir = ''\n",
    "\n",
    "# Directory to the detections list\n",
    "det_dir = ''\n",
    "\n",
    "# Directory to store results of this notebooks analysis\n",
    "analysis_res = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: StokesWarning: Cube is a Stokes cube, returning spectral cube for I component [spectral_cube.io.core]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VaryingResolutionSpectralCube with shape=(287, 4096, 4096) and unit=Jy / beam:\n",
       " n_x:   4096  type_x: RA---SIN  unit_x: deg    range:   148.979931 deg:  151.258959 deg\n",
       " n_y:   4096  type_y: DEC--SIN  unit_y: deg    range:     1.067545 deg:    3.342695 deg\n",
       " n_s:    287  type_s: FREQ      unit_s: Hz     range: 1330320493.996 Hz:1390096088.856 Hz"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the main cube\n",
    "cube_file = data_dir+'COSMOS123.CORR.1330.ms.contsub.dirty.w128.image.u.piwimed.fits'\n",
    "cube = SpectralCube.read(cube_file)\n",
    "\n",
    "# Store the header in a variable\n",
    "hdulist = fits.open(cube_file)\n",
    "\n",
    "# Get the table of beams\n",
    "beam_table = hdulist[1].data\n",
    "\n",
    "# Display information about the cube\n",
    "cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the information above, we can see the RA and Dec ranges, and that the total bandwidth of the cube is 50 MHz. \n",
    "\n",
    "We now have to read in primary beam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: StokesWarning: Cube is a Stokes cube, returning spectral cube for I component [spectral_cube.io.core]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SpectralCube with shape=(287, 4096, 4096):\n",
       " n_x:   4096  type_x: RA---SIN  unit_x: deg    range:   148.979931 deg:  151.258959 deg\n",
       " n_y:   4096  type_y: DEC--SIN  unit_y: deg    range:     1.067545 deg:    3.342695 deg\n",
       " n_s:    287  type_s: FREQ      unit_s: Hz     range: 1330320493.996 Hz:1390096088.856 Hz"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the primary beam file\n",
    "pb_file = data_dir+'COSMOS123.CORR.1330.ms.contsub.dirty.w128.pb.u.e.fits'\n",
    "pb = SpectralCube.read(pb_file)\n",
    "\n",
    "# Display information about the cube\n",
    "pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Primary beam correction\n",
    "* If you choose to perform primary beam correction in ```Python```, then follow step 3.1. (note that one can also do primary beam correction in ```CASA```).\n",
    "* If you have already done primary beam correction, then skip to step 3.2.\n",
    "\n",
    "## 3.1. If the primary beam correction has not yet been done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the header and data of the cube\n",
    "cubehead = fits.getheader(cube_file)\n",
    "cubedata = fits.getdata(cube_file)\n",
    "\n",
    "# Check the shape of the cube\n",
    "shape = cubedata.shape\n",
    "\n",
    "# Check how many dimenstions shape has\n",
    "if len(shape) == 4:\n",
    "        # Assign each value and the dimension\n",
    "        # nc is the number of cubes\n",
    "        # nf is the number of frequency/velocity channels\n",
    "        # ny is the number of DEC points\n",
    "        # nx is the number of RA points\n",
    "        nc, nf, ny, nx = shape \n",
    "        dim = 4\n",
    "elif len(shape) == 2:\n",
    "        ny, nx = S\n",
    "        dim = 2\n",
    "else:\n",
    "    raise(Exception, \"I don't know how to handle a cube with this shape: \"+str(shape))\n",
    "    \n",
    "# Extract the header and data of the primary beam\n",
    "pbhead = fits.getheader(pb_file)\n",
    "pbdata = fits.getdata(pb_file)\n",
    "\n",
    "# Causes WCS init problem if zero\n",
    "if pbhead['CDELT4'] == 0.0:\n",
    "    pbhead['CDELT4'] = -8.236827542606E+07\n",
    "    \n",
    "# Primary beam correction by dividing the image by the pb\n",
    "pbcordat = cubedata / pbdata\n",
    "\n",
    "# Check the shape of the primary beam corrected cube\n",
    "pbshape = pbcordat.shape\n",
    "\n",
    "# Check how many dimenstions pbshape has\n",
    "if len(pbshape) == 4:\n",
    "        pbnc, pbnf, pbny, pbnx = pbshape\n",
    "        pbdim = 4\n",
    "elif len(pbshape) == 2:\n",
    "        pbny, pbnx = pbS\n",
    "        ndim = 2\n",
    "else:\n",
    "        raise(Exception, \"I don't know how to handle a primary beam corrected cube with this shape: \"+str(pbshape))\n",
    "\n",
    "# Save the primary beam corrected file\n",
    "outfile = my_data_dir+'COSMOS123.CORR.1330.ms.contsub.dirty.w128.image.u.e.piwimed.pbcorr.fits'\n",
    "fits.writeto(outfile, pbcordat, header = hdulist[0].header)\n",
    "fits.append(outfile, beam_table, header = hdulist[1].header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. If the primary beam correction has already been done:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now read in the primary beam corrected cube, which was done in ```Python```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: StokesWarning: Cube is a Stokes cube, returning spectral cube for I component [spectral_cube.io.core]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VaryingResolutionSpectralCube with shape=(287, 4096, 4096) and unit=Jy / beam:\n",
       " n_x:   4096  type_x: RA---SIN  unit_x: deg    range:   148.979931 deg:  151.258959 deg\n",
       " n_y:   4096  type_y: DEC--SIN  unit_y: deg    range:     1.067545 deg:    3.342695 deg\n",
       " n_s:    287  type_s: FREQ      unit_s: Hz     range: 1330320493.996 Hz:1390096088.856 Hz"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the primary beam corrected cube\n",
    "pbcordat_file = my_data_dir+'COSMOS123.CORR.1330.ms.contsub.dirty.w128.image.u.e.piwimed.pbcorr.fits'\n",
    "pbcordat = SpectralCube.read(pbcordat_file)\n",
    "\n",
    "# Display information about the cube\n",
    "pbcordat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Extracting subcubes\n",
    "\n",
    "Now that we have a primary beam corrected image, we can extract subcubes around each detection using their positions and frequencies at which the detections occur and plot the HI spectra.\n",
    "\n",
    "My source lists have the following columns:\n",
    "<br>\n",
    "* Detection (number of the detection in the list)\n",
    "* RA (degrees)\n",
    "* Dec (degrees)\n",
    "* Ref (name of detection if found in another catalogue, e.g. AGC208525. If there is no reference in another catalogue, then I just use '-')\n",
    "* MinFreq (minimum baseline frequency of the profile in GHz)\n",
    "* MidFreq (centre frequency in GHz)\n",
    "* MaxFreq (maximum baseline frequency of the profile in GHz)\n",
    "* MinSpec (minimum frequency frequency of the profile in GHz)\n",
    "* MaxSpec (maximum frequency frequency of the profile in GHz)\n",
    "* Profile (morphology: Flat, Double, Gaussian, etc.)\n",
    "* log(MHI) (from MIGHTEE-HI catalogue)\n",
    "* MHI(1e9) (10^log(MHI))\n",
    "* Name (MIGHTEE-HI name from MIGHTEE-HI catalogue)\n",
    "* z (redshift at MidFreq)\n",
    "* log(Mstellar) (from MIGHTEE-HI catalogue)\n",
    "* log(SFR) (from MIGHTEE-HI catalogue)\n",
    "* log(Age) (from MIGHTEE-HI catalogue)\n",
    "* EBV (from MIGHTEE-HI catalogue)\n",
    "* umag (from MIGHTEE-HI catalogue)\n",
    "* gmag (from MIGHTEE-HI catalogue)\n",
    "* rmag (from MIGHTEE-HI catalogue)\n",
    "* Semimaj (from MIGHTEE-HI catalogue)\n",
    "* Semimin (from MIGHTEE-HI catalogue)\n",
    "* PA (from MIGHTEE-HI catalogue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=29</i>\n",
       "<table id=\"table139812278671904\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>Detection</th><th>RA</th><th>Dec</th><th>Ref</th><th>MinFreq</th><th>MidFreq</th><th>MaxFreq</th><th>MinSpec</th><th>MaxSpec</th><th>Profile</th><th>log(MHI)</th><th>MHI(1e9)</th><th>Name</th><th>z</th><th>log(Mstellar)</th><th>log(SFR)</th><th>log(Age)</th><th>EBV</th><th>umag</th><th>gmag</th><th>rmag</th><th>Semimaj</th><th>Semimin</th><th>PA</th></tr></thead>\n",
       "<thead><tr><th>int64</th><th>float64</th><th>float64</th><th>str9</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>str17</th><th>float64</th><th>float64</th><th>str21</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th></tr></thead>\n",
       "<tr><td>1</td><td>149.846692</td><td>2.693685</td><td>-</td><td>1.354</td><td>1.355819</td><td>1.357</td><td>1.355192</td><td>1.356446</td><td>Flat</td><td>8.983</td><td>0.961612</td><td>MGTH_J095923.2+024137</td><td>0.047637</td><td>9.68096</td><td>-0.148713</td><td>9.90309</td><td>0.05</td><td>18.364504</td><td>17.424356</td><td>16.977141</td><td>12.135</td><td>6.913</td><td>80.0</td></tr>\n",
       "<tr><td>4</td><td>150.430155</td><td>2.685806</td><td>AGC208525</td><td>1.355</td><td>1.356655</td><td>1.368</td><td>1.356237</td><td>1.357282</td><td>Flat</td><td>9.712</td><td>5.152286</td><td>MGTH_J100143.2+024109</td><td>0.046991</td><td>9.23994</td><td>-0.081352</td><td>9.477121</td><td>0.1</td><td>18.593977</td><td>17.721064</td><td>17.366805</td><td>16.782</td><td>12.575</td><td>0.0</td></tr>\n",
       "<tr><td>5</td><td>150.038618</td><td>2.713136</td><td>AGC204456</td><td>1.374</td><td>1.375466</td><td>1.377</td><td>1.375257</td><td>1.376093</td><td>Double</td><td>9.472</td><td>2.964831</td><td>MGTH_J100009.3+024247</td><td>0.032672</td><td>9.45761</td><td>-0.521555</td><td>9.875061</td><td>0.0</td><td>0.0</td><td>17.083673</td><td>16.655813</td><td>19.904</td><td>10.339</td><td>330.0</td></tr>\n",
       "<tr><td>7</td><td>149.756951</td><td>2.549942</td><td>-</td><td>1.379</td><td>1.380482</td><td>1.382</td><td>1.380064</td><td>1.3809</td><td>Flat,lopsided</td><td>8.801</td><td>0.632412</td><td>MGTH_J095901.7+023300</td><td>0.02892</td><td>7.56165</td><td>-0.414986</td><td>8.006543</td><td>0.2</td><td>19.502996</td><td>18.873676</td><td>18.688301</td><td>7.635</td><td>5.561</td><td>90.0</td></tr>\n",
       "<tr><td>8</td><td>150.807844</td><td>2.341862</td><td>-</td><td>1.365</td><td>1.367106</td><td>1.369</td><td>1.3669</td><td>1.367732</td><td>Gaussian,lopsided</td><td>9.32</td><td>2.089296</td><td>MGTH_J100313.9+022031</td><td>0.038987</td><td>-99.0</td><td>-99.0</td><td>0.0</td><td>-99.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>4.0</td><td>4.0</td><td>0.0</td></tr>\n",
       "<tr><td>10</td><td>150.171143</td><td>2.412895</td><td>-</td><td>1.355</td><td>1.356655</td><td>1.358</td><td>1.356237</td><td>1.357073</td><td>Gaussian</td><td>9.068</td><td>1.169499</td><td>MGTH_J100041.1+022446</td><td>0.046991</td><td>8.19382</td><td>-0.424585</td><td>8.756548</td><td>0.3</td><td>20.86746</td><td>19.977257</td><td>19.594132</td><td>5.342</td><td>5.111</td><td>90.0</td></tr>\n",
       "<tr><td>11</td><td>150.404485</td><td>2.10662</td><td>-</td><td>1.358</td><td>1.35979</td><td>1.361</td><td>1.359372</td><td>1.359999</td><td>Gaussian</td><td>8.491</td><td>0.309742</td><td>MGTH_J100137.1+020624</td><td>0.044577</td><td>8.92938</td><td>-0.673457</td><td>9.812913</td><td>0.1</td><td>19.620231</td><td>18.6917</td><td>18.272216</td><td>8.493</td><td>8.422</td><td>90.0</td></tr>\n",
       "<tr><td>12</td><td>150.230087</td><td>2.395457</td><td>AGC204457</td><td>1.358</td><td>1.360208</td><td>1.362</td><td>1.359372</td><td>1.360626</td><td>Flat,lopsided</td><td>9.274</td><td>1.879317</td><td>MGTH_J100055.2+022344</td><td>0.044256</td><td>10.416</td><td>-0.122561</td><td>9.845098</td><td>0.05</td><td>17.547062</td><td>16.214165</td><td>15.586224</td><td>21.68</td><td>13.983</td><td>0.0</td></tr>\n",
       "<tr><td>13</td><td>150.313451</td><td>2.306401</td><td>-</td><td>1.379</td><td>1.381109</td><td>1.383</td><td>1.380273</td><td>1.381318</td><td>Flat,lopsided</td><td>9.248</td><td>1.770109</td><td>MGTH_J100115.2+021823</td><td>0.028453</td><td>8.61082</td><td>-0.783372</td><td>9.414973</td><td>0.0</td><td>18.468288</td><td>17.761891</td><td>17.487835</td><td>15.423</td><td>5.408</td><td>345.0</td></tr>\n",
       "<tr><td>14</td><td>149.335627</td><td>1.918625</td><td>AGC191619</td><td>1.374</td><td>1.376302</td><td>1.378</td><td>1.375884</td><td>1.376929</td><td>Gaussian</td><td>9.69</td><td>4.897788</td><td>MGTH_J095720.6+015507</td><td>0.032045</td><td>10.1396</td><td>0.196737</td><td>10.041393</td><td>0.0</td><td>0.0</td><td>15.3605</td><td>14.965485</td><td>35.412</td><td>26.773</td><td>50.0</td></tr>\n",
       "<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "<tr><td>30</td><td>150.988075</td><td>2.418039</td><td>AGC201251</td><td>1.382</td><td>1.383617</td><td>1.385</td><td>1.382572</td><td>1.384935</td><td>Flat,lopsided</td><td>9.586</td><td>3.854784</td><td>MGTH_J100357.1+022505</td><td>0.026589</td><td>-99.0</td><td>-99.0</td><td>0.0</td><td>-99.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>4.0</td><td>4.0</td><td>0.0</td></tr>\n",
       "<tr><td>31</td><td>150.968441</td><td>2.426136</td><td>-</td><td>1.382</td><td>1.383408</td><td>1.385</td><td>1.383199</td><td>1.383617</td><td>Gaussian</td><td>8.872</td><td>0.744732</td><td>MGTH_J100352.4+022534</td><td>0.026744</td><td>-99.0</td><td>-99.0</td><td>0.0</td><td>-99.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>4.0</td><td>4.0</td><td>0.0</td></tr>\n",
       "<tr><td>33</td><td>150.679479</td><td>1.995548</td><td>-</td><td>1.338</td><td>1.340144</td><td>1.342</td><td>1.339935</td><td>1.3406</td><td>Gaussian</td><td>9.223</td><td>1.671091</td><td>MGTH_J100243.1+015944</td><td>0.05989</td><td>8.26728</td><td>-1.31708</td><td>9.30103</td><td>0.3</td><td>0.0</td><td>21.905879</td><td>21.224922</td><td>4.763</td><td>4.672</td><td>90.0</td></tr>\n",
       "<tr><td>34</td><td>150.345539</td><td>1.793541</td><td>-</td><td>1.384</td><td>1.385916</td><td>1.387</td><td>1.385498</td><td>1.386125</td><td>Gaussian</td><td>8.626</td><td>0.422669</td><td>MGTH_J100122.9+014737</td><td>0.024886</td><td>7.63386</td><td>-1.0156</td><td>8.806548</td><td>0.15</td><td>19.793967</td><td>19.101079</td><td>18.902416</td><td>12.207</td><td>5.38</td><td>50.0</td></tr>\n",
       "<tr><td>37</td><td>149.964278</td><td>1.70668</td><td>-</td><td>1.384</td><td>1.385707</td><td>1.387</td><td>1.385498</td><td>1.385916</td><td>Gaussian</td><td>8.813</td><td>0.65013</td><td>MGTH_J095951.4+014224</td><td>0.02504</td><td>7.18355</td><td>-0.914351</td><td>8.206545</td><td>0.1</td><td>0.0</td><td>19.196451</td><td>19.114004</td><td>9.242</td><td>6.346</td><td>130.0</td></tr>\n",
       "<tr><td>39</td><td>149.593779</td><td>1.584713</td><td>-</td><td>1.38</td><td>1.382572</td><td>1.384</td><td>1.382363</td><td>1.382781</td><td>Gaussian</td><td>9.037</td><td>1.08893</td><td>MGTH_J095822.5+013505</td><td>0.027365</td><td>-99.0</td><td>-99.0</td><td>0.0</td><td>-99.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>4.0</td><td>4.0</td><td>0.0</td></tr>\n",
       "<tr><td>40</td><td>150.099013</td><td>2.368161</td><td>-</td><td>1.372</td><td>1.375466</td><td>1.38</td><td>1.375257</td><td>1.375675</td><td>Gaussian</td><td>7.916</td><td>0.082414</td><td>MGTH_J100023.8+022205</td><td>0.032672</td><td>7.59845</td><td>-1.98592</td><td>9.30103</td><td>0.05</td><td>21.790596</td><td>20.961849</td><td>20.544352</td><td>6.693</td><td>4.445</td><td>90.0</td></tr>\n",
       "<tr><td>48</td><td>149.369742</td><td>3.085745</td><td>-</td><td>1.338</td><td>1.341607</td><td>1.345</td><td>1.341398</td><td>1.342025</td><td>Gaussian</td><td>9.853</td><td>7.12853</td><td>MGTH_J095728.7+030509</td><td>0.058735</td><td>-99.0</td><td>-99.0</td><td>0.0</td><td>-99.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>4.0</td><td>4.0</td><td>0.0</td></tr>\n",
       "<tr><td>49</td><td>149.363779</td><td>1.87243</td><td>AGC193557</td><td>1.374</td><td>1.375257</td><td>1.377</td><td>1.374839</td><td>1.375675</td><td>Gaussian</td><td>8.807</td><td>0.64121</td><td>MGTH_J095727.3+015221</td><td>0.032829</td><td>8.31156</td><td>0.177483</td><td>8.006543</td><td>0.3</td><td>0.0</td><td>17.897732</td><td>17.595738</td><td>12.251</td><td>10.417</td><td>90.0</td></tr>\n",
       "<tr><td>54</td><td>150.652188</td><td>1.771678</td><td>-</td><td>1.357</td><td>1.3589</td><td>1.363</td><td>1.358536</td><td>1.359581</td><td>Double</td><td>8.744</td><td>0.554626</td><td>MGTH_J100236.5+014618</td><td>0.045261</td><td>7.94225</td><td>-1.32108</td><td>9.380211</td><td>0.1</td><td>0.0</td><td>20.452731</td><td>20.160727</td><td>9.091</td><td>5.824</td><td>30.0</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=29>\n",
       "Detection     RA       Dec       Ref    ...    rmag   Semimaj Semimin    PA  \n",
       "  int64    float64   float64     str9   ...  float64  float64 float64 float64\n",
       "--------- ---------- -------- --------- ... --------- ------- ------- -------\n",
       "        1 149.846692 2.693685         - ... 16.977141  12.135   6.913    80.0\n",
       "        4 150.430155 2.685806 AGC208525 ... 17.366805  16.782  12.575     0.0\n",
       "        5 150.038618 2.713136 AGC204456 ... 16.655813  19.904  10.339   330.0\n",
       "        7 149.756951 2.549942         - ... 18.688301   7.635   5.561    90.0\n",
       "        8 150.807844 2.341862         - ...       0.0     4.0     4.0     0.0\n",
       "       10 150.171143 2.412895         - ... 19.594132   5.342   5.111    90.0\n",
       "       11 150.404485  2.10662         - ... 18.272216   8.493   8.422    90.0\n",
       "       12 150.230087 2.395457 AGC204457 ... 15.586224   21.68  13.983     0.0\n",
       "       13 150.313451 2.306401         - ... 17.487835  15.423   5.408   345.0\n",
       "       14 149.335627 1.918625 AGC191619 ... 14.965485  35.412  26.773    50.0\n",
       "      ...        ...      ...       ... ...       ...     ...     ...     ...\n",
       "       30 150.988075 2.418039 AGC201251 ...       0.0     4.0     4.0     0.0\n",
       "       31 150.968441 2.426136         - ...       0.0     4.0     4.0     0.0\n",
       "       33 150.679479 1.995548         - ... 21.224922   4.763   4.672    90.0\n",
       "       34 150.345539 1.793541         - ... 18.902416  12.207    5.38    50.0\n",
       "       37 149.964278  1.70668         - ... 19.114004   9.242   6.346   130.0\n",
       "       39 149.593779 1.584713         - ...       0.0     4.0     4.0     0.0\n",
       "       40 150.099013 2.368161         - ... 20.544352   6.693   4.445    90.0\n",
       "       48 149.369742 3.085745         - ...       0.0     4.0     4.0     0.0\n",
       "       49 149.363779  1.87243 AGC193557 ... 17.595738  12.251  10.417    90.0\n",
       "       54 150.652188 1.771678         - ... 20.160727   9.091   5.824    30.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections = ascii.read(det_dir+'COSMOS123_1330_catalogue_notes.txt', header_start = 0, data_start = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, a function called `get_subcube_and_noisecube` has been defined. It extracts a subcube from an input cube, as well as the corresponding noise cube. The noise cubes are important for taking the standard deviation of noise in the noise cubes and using the mean as the overall noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function extracts the signal and noise cubes\n",
    "def get_subcube_and_noisecube(cube, common_beam, ra, dec, freq, width, velocity_convention='relativistic', noise_offset = 0.5*u.arcmin, dfreq=0.0005):\n",
    "    '''\n",
    "    cube is the cube used for the analysis\n",
    "    ra is the ra of the detection in decimal degrees or hours, minutes and seconds\n",
    "    dec is the dec of the detection in decimal degrees or degrees, minutes and seconds\n",
    "    freq is the center frequency in GHz\n",
    "    width is the size of the signal cube in arcminutes\n",
    "    velocity_convention by default is the relativistic convention\n",
    "    noise_offset is the amount added to the ra of the detection to get the ra of the noise cube\n",
    "    dfreq is the offset from the centre frequency in GHz\n",
    "    \n",
    "    Outputs are:\n",
    "    the signal cube with spectral axis frequency\n",
    "    the signal cube with spectral axis velocity\n",
    "    the frequency axis\n",
    "    the velocity axis\n",
    "    the flux density\n",
    "    the noise cube with spectral axis velocity\n",
    "    the detections coordinates\n",
    "    '''\n",
    "    # Lower and upper frequency limits\n",
    "    freq_lower = '%.5fGHz' % (freq-dfreq) \n",
    "    freq_upper = '%.5fGHz' % (freq+dfreq)\n",
    "    \n",
    "    # Subcube extraction string\n",
    "    crtf_str = 'centerbox[['+ra+','+dec+'], ['+width+','+width+']], coord=fk5, range=['+freq_lower+', '+freq_upper+']]'\n",
    "    \n",
    "    # Convert the RA and DEC into decimal degrees if not yet in decimal degrees\n",
    "    coord = SkyCoord(ra, dec, unit='deg', frame='fk5')\n",
    "    \n",
    "    # RA and Dec for the noise cube. Need to shift the RA by the specified width\n",
    "    ra_deg = coord.ra.deg + noise_offset.to(u.deg).value\n",
    "    dec_deg = coord.dec.deg # Same declination as signal cube\n",
    "\n",
    "    # Noise cube extraction\n",
    "    noise_crtf = 'centerbox[['+str(ra_deg)+','+str(dec_deg)+'], ['+width+','+width+']], coord=fk5, range=['+freq_lower+', '+freq_upper+']]'\n",
    "\n",
    "    # Generating the new signal cube from the crtf_str region, spectral axis = frequency\n",
    "    subcube = cube.subcube_from_crtfregion(crtf_str) \n",
    "    \n",
    "    # Convolve the subcube to the common beam\n",
    "    target_subcube = subcube.convolve_to(common_beam)\n",
    "    \n",
    "    # Generating the corresponding noise cube from the noise_crtf region, spectral axis = frequency\n",
    "    noise_sub = cube.subcube_from_crtfregion(noise_crtf) \n",
    "    noise_subcube = noise_sub.convolve_to(common_beam)\n",
    "    \n",
    "    # Frequency axis in Hz\n",
    "    freqs = target_subcube.spectral_axis \n",
    "    \n",
    "    # Convert the signal and noise cubes spectral axes into velocity km/s in radio convention\n",
    "    vel_subcube = target_subcube.with_spectral_unit(u.km / u.s, velocity_convention=velocity_convention, rest_value=1.42040575e9*u.Hz)\n",
    "    noise_velsubcube = noise_subcube.with_spectral_unit(u.km / u.s, velocity_convention=velocity_convention, rest_value=1.42040575e9*u.Hz)\n",
    "    \n",
    "    # Velocity axis in km/s\n",
    "    vel = vel_subcube.spectral_axis\n",
    "    \n",
    "    # Flux density values in Jy/beam\n",
    "    target_spectrum_sum = target_subcube.sum(axis=(1,2))/target_subcube.unit\n",
    "    \n",
    "    return coord, target_subcube, vel_subcube, freqs, vel, target_spectrum_sum, noise_velsubcube, noise_subcube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subcubes of 2 arcmin radii are typically extracted, but sometimes you have feint sources or sources that are very close to each other that need smaller radii, or really large sources that need bigger radii. The parameters used for the extractions are the same as those used in `Step1_Moment_Maps_COSMOS_1330.ipynb` (apart from an increased frequency width) for consistency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common beam of the main cube\n",
    "common_beam = cube.beams.common_beam(tolerance=1e-5)\n",
    "\n",
    "# Extraction parameters\n",
    "subcube_width = 2 # Size of the subcube in arcminutes\n",
    "subcube_width_in_text = '2arcmin' # String format of the size of the subcube\n",
    "\n",
    "# We may encounter detections that need a bigger or smaller subcube extraction, so you can select their index numbers:\n",
    "list_index = []\n",
    "# The new width to use instead of '2arcmin'\n",
    "width_new = []\n",
    "width_new_in_text = []\n",
    "\n",
    "# Frequency width for the extraction\n",
    "half_freq_width = 2e-3 # This is dfreq in the det_subcube_and_noisecube() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Capture all warnings\n",
    "\n",
    "# Subcube and noise cubes extractions\n",
    "subcube = [] # Subcubes with frequency axis\n",
    "Sum = [] # Sum value of the flux\n",
    "vel = [] # Velocity axis\n",
    "freqs = [] # Frequency axis\n",
    "vel_subcube = [] # Subcubes with velocity axis\n",
    "noise_velsubcube = [] # Noise cubes with velocity axis\n",
    "noise_subcube = [] # Noise cubes with frequency axis\n",
    "dets = [] # Detection numbers\n",
    "coordinates = [] # Coordinates of each detection\n",
    "center_freqs = [] # Center frequencies\n",
    "\n",
    "for i in range(len(detections)):\n",
    "    ra = detections[i]['RA'] \n",
    "    dec = detections[i]['Dec'] \n",
    "    freq = detections[i]['MidFreq'] \n",
    "    det = detections[i]['Detection']\n",
    "    \n",
    "    # Check if the detection needs a bigger radius of extraction (refer to list_index in very first cell)\n",
    "    if detections[i]['Detection'] in list_index:\n",
    "        # Get the detections index in the index list\n",
    "        i = list_index.index(detections[i]['Detection'])\n",
    "        coord, a, b, c, d, e, f, g = get_subcube_and_noisecube(pbcordat, common_beam, str(ra), str(dec), freq, noise_offset=width_new[i]*u.arcmin, width=width_new_in_text[i], dfreq=half_freq_width)\n",
    "    # Else extract a subcube of size 2 arcminutes\n",
    "    else:\n",
    "        coord, a, b, c, d, e, f, g = get_subcube_and_noisecube(pbcordat, common_beam, str(ra), str(dec), freq, noise_offset=subcube_width*u.arcmin, width=subcube_width_in_text, dfreq=half_freq_width)\n",
    "    \n",
    "    # Store everything in the lists\n",
    "    coordinates.append(coord)\n",
    "    subcube.append(a)\n",
    "    vel_subcube.append(b)\n",
    "    freqs.append(c)\n",
    "    vel.append(d)\n",
    "    Sum.append(e)\n",
    "    noise_velsubcube.append(f)\n",
    "    noise_subcube.append(g)\n",
    "    dets.append(det)\n",
    "    center_freqs.append(freq*u.GHz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Smoothing the cubes\n",
    "\n",
    "As with the `Step1_Moment_Maps_COSMOS_1330.ipynb` notebook, for consistency we need to convolve the subcubes and noise cubes into a common restoring beam: the bigger the restored beam is, the more sensitive to faint emission the cube will be. For that, we will convolve the signal cubes into a circular beam of 20\" x 20\" with a bpa = 0 degrees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function convolves the cube to a circular beam\n",
    "def beam_convolution_and_mean_rms(cube, noise_cube, beam, detections_list):\n",
    "    '''\n",
    "    cube is the signal cube to be convolved\n",
    "    noise_cube is the noise_cube to be convolved\n",
    "    beam is the beam we will convolve the cubes to \n",
    "    detections_list is the ASCII table containing the list of detections\n",
    "    \n",
    "    Outputs are:\n",
    "    a list of the convolved signal cubes\n",
    "    a list of the convolved noise cubes\n",
    "    the mean noise from the noise cube\n",
    "    '''\n",
    "    convolved_cube = [] # List to store convolved signal cubes\n",
    "    convolved_noise_cube = [] # List to store convolved noise cubes\n",
    "    mean_rms = [] # List to store mean noise values from each noise cube\n",
    "    \n",
    "    # Loop through each detection\n",
    "    for i in range(len(detections_list)):\n",
    "        # Convolve the signal and noise cubes\n",
    "        convolved_cube.append(cube[i].convolve_to(beam))\n",
    "        convolved_noise_cube.append(noise_cube[i].convolve_to(beam))\n",
    "        \n",
    "        # Calculate the mean of standard deviation of the noise cube\n",
    "        std = convolved_noise_cube[i].std(axis=(1,2))/convolved_noise_cube[i].unit \n",
    "        mean_rms.append(np.mean(std))\n",
    "        \n",
    "    return convolved_cube, convolved_noise_cube, mean_rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Capture all warnings\n",
    "\n",
    "# Beam convolution parameters\n",
    "circular_beam_axis = 20 # 20'' x 20'' circular beam\n",
    "\n",
    "# Convolve the noise and signal cubes to a circular beam\n",
    "circular_beam = Beam(major=circular_beam_axis*u.arcsec, minor=circular_beam_axis*u.arcsec, pa=0*u.deg)\n",
    "\n",
    "# Convolution and rms for velocity cube\n",
    "vel_circular, noise_circular, mean_rms_circular = beam_convolution_and_mean_rms(vel_subcube, noise_velsubcube, circular_beam, detections)\n",
    "\n",
    "# Convolution and rms for frequency cube\n",
    "freq_circular, noise_circular, mean_rms_circular_freq = beam_convolution_and_mean_rms(subcube, noise_subcube, circular_beam, detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Masking the extracted subcubes with the smoothed cubes\n",
    "\n",
    "Masking is done so that when the profile fitting is done, the software can destinguish the baseline from the HI emission of the profile clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_cube(cube, smooth_cube, rms, sigma):\n",
    "    mask_cube = cube.with_mask(smooth_cube > sigma*rms*smooth_cube.unit)\n",
    "    \n",
    "    return mask_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "masked_subcubes_freq = [] # List to store masked subcubes with frequency axis\n",
    "masked_subcubes_vel = [] # List to store masked subcubes with velocity axis\n",
    "masked_sum_freq = [] # List to store integrated flux from masked frequency cubes\n",
    "masked_sum_vel = [] # List to store integrated flux from masked velocity cubes\n",
    "\n",
    "for i in range(len(detections)):\n",
    "    masked_freq = masked_cube(subcube[i], freq_circular[i], mean_rms_circular_freq[i], sigma = 3)\n",
    "    masked_subcubes_freq.append(masked_freq)\n",
    "    masked_sum_freq.append(np.nan_to_num(masked_freq.sum(axis=(1,2))))\n",
    "    \n",
    "    masked_vel = masked_cube(vel_subcube[i], vel_circular[i], mean_rms_circular[i], sigma = 3)\n",
    "    masked_subcubes_vel.append(masked_vel)\n",
    "    masked_sum_vel.append(np.nan_to_num(masked_vel.sum(axis=(1,2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Calculating the error in the flux densities\n",
    "\n",
    "Now that we have masked the cubes, we must find the error in the flux density (Jy/beam). We need to calculate the rms in each channel of the unmasked subcubes (which is just the standard deviation), i.e. calculate the rms of each plane (or image slice) that has constant frequency/velocity but varying RA and Dec in the cube. The rms in each channel is the error in the flux density to first order. And for Gaussian statistics, the rms should be roughly equal to the standard deviation.\n",
    "\n",
    "Also, since the frequencies are defined by the correlator, they do not have any uncertainties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "# The capture line above will prevent this cell from printing out too many warnings\n",
    "\n",
    "error = [] # Error in Jy/beam\n",
    "\n",
    "# Loop through each detection\n",
    "for i in range(len(detections)):\n",
    "    error.append(subcube[i].std(axis=(1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To double check how the standard deviation was calculated, we can calculate it manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "\n",
    "# mean = subcube[0].mean(axis=(1,2))\n",
    "\n",
    "# stddev = []\n",
    "\n",
    "# for i in range(len(subcube[0])):\n",
    "#     num = pow(subcube[0][i] - mean[i], 2).sum(axis=(0,1))\n",
    "#     sig = np.sqrt(num/subcube[0][i].size)\n",
    "    \n",
    "#     stddev.append(sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviation should equal the rms, so we can confirm that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "\n",
    "# rms = []\n",
    "\n",
    "# for i in range(len(subcube[0])):\n",
    "#     numsum = pow(subcube[0][i], 2).sum(axis=(0,1))\n",
    "#     sqrroot = np.sqrt(numsum/subcube[0][i].size)\n",
    "\n",
    "#     rms.append(sqrroot.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Optional: plotting the profiles from each subcube\n",
    "\n",
    "Since the spectra of the profiles are low resolution, the convention is to plot them as flux density as a function of frequency. High resolution spectra are usually what have the x-axis in velocity (km/s). Note that since we are limited by the channel resolution, it is best to plot the spectra with a step plot with the middle of the step indication the measurement and the width indication the channel resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl.figure(figsize=(50,120))\n",
    "\n",
    "# for i in range(len(detections)):\n",
    "#     pl.subplot(15,2,i+1)\n",
    "\n",
    "#     pl.step((freqs[i].to(u.MHz)).value, masked_sum_freq[i].value, 'k', where='mid')\n",
    "#     pl.errorbar((freqs[i].to(u.MHz)).value, masked_sum_freq[i].value, yerr=error[i].value, fmt='', marker=None, \n",
    "#                 ls='none', color='k')\n",
    "#     pl.axvline(x=(center_freqs[i].to(u.MHz)).value, color='red', zorder=1, \n",
    "#                label='Center Frequency: %.2f MHz'%(center_freqs[i].to(u.MHz)).value)\n",
    "#     pl.axhline(y=0, color='cyan', zorder=1, linestyle='--')\n",
    "#     pl.tick_params(which='major', direction='in')\n",
    "#     pl.title('Detection '+str(dets[i]))\n",
    "#     pl.xlabel('Frequency (MHz)')\n",
    "#     pl.ylabel('Integrated Flux (Jy/beam)')\n",
    "#     pl.tight_layout()\n",
    "#     pl.legend()\n",
    "# pl.subplots_adjust(hspace=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Converting Jy/beam to Jy\n",
    "\n",
    "To start doing the analysis on the spectra, we first need to convert the flux density in Jy/beam to Jy. The method behing this conversion is described in an excerpt from Meyer 2017:\n",
    "\n",
    "![jybeamconv.png](jybeamconv.png)\n",
    "\n",
    "$\\Omega_B$ is the solid angle of the source and has the relation with the physical area given by\n",
    "\n",
    "\\begin{align}\n",
    "\\Omega_B = \\frac{\\pi b_\\text{maj}b_{min}}{4\\text{ln}2}, \\\\\n",
    "\\end{align}\n",
    "\n",
    "in units of steradians (radians squared) or m$^2$m$^{-2}$. In our case, we will work in arcseconds squared. We can convert the errors in Jy/beam in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that converts Jy/beam to Jy\n",
    "def jybeam_jy(subcube_list, sum_list, err):\n",
    "    '''\n",
    "    subcube_list is the list of subcubes\n",
    "    sum_list is the list of sum flux densities in Jy/beam\n",
    "    err is the list of errors in Jy/beam\n",
    "    '''\n",
    "    # List to store the fluxes in Jy for each detection\n",
    "    jy_list = []\n",
    "    jy_err_list = []\n",
    "    \n",
    "    # Loop through each detection\n",
    "    for i in range(len(subcube_list)):\n",
    "        # List to store Jy for each channel\n",
    "        jy = [] \n",
    "        jy_err = []\n",
    "        \n",
    "        # Loop through each channel\n",
    "        for j in range(len(subcube_list[i])):\n",
    "            # Calculate the solid angle or beam (omegaB) in arcsec squared\n",
    "            # Jy/beam * beam = Jy/pixel_area\n",
    "            bmaj = (subcube_list[i][j].beam.major).to(u.arcsec).value\n",
    "            bmin = (subcube_list[i][j].beam.minor).to(u.arcsec).value\n",
    "\n",
    "            omegaB = (np.pi*bmaj*bmin)/(4*np.log(2))\n",
    "\n",
    "            # Calculate the pixel area in arcsec squared\n",
    "            # Jy/pixel * pixel_area = Jy\n",
    "            # CDELT1 and CDELT2 have the same magnitudes in degrees, so CDELT2 will be used since CDELT2 > 0\n",
    "            pix_area = pow((subcube_list[i].header['CDELT2']*3600),2)\n",
    "\n",
    "            jy.append(sum_list[i][j].value*(pix_area/omegaB))\n",
    "            jy_err.append(err[i][j].value*(pix_area/omegaB))\n",
    "\n",
    "        jy_list.append(np.array(jy)*u.Jy)\n",
    "        jy_err_list.append(np.array(jy_err)*u.Jy)\n",
    "    \n",
    "    return jy_list, jy_err_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Capture all warnings\n",
    "\n",
    "flux, flux_err = jybeam_jy(masked_subcubes_freq, masked_sum_freq, error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also calculate the flux of the unmasked profiles for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Capture all warnings\n",
    "\n",
    "unmasked_flux, unmasked_flux_err = jybeam_jy(subcube, Sum, error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the rms calculated from the unmasked profiles for each detection to a text file\n",
    "dirName = analysis_res+'/users/wanga/mightee/analysis/COSMOS_1330/masked_profiles_COSMOS_1330_output/'\n",
    "\n",
    "# Create the text file\n",
    "f = open(dirName+'unmasked_rms.txt', 'w+')\n",
    "\n",
    "f.write('Detection rms[Jy]\\n')\n",
    "\n",
    "# Loop through each detection\n",
    "for i in range(len(detections)):\n",
    "    # Only need the rms in Jy in a signal free part of the spectrum\n",
    "    f.write('%i %e\\n'%(detections[i][0], unmasked_flux_err[i][0].value))\n",
    "        \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are working with the masked profiles, it is best to use the method above to also have errors for the values in the baseline that are zero as a result of masking. The method below gives the same errors, however, should only be used when using the unmasked profiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the error in the flux we can use:\n",
    "\n",
    "\\begin{align}\n",
    "u(\\text{flux}) = \\sqrt{\\left(\\text{flux}\\frac{u(Sum)}{Sum}\\right)^2}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the error in the flux\n",
    "flux_err = []\n",
    "\n",
    "# Loop through each detection\n",
    "for i in range(len(detections)):\n",
    "    # Calculate the error in each channel\n",
    "    err = []\n",
    "    for j in range(len(flux[i])):\n",
    "        # Return 0 where uncertainties are 0\n",
    "        if flux[i][j].value == 0:\n",
    "            err.append(0)\n",
    "        else:\n",
    "            err.append(flux[i][j].value*(error[i][j].value/masked_sum_freq[i][j].value))\n",
    "        \n",
    "    flux_err.append(np.array(err)*u.Jy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: plot the spectra in terms of flux in Jy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl.figure(figsize=(50,120))\n",
    "\n",
    "# for i in range(len(detections)):\n",
    "#     pl.subplot(15,2,i+1)\n",
    "\n",
    "#     pl.step((freqs[i].to(u.MHz)).value, flux[i].value, 'k', where='mid') \n",
    "#     pl.errorbar((freqs[i].to(u.MHz)).value, flux[i].value, yerr=flux_err[i].value, fmt='', marker=None, ls='none', color='k')\n",
    "#     pl.axvline(x=(center_freqs[i].to(u.MHz)).value, color='red', zorder=1, \n",
    "#                label='Center Frequency: %.2f MHz'%(center_freqs[i].to(u.MHz)).value)\n",
    "#     pl.axhline(y=0, color='cyan', zorder=1, linestyle='--')\n",
    "#     pl.tick_params(which='major', direction='in')\n",
    "#     pl.title('Detection '+str(dets[i]))\n",
    "#     pl.xlabel('Frequency (MHz)')\n",
    "#     pl.ylabel('Flux Density (Jy)')\n",
    "#     pl.tight_layout()\n",
    "#     pl.legend() \n",
    "# pl.subplots_adjust(hspace=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Analysis\n",
    "This section will be useful for if you want to calculate some of the HI quantities yourself. The results from the notebook are written to text files at the very end.\n",
    "\n",
    "## 10.1. Create a mask where the HI emission is\n",
    "Note that since one Early Science channel is 208985.82 Hz wide, we are plotting the spectral as a step function (i.e. for every 208985.82 Hz, we have one flux value). The bounds of the the emission need to lie at the centers of the step.\n",
    "\n",
    "Note, the channel width can be checked using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$209005.58 \\; \\mathrm{Hz}$"
      ],
      "text/plain": [
       "<Quantity 209005.57643318 Hz>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnu = freqs[0][1] - freqs[0][0]\n",
    "dnu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find out what the channel width is in terms of velocity, which will be useful later, one can either use the velocity list that was calculated in the subcube extraction using `with_spectral_unit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$46.149862 \\; \\mathrm{\\frac{km}{s}}$"
      ],
      "text/plain": [
       "<Quantity 46.14986194 km / s>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vel[0][4]-vel[0][5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or by converting the frequencies directly into velocities, and then calculating the difference (which is essentially what `with_spectral_unit` does). However, the channel wdith varies slightly across each detection due to the relativistic conversion from frequencies to velocities, so we need to calculate the average channel width for each detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store average channel widths in velocity space\n",
    "dv_det = []\n",
    "\n",
    "for i in range (len(detections)):\n",
    "    dv_det.append(np.average(abs(np.diff(vel[i]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to creating the mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency limits for each of the detections\n",
    "# The number of bounds below will depend on the size of your detections list\n",
    "f_1a, f_1b = detections[0]['MinSpec']*1e3, detections[0]['MaxSpec']*1e3\n",
    "f_4a, f_4b = detections[1]['MinSpec']*1e3, detections[1]['MaxSpec']*1e3\n",
    "f_5a, f_5b = detections[2]['MinSpec']*1e3, detections[2]['MaxSpec']*1e3\n",
    "f_7a, f_7b = detections[3]['MinSpec']*1e3, detections[3]['MaxSpec']*1e3\n",
    "f_8a, f_8b = detections[4]['MinSpec']*1e3, detections[4]['MaxSpec']*1e3\n",
    "f_10a, f_10b = detections[5]['MinSpec']*1e3, detections[5]['MaxSpec']*1e3\n",
    "f_11a, f_11b = detections[6]['MinSpec']*1e3, detections[6]['MaxSpec']*1e3\n",
    "f_12a, f_12b = detections[7]['MinSpec']*1e3, detections[7]['MaxSpec']*1e3\n",
    "f_13a, f_13b = detections[8]['MinSpec']*1e3, detections[8]['MaxSpec']*1e3\n",
    "f_14a, f_14b = detections[9]['MinSpec']*1e3, detections[9]['MaxSpec']*1e3\n",
    "f_17a, f_17b = detections[10]['MinSpec']*1e3, detections[10]['MaxSpec']*1e3\n",
    "f_18a, f_18b = detections[11]['MinSpec']*1e3, detections[11]['MaxSpec']*1e3\n",
    "f_19a, f_19b = detections[12]['MinSpec']*1e3, detections[12]['MaxSpec']*1e3\n",
    "f_20a, f_20b = detections[13]['MinSpec']*1e3, detections[13]['MaxSpec']*1e3\n",
    "f_21a, f_21b = detections[14]['MinSpec']*1e3, detections[14]['MaxSpec']*1e3\n",
    "f_22a, f_22b = detections[15]['MinSpec']*1e3, detections[15]['MaxSpec']*1e3\n",
    "f_23a, f_23b = detections[16]['MinSpec']*1e3, detections[16]['MaxSpec']*1e3\n",
    "f_24a, f_24b = detections[17]['MinSpec']*1e3, detections[17]['MaxSpec']*1e3\n",
    "f_25a, f_25b = detections[18]['MinSpec']*1e3, detections[18]['MaxSpec']*1e3\n",
    "f_30a, f_30b = detections[19]['MinSpec']*1e3, detections[19]['MaxSpec']*1e3\n",
    "f_31a, f_31b = detections[20]['MinSpec']*1e3, detections[20]['MaxSpec']*1e3\n",
    "f_33a, f_33b = detections[21]['MinSpec']*1e3, detections[21]['MaxSpec']*1e3\n",
    "f_34a, f_34b = detections[22]['MinSpec']*1e3, detections[22]['MaxSpec']*1e3\n",
    "f_37a, f_37b = detections[23]['MinSpec']*1e3, detections[23]['MaxSpec']*1e3\n",
    "f_39a, f_39b = detections[24]['MinSpec']*1e3, detections[24]['MaxSpec']*1e3\n",
    "f_40a, f_40b = detections[25]['MinSpec']*1e3, detections[25]['MaxSpec']*1e3\n",
    "f_48a, f_48b = detections[26]['MinSpec']*1e3, detections[26]['MaxSpec']*1e3\n",
    "f_49a, f_49b = detections[27]['MinSpec']*1e3, detections[27]['MaxSpec']*1e3\n",
    "f_54a, f_54b = detections[28]['MinSpec']*1e3, detections[28]['MaxSpec']*1e3\n",
    "\n",
    "# Zip and store these limits in a tuple\n",
    "f_limit = [[f_1a, f_1b],[f_4a, f_4b],[f_5a, f_5b],[f_7a, f_7b],[f_8a, f_8b],[f_10a, f_10b],[f_11a, f_11b],[f_12a, f_12b],[f_13a, f_13b],\n",
    "           [f_14a, f_14b],[f_17a, f_17b],[f_18a, f_18b],[f_19a, f_19b],[f_20a, f_20b],[f_21a, f_21b],[f_22a, f_22b],[f_23a, f_23b],\n",
    "           [f_24a, f_24b],[f_25a, f_25b],[f_30a, f_30b],[f_31a, f_31b],[f_33a, f_33b],[f_34a, f_34b],[f_37a, f_37b],[f_39a, f_39b],\n",
    "           [f_40a, f_40b],[f_48a, f_48b],[f_49a, f_49b],[f_54a, f_54b]]\n",
    "f_a, f_b = zip(*f_limit)\n",
    "\n",
    "# Look for close matches to our limits in the data set\n",
    "# Store these matches in lists\n",
    "findex_a = []\n",
    "findex_b = []\n",
    "for i in range(len(detections)):\n",
    "    x = freqs[i].to(u.MHz).value\n",
    "    # Rather than demand an exact match, should find the closest one\n",
    "    findex_b.append(min(range(len(x)), key=lambda k: abs(x[k]-f_a[i])))\n",
    "    findex_a.append(min(range(len(x)), key=lambda k: abs(x[k]-f_b[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(50,120))\n",
    "\n",
    "for i in range(len(detections)):\n",
    "    pl.subplot(15,2,i+1)\n",
    "\n",
    "    pl.step(freqs[i].to(u.MHz).value, flux[i].value, 'k', where='mid')  \n",
    "    pl.errorbar((freqs[i].to(u.MHz)).value, flux[i].value, yerr=flux_err[i].value, fmt='', marker=None, ls='none', color='k')\n",
    "    pl.axvline(x=(center_freqs[i].to(u.MHz)).value, color='red', zorder=1, \n",
    "               label='Center Frequency: %.2f MHz'%(center_freqs[i].to(u.MHz)).value)\n",
    "    pl.axhline(y=0, color='cyan', zorder=1, linestyle='--')\n",
    "    pl.tick_params(which='major', direction='in')\n",
    "    pl.title('Detection '+str(dets[i]))\n",
    "    pl.xlabel('Frequency (MHz)')\n",
    "    pl.ylabel('Integrated Flux (Jy/beam)')\n",
    "    ax = pl.gca()\n",
    "    ax.axvspan(freqs[i].to(u.MHz).value[findex_a[i]], freqs[i].to(u.MHz).value[findex_b[i]], alpha=0.15, color='grey')\n",
    "    pl.tight_layout()\n",
    "    pl.legend()\n",
    "pl.subplots_adjust(hspace=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following analyisis is based on the the equations in Meyer (2017) and notes found here: https://www.cv.nrao.edu/course/astr534/HILine.html \n",
    "\n",
    "## 10.2. Systemic velocities, Hubble distances and redshifts\n",
    "We need to calculate the systemic velocity using the rest frame motions (i.e. the motions of objects through space; this is the peculiar velocity)\n",
    "\n",
    "\\begin{align}\n",
    "V(z) = c\\frac{\\nu_0^2 - \\nu^2}{\\nu_0^2 + \\nu^2}.\n",
    "\\end{align}\n",
    "\n",
    "It is not advised to use $V = cz = c\\frac{\\nu_0 - \\nu}{\\nu}$ because the deviations from this linear law become increasingly larger. The uncertaintity can be calculated using\n",
    "\n",
    "\\begin{align}\n",
    "u(R) = \\sqrt{\\sum_{i=1}^N \\left(u(w_i)\\frac{\\partial f}{\\partial w_i}\\right)^2},\n",
    "\\end{align}\n",
    "\n",
    "where in our case\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial f}{\\partial w_i} &= \\frac{\\partial V}{\\partial \\nu} = -\\frac{4c\\nu_0^2\\nu}{(\\nu^2 + \\nu_0^2)^2}.\n",
    "\\end{align}\n",
    "\n",
    "Therefore\n",
    "\n",
    "\\begin{align}\n",
    "u(V) = \\sqrt{\\left(-u(\\nu)\\frac{4c\\nu_0^2\\nu}{(\\nu^2 + \\nu_0^2)^2}\\right)^2}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection 1: 13941.34 +\\- 46.11 km/s\n",
      "Detection 2: 13756.94 +\\- 46.09 km/s\n",
      "Detection 3: 9635.00 +\\- 45.51 km/s\n",
      "Detection 4: 8544.73 +\\- 45.35 km/s\n",
      "Detection 5: 11460.42 +\\- 45.77 km/s\n",
      "Detection 6: 13756.94 +\\- 46.09 km/s\n",
      "Detection 7: 13066.35 +\\- 45.99 km/s\n",
      "Detection 8: 12974.39 +\\- 45.98 km/s\n",
      "Detection 9: 8408.70 +\\- 45.33 km/s\n",
      "Detection 10: 9453.03 +\\- 45.48 km/s\n",
      "Detection 11: 13342.41 +\\- 46.03 km/s\n",
      "Detection 12: 9407.56 +\\- 45.47 km/s\n",
      "Detection 13: 13342.41 +\\- 46.03 km/s\n",
      "Detection 14: 8816.95 +\\- 45.39 km/s\n",
      "Detection 15: 13526.58 +\\- 46.06 km/s\n",
      "Detection 16: 13526.58 +\\- 46.06 km/s\n",
      "Detection 17: 12974.39 +\\- 45.98 km/s\n",
      "Detection 18: 16719.72 +\\- 46.50 km/s\n",
      "Detection 19: 8590.08 +\\- 45.36 km/s\n",
      "Detection 20: 7865.19 +\\- 45.25 km/s\n",
      "Detection 21: 7910.45 +\\- 45.26 km/s\n",
      "Detection 22: 17417.94 +\\- 46.60 km/s\n",
      "Detection 23: 7367.80 +\\- 45.18 km/s\n",
      "Detection 24: 7412.98 +\\- 45.19 km/s\n",
      "Detection 25: 8091.54 +\\- 45.29 km/s\n",
      "Detection 26: 9635.00 +\\- 45.51 km/s\n",
      "Detection 27: 17091.93 +\\- 46.55 km/s\n",
      "Detection 28: 9680.51 +\\- 45.51 km/s\n",
      "Detection 29: 13262.26 +\\- 46.02 km/s\n"
     ]
    }
   ],
   "source": [
    "# Defining a function used for converting an observed frequency (Ghz) into velocity (km/s) for 21 cm emission\n",
    "def radial_vel(obs_freq):\n",
    "    '''\n",
    "    obs_freq is the observed frequency of the emitted line in Ghz\n",
    "    nu_o is the rest/emitted frequency in GHz\n",
    "    v_opt is returned in km/s\n",
    "    '''\n",
    "    nu_0 = (hdulist[0].header['RESTFRQ']*u.Hz).to(u.GHz)\n",
    "    v_sys = (const.c.to(u.km/u.s))*((pow(nu_0,2) - pow(obs_freq, 2))/(pow(nu_0,2) + pow(obs_freq, 2)))\n",
    "    return v_sys\n",
    "\n",
    "# Calculate the systemic velocities\n",
    "central_vel = [radial_vel(cfreq) for cfreq in center_freqs]\n",
    "    \n",
    "# Calculate the uncertainties using above formula\n",
    "vel_unc = []\n",
    "for i in range(len(detections)):\n",
    "    un = np.sqrt(pow((-dnu.to(u.GHz)*4*(const.c.to(u.km/u.s))*pow((hdulist[0].header['RESTFRQ']*u.Hz).to(u.GHz),2)*center_freqs[i])/\n",
    "                     (pow((pow(center_freqs[i],2) + pow((hdulist[0].header['RESTFRQ']*u.Hz).to(u.GHz),2)),2)),2))\n",
    "    \n",
    "    vel_unc.append(un)\n",
    "\n",
    "# Display the velocities\n",
    "for i in range(len(central_vel)):\n",
    "    print(\"Detection %d: %.2f +\\- %.2f km/s\"%(int(i+1),central_vel[i].value,vel_unc[i].value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can calculate the redshifts to the galaxies using $z=\\frac{\\nu_0-\\nu}{\\nu}=\\frac{\\nu_0}{\\nu}-1$, and approximate the uncertainties in $z$ using the derivative formula above:\n",
    "\n",
    "\\begin{align}\n",
    "u(z) &= \\sqrt{\\left(u(z)\\frac{\\partial z}{\\partial \\nu}\\right)^2} \\\\\n",
    " &= \\sqrt{\\left[u(\\nu)\\left(-\\frac{\\nu_0}{\\nu^2}\\right)\\right]^2} \\\\\n",
    " &= \\sqrt{\\left[u(\\nu)\\left(-\\frac{\\nu_0}{\\nu^2}\\right)\\right]^2} \\\\\n",
    " &= -\\frac{u(\\nu)\\nu_0}{\\nu^2} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection 1: 0.047637 +\\- 0.000161\n",
      "Detection 2: 0.046991 +\\- 0.000161\n",
      "Detection 3: 0.032672 +\\- 0.000157\n",
      "Detection 4: 0.028920 +\\- 0.000156\n",
      "Detection 5: 0.038987 +\\- 0.000159\n",
      "Detection 6: 0.046991 +\\- 0.000161\n",
      "Detection 7: 0.044577 +\\- 0.000161\n",
      "Detection 8: 0.044256 +\\- 0.000160\n",
      "Detection 9: 0.028453 +\\- 0.000156\n",
      "Detection 10: 0.032045 +\\- 0.000157\n",
      "Detection 11: 0.045541 +\\- 0.000161\n",
      "Detection 12: 0.031888 +\\- 0.000157\n",
      "Detection 13: 0.045541 +\\- 0.000161\n",
      "Detection 14: 0.029856 +\\- 0.000156\n",
      "Detection 15: 0.046185 +\\- 0.000161\n",
      "Detection 16: 0.046185 +\\- 0.000161\n",
      "Detection 17: 0.044256 +\\- 0.000160\n",
      "Detection 18: 0.057417 +\\- 0.000165\n",
      "Detection 19: 0.029076 +\\- 0.000156\n",
      "Detection 20: 0.026589 +\\- 0.000155\n",
      "Detection 21: 0.026744 +\\- 0.000155\n",
      "Detection 22: 0.059890 +\\- 0.000165\n",
      "Detection 23: 0.024886 +\\- 0.000155\n",
      "Detection 24: 0.025040 +\\- 0.000155\n",
      "Detection 25: 0.027365 +\\- 0.000155\n",
      "Detection 26: 0.032672 +\\- 0.000157\n",
      "Detection 27: 0.058735 +\\- 0.000165\n",
      "Detection 28: 0.032829 +\\- 0.000157\n",
      "Detection 29: 0.045261 +\\- 0.000161\n"
     ]
    }
   ],
   "source": [
    "# Extract the redshifts\n",
    "z = [detections[i]['z'] for i in range(len(detections))]\n",
    "    \n",
    "# Calculate the uncertainties in z\n",
    "#unc_z = [z[i]*np.sqrt(pow(dnu/(hdr[0].header['RESTFRQ']*u.Hz),2) + pow(dnu/center_freqs[i].to(u.Hz),2)) for i in range(len(detections))]\n",
    "unc_z = [(dnu.to(u.GHz)*(hdulist[0].header['RESTFRQ']*u.Hz).to(u.GHz))/pow(v,2) for v in center_freqs]\n",
    "    \n",
    "# Display the redshifts\n",
    "for i in range(len(z)):\n",
    "    print(\"Detection %d: %.6f +\\- %.6f\"%(int(i+1),z[i],unc_z[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The luminosity distance $D_L$ to a galaxy is given by\n",
    "\n",
    "\\begin{align}\n",
    "D_L = (1+z)D_C,\n",
    "\\end{align}\n",
    "\n",
    "where $D_C$ is the comoving distance given by\n",
    "\n",
    "\\begin{align}\n",
    "D_C = \\frac{c}{H_0}\\int^z_0 \\frac{dz'}{\\sqrt{\\Omega_m(1+z)^3 + \\Omega_\\Lambda}}\n",
    "\\end{align}\n",
    "\n",
    "For MIGHTEE, the cosmological constants used to initialise ```cosmo``` are $H_0$, $\\Omega_m$ and $\\Omega_\\Lambda$, and that is why $E(z)$ reduces to what it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection 1: 219.461 +\\- 1.902 Mpc\n",
      "Detection 4: 216.386 +\\- 1.879 Mpc\n",
      "Detection 5: 148.906 +\\- 1.385 Mpc\n",
      "Detection 7: 131.446 +\\- 1.263 Mpc\n",
      "Detection 8: 178.502 +\\- 1.598 Mpc\n",
      "Detection 10: 216.386 +\\- 1.879 Mpc\n",
      "Detection 11: 204.916 +\\- 1.793 Mpc\n",
      "Detection 12: 203.394 +\\- 1.782 Mpc\n",
      "Detection 13: 129.279 +\\- 1.248 Mpc\n",
      "Detection 14: 145.982 +\\- 1.364 Mpc\n",
      "Detection 17: 209.492 +\\- 1.827 Mpc\n",
      "Detection 18: 145.250 +\\- 1.359 Mpc\n",
      "Detection 19: 209.492 +\\- 1.827 Mpc\n",
      "Detection 20: 135.793 +\\- 1.293 Mpc\n",
      "Detection 21: 212.552 +\\- 1.850 Mpc\n",
      "Detection 22: 212.552 +\\- 1.850 Mpc\n",
      "Detection 23: 203.394 +\\- 1.782 Mpc\n",
      "Detection 24: 266.351 +\\- 2.259 Mpc\n",
      "Detection 25: 132.170 +\\- 1.268 Mpc\n",
      "Detection 30: 120.645 +\\- 1.190 Mpc\n",
      "Detection 31: 121.362 +\\- 1.195 Mpc\n",
      "Detection 33: 278.305 +\\- 2.351 Mpc\n",
      "Detection 34: 112.776 +\\- 1.138 Mpc\n",
      "Detection 37: 113.487 +\\- 1.143 Mpc\n",
      "Detection 39: 124.237 +\\- 1.214 Mpc\n",
      "Detection 40: 148.906 +\\- 1.385 Mpc\n",
      "Detection 48: 272.717 +\\- 2.308 Mpc\n",
      "Detection 49: 149.639 +\\- 1.390 Mpc\n",
      "Detection 54: 208.162 +\\- 1.817 Mpc\n"
     ]
    }
   ],
   "source": [
    "# Cosmology parameters based on MIGHTEE\n",
    "H0 = 67.4 # km/s/Mpc\n",
    "unc_H0 = 0.54 #*u.km/u.s/u.Mpc # Uncertainty in the Hubble constant https://arxiv.org/pdf/1807.06209.pdf\n",
    "h = H0/100\n",
    "Om0 = 0.315\n",
    "Ode0 = 0.685\n",
    "\n",
    "cosmo = LambdaCDM(H0, Om0, Ode0)\n",
    "\n",
    "# Calculate the luminosity distance\n",
    "D = [(cosmo.comoving_distance(redshift))*(1 + redshift) for redshift in z]\n",
    "    \n",
    "# Calculate the uncertainty in D\n",
    "unc_D = [D[i]*np.sqrt(pow(dv_det[i]/central_vel[i],2) + pow(unc_H0/H0,2)) for i in range(len(detections))]\n",
    "\n",
    "\n",
    "# Display the Hubble distances\n",
    "for i in range(len(D)):\n",
    "    print(\"Detection %d: %.3f +\\- %.3f Mpc\"%(dets[i],D[i].value,unc_D[i].value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2. HI Mass\n",
    "In order to calculate the HI mass $M_\\text{HI}$, we need to use the formula\n",
    "\n",
    "\\begin{equation}\n",
    "\\left(\\frac{M_\\text{HI}}{\\text{M}_\\odot}\\right) \\approx \\frac{2.36 \\times 10^5}{(1+z)^2} \\left(\\frac{D_L}{\\text{Mpc}}\\right)^2 \\int\\left[\\frac{S(\\nu)}{\\text{Jy}}\\right]\\left(\\frac{dv}{\\text{km/s}}\\right) \\\\\n",
    "\\end{equation}\n",
    "\n",
    "where $\\int S(\\nu)dv$ over the line is called the line flux and is in units of Jy km $\\text{s}^{-1}$. However, we need only calculate the HI mass of the detection and not the whole spectrum. So let us define the limits of the profile, where the x-values are now in terms of velocity (km/s) and not frequency (MHz). However, since we already found the limits in terms of frequencies, we can flip `index_a` and `index_b` for the velocities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_a = findex_b\n",
    "index_b = findex_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hi_mass_vel(DL, S, unmasked_S, z, vel_array, vel_lower, vel_upper, v_diff):\n",
    "    '''\n",
    "    DL is the list of luminosity distances in Mpc\n",
    "    S is the list of masked fluxes in Jy\n",
    "    unmasked_S is the list of unmasked fluxes in Jy\n",
    "    vel_arr is the array of velocities for each subcube in km/s\n",
    "    vel_lower is the list of lower limits for each profile\n",
    "    vel_upper is the list of upper limits for each profile\n",
    "    v_diff is the channel width in terms of velocity\n",
    "    '''\n",
    "    HI_mass = [] # List to store Mhi for each detection\n",
    "    HI_mass_err = [] # List to store errors in Mhi\n",
    "    line_flux = [] # List to store the line fluxes in km/s\n",
    "    line_flux_err = [] # List to store errors in line fluxes\n",
    "    \n",
    "    # Loop through each data cube\n",
    "    for i in range(len(detections)):\n",
    "        # HI mass\n",
    "        M = detections[i]['MHI(1e9)']*1e9\n",
    "        HI_mass.append(M*u.M_sun)\n",
    "        \n",
    "        # Integrated flux\n",
    "        Sdv = 0 # Initialise line flux\n",
    "        \n",
    "        # Loop through data in each cube to calculate the line flux\n",
    "        for j in range(vel_lower[i], vel_upper[i]+1):\n",
    "            # Velocity width\n",
    "            dv = v_diff[i].value\n",
    "            \n",
    "            # Calculate the integral\n",
    "            Sdv += S[i][j].value*dv\n",
    "           \n",
    "        # Sdv = (M*pow(1+z[i], 2))/(2.365*1e5*pow(D[i].value, 2))\n",
    "        line_flux.append(Sdv*u.Jy*u.km/u.s) # Masked line flux\n",
    "        \n",
    "        # Calculate the error in the line flux from unmasked fluxes\n",
    "        # Flux from off-emission channels \n",
    "        off_flux = np.array(unmasked_S[i].value[0:vel_lower[i]].tolist() + unmasked_S[i].value[vel_upper[i]:-1].tolist())\n",
    "        \n",
    "        # Calculate the std deviation of off-emission channels\n",
    "        std_off_flux = np.std(off_flux)\n",
    "        \n",
    "        # Error in integrated flux\n",
    "        line_err = (std_off_flux*np.sqrt(len(unmasked_S[i]))*v_diff[i].value)\n",
    "        line_flux_err.append(line_err*u.Jy*u.km/u.s)\n",
    "        \n",
    "        # Calculate the HI mass error\n",
    "        M_err = ((2.356*(10**5))/pow(1+z[i],2))*pow(DL[i].value,2)*line_err\n",
    "        HI_mass_err.append(M_err*u.M_sun)\n",
    "        \n",
    "    return HI_mass, HI_mass_err, line_flux, line_flux_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection 1: (0.9616 +/- 0.6842) x 10^9 Msol\n",
      "Detection 4: (5.1523 +/- 1.0717) x 10^9 Msol\n",
      "Detection 5: (2.9648 +/- 0.3672) x 10^9 Msol\n",
      "Detection 7: (0.6324 +/- 0.1467) x 10^9 Msol\n",
      "Detection 8: (2.0893 +/- 0.7856) x 10^9 Msol\n",
      "Detection 10: (1.1695 +/- 0.3027) x 10^9 Msol\n",
      "Detection 11: (0.3097 +/- 0.2962) x 10^9 Msol\n",
      "Detection 12: (1.8793 +/- 0.3064) x 10^9 Msol\n",
      "Detection 13: (1.7701 +/- 0.1476) x 10^9 Msol\n",
      "Detection 14: (4.8978 +/- 1.2177) x 10^9 Msol\n",
      "Detection 17: (5.3088 +/- 1.165) x 10^9 Msol\n",
      "Detection 18: (0.4295 +/- 0.2889) x 10^9 Msol\n",
      "Detection 19: (2.8249 +/- 0.8586) x 10^9 Msol\n",
      "Detection 20: (0.7943 +/- 1.5659) x 10^9 Msol\n",
      "Detection 21: (6.1944 +/- 4.5715) x 10^9 Msol\n",
      "Detection 22: (9.6605 +/- 2.8759) x 10^9 Msol\n",
      "Detection 23: (5.8749 +/- 0.6854) x 10^9 Msol\n",
      "Detection 24: (0.3199 +/- 1.2601) x 10^9 Msol\n",
      "Detection 25: (1.3062 +/- 0.1441) x 10^9 Msol\n",
      "Detection 30: (3.8548 +/- 1.6109) x 10^9 Msol\n",
      "Detection 31: (0.7447 +/- 0.4355) x 10^9 Msol\n",
      "Detection 33: (1.6711 +/- 1.2723) x 10^9 Msol\n",
      "Detection 34: (0.4227 +/- 0.1117) x 10^9 Msol\n",
      "Detection 37: (0.6501 +/- 0.1242) x 10^9 Msol\n",
      "Detection 39: (1.0889 +/- 0.6824) x 10^9 Msol\n",
      "Detection 40: (0.0824 +/- 0.145) x 10^9 Msol\n",
      "Detection 48: (7.1285 +/- 32.2964) x 10^9 Msol\n",
      "Detection 49: (0.6412 +/- 0.7084) x 10^9 Msol\n",
      "Detection 54: (0.5546 +/- 0.6043) x 10^9 Msol\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HI_mass1330_vel, HI_mass1330_vel_err, line_jykms, line_jykms_err = hi_mass_vel(D, flux, unmasked_flux, z, vel, index_a, index_b, dv_det)\n",
    "\n",
    "[print('Detection %d: ('%(dets[i])+str(round(HI_mass1330_vel[i].value/1e9, 4))+' +/- '+str(round(HI_mass1330_vel_err[i].value/1e9, 4))\n",
    " +') x 10^9 Msol') for i in range(len(HI_mass1330_vel))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection 1: (8.983 +/- 0.3088) log(Msol)\n",
      "Detection 4: (9.712 +/- 0.0903) log(Msol)\n",
      "Detection 5: (9.472 +/- 0.0537) log(Msol)\n",
      "Detection 7: (8.801 +/- 0.1006) log(Msol)\n",
      "Detection 8: (9.32 +/- 0.1632) log(Msol)\n",
      "Detection 10: (9.068 +/- 0.1123) log(Msol)\n",
      "Detection 11: (8.491 +/- 0.415) log(Msol)\n",
      "Detection 12: (9.274 +/- 0.0708) log(Msol)\n",
      "Detection 13: (9.248 +/- 0.0362) log(Msol)\n",
      "Detection 14: (9.69 +/- 0.1079) log(Msol)\n",
      "Detection 17: (9.725 +/- 0.0952) log(Msol)\n",
      "Detection 18: (8.633 +/- 0.2919) log(Msol)\n",
      "Detection 19: (9.451 +/- 0.1319) log(Msol)\n",
      "Detection 20: (8.9 +/- 0.8556) log(Msol)\n",
      "Detection 21: (9.792 +/- 0.3203) log(Msol)\n",
      "Detection 22: (9.985 +/- 0.1292) log(Msol)\n",
      "Detection 23: (9.769 +/- 0.0506) log(Msol)\n",
      "Detection 24: (8.505 +/- 1.7096) log(Msol)\n",
      "Detection 25: (9.116 +/- 0.0479) log(Msol)\n",
      "Detection 30: (9.586 +/- 0.1814) log(Msol)\n",
      "Detection 31: (8.872 +/- 0.2538) log(Msol)\n",
      "Detection 33: (9.223 +/- 0.3304) log(Msol)\n",
      "Detection 34: (8.626 +/- 0.1147) log(Msol)\n",
      "Detection 37: (8.813 +/- 0.0829) log(Msol)\n",
      "Detection 39: (9.037 +/- 0.272) log(Msol)\n",
      "Detection 40: (7.916 +/- 0.7637) log(Msol)\n",
      "Detection 48: (9.853 +/- 1.9663) log(Msol)\n",
      "Detection 49: (8.807 +/- 0.4795) log(Msol)\n",
      "Detection 54: (8.744 +/- 0.4729) log(Msol)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print('Detection %d: ('%(dets[i])+str(round(math.log(HI_mass1330_vel[i].value, 10),4))+' +/- '\n",
    " +str(round(0.434*HI_mass1330_vel_err[i].value/HI_mass1330_vel[i].value, 4))+') log(Msol)') for i in range(len(HI_mass1330_vel))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection 1: (0.1222 +/- 0.0662) Jy km/s\n",
      "Detection 4: (0.4299 +/- 0.1065) Jy km/s\n",
      "Detection 5: (0.5362 +/- 0.075) Jy km/s\n",
      "Detection 7: (0.1588 +/- 0.0381) Jy km/s\n",
      "Detection 8: (0.2244 +/- 0.113) Jy km/s\n",
      "Detection 10: (0.1081 +/- 0.0301) Jy km/s\n",
      "Detection 11: (0.0296 +/- 0.0327) Jy km/s\n",
      "Detection 12: (0.1882 +/- 0.0343) Jy km/s\n",
      "Detection 13: (0.3669 +/- 0.0396) Jy km/s\n",
      "Detection 14: (1.1404 +/- 0.2583) Jy km/s\n",
      "Detection 17: (0.4276 +/- 0.1232) Jy km/s\n",
      "Detection 18: (0.0862 +/- 0.0619) Jy km/s\n",
      "Detection 19: (0.1785 +/- 0.0908) Jy km/s\n",
      "Detection 20: (0.1681 +/- 0.3823) Jy km/s\n",
      "Detection 21: (0.4622 +/- 0.4701) Jy km/s\n",
      "Detection 22: (0.7378 +/- 0.2957) Jy km/s\n",
      "Detection 23: (0.4832 +/- 0.0767) Jy km/s\n",
      "Detection 24: (0.0404 +/- 0.0843) Jy km/s\n",
      "Detection 25: (0.1725 +/- 0.0371) Jy km/s\n",
      "Detection 30: (0.6309 +/- 0.4951) Jy km/s\n",
      "Detection 31: (0.1235 +/- 0.1323) Jy km/s\n",
      "Detection 33: (0.0643 +/- 0.0783) Jy km/s\n",
      "Detection 34: (0.1007 +/- 0.0392) Jy km/s\n",
      "Detection 37: (0.1539 +/- 0.043) Jy km/s\n",
      "Detection 39: (0.2113 +/- 0.1981) Jy km/s\n",
      "Detection 40: (0.0136 +/- 0.0296) Jy km/s\n",
      "Detection 48: (3.4972 +/- 2.066) Jy km/s\n",
      "Detection 49: (0.2212 +/- 0.1432) Jy km/s\n",
      "Detection 54: (0.0301 +/- 0.0647) Jy km/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print('Detection %d: ('%(dets[i])+str(round(line_jykms[i].value ,4))+' +/- '+str(round(line_jykms_err[i].value, 4))+\n",
    " ') Jy km/s') for i in range(len(line_jykms))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing the results to a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the masses and errors to a text file\n",
    "# Create the text file\n",
    "mass_txt = open(analysis_res+'masked_profile_HImasses.txt', 'w+')\n",
    "\n",
    "# Loop through each detection\n",
    "for i in range(len(detections)): \n",
    "    mass_txt.write('%d %f %f %f %f\\n'%(dets[i], math.log(HI_mass1330_vel[i].value, 10), 0.434*HI_mass1330_vel_err[i].value/HI_mass1330_vel[i].value, central_vel[i].value, vel_unc[i].value))\n",
    "        \n",
    "mass_txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the redshifts and errors to a text file\n",
    "# Create the text file\n",
    "z_txt = open(analysis_res+'COSMOS_1330_redshifts.txt', 'w+')\n",
    "\n",
    "# Loop through each detection\n",
    "for i in range(len(detections)):\n",
    "    det = detections[i]['Detection'] # Detection number\n",
    "    \n",
    "    z_txt.write('%d %f %f %f %f\\n'%(det,z[i],unc_z[i], D[i].value, unc_D[i].value))\n",
    "\n",
    "z_txt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_a = findex_b\n",
    "index_b = findex_a\n",
    "\n",
    "# Loop through each detection\n",
    "for i in range(len(detections)):\n",
    "    # Create the text file\n",
    "    f = open(analysis_res+'COSMOS_1330_masked_detection'+str(dets[i])+'_profile_vel.txt', 'w+')\n",
    "    \n",
    "    # Write the central velocity\n",
    "    f.write('%s %f %f\\n'%('CVel', central_vel[i].value, vel_unc[i].value))\n",
    "    \n",
    "    # Write indices strict to where emission is\n",
    "    #f.write('%s %i %i\\n'%('Indices', index_a[i], index_b[i]))\n",
    "    \n",
    "    # Write the integrated fluxes\n",
    "    f.write('%s %f %f\\n'%('Sdv', line_jykms[i].value, line_jykms_err[i].value))\n",
    "    \n",
    "    # Loop through each channel\n",
    "    for j in range(len(masked_subcubes_vel[i])):\n",
    "        f.write('%f %f %f\\n'%(vel[i][j].value, flux[i][j].value, flux_err[i][j].value))\n",
    "        \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ASTRO-PY3",
   "language": "python",
   "name": "astro-py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
