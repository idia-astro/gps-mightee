{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIGHTEE-HI Data: Calculating $W_{50}$\n",
    "***\n",
    "By Wanga Mulaudzi \n",
    "\n",
    "<b>Date:</b> 1 August 2021\n",
    "<br>\n",
    "<b>Affiliation:</b> Department of Astronomy, University of Cape Town, Private Bag X3, Rondebosch 7701, South Africa\n",
    "<br>\n",
    "<b>Contact:</b> MLDWAN001@myuct.ac.za\n",
    "<br>\n",
    "<b>Ilifu Jupyter Kernel:</b> PyMultiNest\n",
    "\n",
    "This notebook reads in text files created by the `Step2_Masked_Profiles_COSMOS_1330.ipynb` notebook and then fits a Busy Function using ```PyMultiNest``` (see http://johannesbuchner.github.io/pymultinest-tutorial/index.html).\n",
    "\n",
    "To find the width at $20\\%$ and $50\\%$, we have to decipher if the profile is double horned or not, and based on that, we can find the widths. Since the data from this particular cube is very low resolution, the best width to calculate is $W_{50}$, else we would be reaching into the noise of the profile.\n",
    "\n",
    "The busy function is defined as\n",
    "\n",
    "\\begin{align}\n",
    "B(x) = \\frac{a}{4}[\\text{erf}(b_1\\{w+x-x_e\\})+1]\\times[\\text{erf}(b_2\\{w-x+x_e\\})+1]\\times [c|x-x_p|^n+1], \\\\\n",
    "\\end{align}\n",
    "\n",
    "where $\\text{erf}(x) = \\frac{2}{\\sqrt{\\pi}}\\int^x_0\\text{exp}(-t^2)\\text{d}t$ is the gaussian error function, $a$ is the scaling factor, $b_1$ and $b_2$ the steepness of the line flanks, $w$ the half-width of the profile, $x_e$ and $x_p$ the centroid of the error functions/polynomial, $c$ the scaling factor of the polynomial trough, and $n$ the order of the polynomial (see https://www.astron.nl/phiscc2014/Documents/Techniques/Westmeier_Busy_Function_phiscc2014.pdf for more details). The diagram below further illustrates the different parameters.\n",
    "\n",
    "![BF.png](BF.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "from astropy.io import ascii\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "import matplotlib.ticker as mtick\n",
    "import numpy as np\n",
    "from numpy import log, exp, pi\n",
    "import os\n",
    "import pymultinest\n",
    "import pylab as pl\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initiate parameters for plotting\n",
    "# pl.rc('axes',titlesize='large')\n",
    "# pl.rc('text', usetex=False)\n",
    "# pl.rc('font', **{'family':'serif','size':20})\n",
    "# pl.rc('axes', labelsize=16)\n",
    "# pl.rc('xtick',labelsize=16)\n",
    "# pl.rc('ytick',labelsize=16)\n",
    "\n",
    "# plt.rcParams['mathtext.fontset'] = 'custom'\n",
    "# plt.rcParams['mathtext.rm'] = 'serif'\n",
    "# plt.rcParams['font.family'] = 'serif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. User Inputs and Creating a Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your detection file list in an ASCII table format (e.g xxx.dat)\n",
    "detections_list = 'COSMOS123_1330_catalogue_notes.txt'\n",
    "detections = ascii.read(detections_list)\n",
    "\n",
    "# Path for new 'analysis_output' directory that will be created\n",
    "dirName = 'analysis_output/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Busy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the busy function model\n",
    "def Bmodel(a, b1, b2, w, xe, xp, c, n):\n",
    "    '''\n",
    "    x is the list of x-values\n",
    "    a is the scaling factor\n",
    "    b1 is the steepness of the first flank\n",
    "    b2 is the steepness of the second flank\n",
    "    w is half the FWHM\n",
    "    xe is the center of the error function\n",
    "    xp is the center of the polynomial\n",
    "    c is the scaling factor of the polynomial trough\n",
    "    n is the order of the polynomial\n",
    "    '''\n",
    "    return (a/4.)*(sp.special.erf(b1*(w+vel-xe))+1)*(sp.special.erf(b2*(w-vel+xe))+1)*(c*pow(abs(vel-xp),n)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the busy function model for the model solutions that take in new x\n",
    "def Bmodelx(x, a, b1, b2, w, xe, xp, c, n):\n",
    "    '''\n",
    "    x is the list of x-values\n",
    "    a is the scaling factor\n",
    "    b1 is the steepness of the first flank\n",
    "    b2 is the steepness of the second flank\n",
    "    w is half the FWHM\n",
    "    xe is the center of the error function\n",
    "    xp is the center of the polynomial\n",
    "    c is the scaling factor of the polynomial trough\n",
    "    n is the order of the polynomial\n",
    "    '''\n",
    "    return (a/4.)*(sp.special.erf(b1*(w+x-xe))+1)*(sp.special.erf(b2*(w-x+xe))+1)*(c*pow(abs(x-xp),n)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The prior and the log likelihood functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prior that transforms the unit cube into the parameter cube that is now in log space\n",
    "# parameters are a, b1, b2, w, xe, xp, c, n\n",
    "# uniform priors span one order of magnitude\n",
    "# log-uniform priors span multiple orders of magnitude. Should be written in powers of 10\n",
    "def prior(cube, ndim, nparams):\n",
    "    cube[0] = cube[0] # uniform prior for a between 0*1=0 and 1*1=1\n",
    "    cube[1] = cube[1] # uniform prior for b1 between 0*1=0 and 1*1=1\n",
    "    cube[2] = cube[2] # uniform prior for b2 between 0*1=0 and 1*1=1\n",
    "    cube[3] = 10**(cube[3]*3) # log-uniform prior for w between 10**(0*3)=1 and 10**(1*3)=1e3\n",
    "    cube[4] = -cube[4]*600 + 300 # uniform prior for xe between -0*600+300=300 and -1*600+300=-300\n",
    "    cube[5] = -cube[5]*600 + 300 # uniform prior for xp between -0*600+300=300 and -1*600+300=-300\n",
    "    cube[6] = 10**(-cube[6]*2 - 7) # log-uniform prior for c between 10**(-0*2-7)=1e-7 and 10**(-1*2-7)=1e-9\n",
    "    cube[7] = 6*cube[7] + 2 # log-uniform prior for n between 6(0)+2=2 and 6(1)+2=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loglike function which returns the logarithm of the likelihood (least squares)\n",
    "def loglike(cube, ndim, nparams):\n",
    "    # Assign each of the parameters\n",
    "    a, b1, b2, w, xe, xp, c, n = cube[0], cube[1], cube[2], cube[3], cube[4], cube[5], cube[6], cube[7]\n",
    "    \n",
    "    # Evaluate the velocity data with the parameters\n",
    "    fluxmodel = Bmodel(a, b1, b2, w, xe, xp, c, n)\n",
    "    \n",
    "    flux2 = np.array(phi) # converting flux from a list to an array\n",
    "    noise2 = np.array(noise)\n",
    "    \n",
    "    # Calculate the sum of squares normalised by the residuals\n",
    "    chi2 = (((fluxmodel_model - fluxdata) / noise2)**2).sum()\n",
    "\n",
    "    # The log likelihood function\n",
    "    loglikelihood = -((np.log(2*np.pi*noise2**2)).sum())/2 - chi2/2 # since noise is not constant, the sum over sigma is not just N=len(flux2)\n",
    "\n",
    "    return loglikelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Running PyMultiNest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to create a list to store all the data itself\n",
    "# for plotting the model solutions later on\n",
    "all_flux = []\n",
    "all_flux_err = []\n",
    "all_max_flux = []\n",
    "all_vel = []\n",
    "all_cvel = []\n",
    "all_sdv = []\n",
    "all_sdv_err = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to Step2_Masked_profiles_COSMOS_1330.ipynb file output\n",
    "path_to_data = ''\n",
    "\n",
    "# Loop through each detection\n",
    "for i in range(len(detections)):\n",
    "    # Create a directory for detection i's results\n",
    "    directory_i = dirName+'detection_'+str(detections[i]['Detection'])+'/'\n",
    "    \n",
    "    if not os.path.exists(directory_i):\n",
    "        os.makedirs(directory_i)\n",
    "    else:\n",
    "        shutil.rmtree(directory_i)\n",
    "        os.makedirs(directory_i)\n",
    "        \n",
    "    # Read in the data\n",
    "    txt_file = path_to_data+'COSMOS_1330_masked_detection'+str(detections[i]['Detection'])+'_profile_vel.txt'\n",
    "    \n",
    "    data = np.genfromtxt(txt_file, delimiter=' ').T\n",
    "    cvel = data[1][0]\n",
    "    vel = data[0][2:] - cvel\n",
    "    fluxdata = data[1][2:]/max(data[1][2:])\n",
    "    fluxerr = data[2][2:]/max(data[1][2:])\n",
    "    intflux = data[1][1]\n",
    "    intfluxerr = data[2][1]\n",
    "    \n",
    "    # Save the data\n",
    "    all_flux.append(fluxdata)\n",
    "    all_flux_err.append(fluxerr)\n",
    "    all_max_flux.append(max(data[1][2:]))\n",
    "    all_vel.append(vel)\n",
    "    all_cvel.append(cvel)\n",
    "    all_sdv.append(intflux)\n",
    "    all_sdv_err.append(intfluxerr)\n",
    "    \n",
    "    noise = fluxerr\n",
    "    \n",
    "    # Number of dimensions our problem has\n",
    "    parameters = [r'$a$', r'$b_1$', r'$b_2$', r'$w$', r'$x_e$', r'$x_p$', r'$c$', r'$n$']\n",
    "    n_params = len(parameters)\n",
    "    \n",
    "    # Run PyMultiNest\n",
    "    pymultinest.run(loglike, prior, n_params, outputfiles_basename='detection_'+str(detections[i]['Detection']), resume=False, verbose=True)\n",
    "    json.dump(parameters, open(directory_i+'/params.json', 'w')) # Save the parameters\n",
    "    \n",
    "    # plot the distribution of a posteriori possible models\n",
    "    pl.figure(figsize=(15,7)) \n",
    "    pl.step(vel, fluxdata, '-', color='black', where='mid')\n",
    "    pl.errorbar(vel, fluxdata, yerr=fluxerr, fmt='', marker=None, ls='none', color='k')\n",
    "    pl.xlabel(r'Velocity [km s$^{-1}$]', fontsize=28)\n",
    "    pl.ylabel('Normalized Flux Density', fontsize=28)\n",
    "    pl.gca().tick_params(axis='both', labelsize=28)\n",
    "    pl.tight_layout()\n",
    "    \n",
    "    # Plot the distribution of a posteriori possible models\n",
    "    # Modelx is just a linear space of the velocities\n",
    "    modelx = np.linspace(min(vel), max(vel), 1000)\n",
    "\n",
    "    an = pymultinest.Analyzer(outputfiles_basename='detection_'+str(detections[i]['Detection']), n_params = n_params)\n",
    "    \n",
    "    # Loop through each possible model and plot it\n",
    "    for (a, b1, b2, w, xe, xp, c, n) in an.get_equal_weighted_posterior()[::100,:-1]:\n",
    "        pl.plot(modelx, Bmodelx(modelx, a, b1, b2, w, xe, xp, c, n), '-', color='red', alpha=0.3)\n",
    "        \n",
    "        # Axes parameters\n",
    "        pl.gca().xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        pl.gca().yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        pl.gca().tick_params(axis='both', which='major', direction='in', length=10, top=True, right=True)\n",
    "        pl.gca().tick_params(axis='both', which='minor', direction='in', length=5, top=True, right=True)\n",
    "\n",
    "    pl.savefig(directory_i+'posterior'+str(detections[i]['Detection'])+'.png')\n",
    "    pl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyMultiNest dumps all the output where the notebook is located so we need to re-organize everything. May need to run this cell twice if errors arise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to where the MultiNest data dump is\n",
    "source = ''\n",
    "\n",
    "# Read in all the files in the directory\n",
    "files = os.listdir(source)\n",
    "\n",
    "# Detections with two digit numbers confuse python so sort detections in reverse order\n",
    "rev_det = [detections[i]['Detection'] for i in range(len(detections))][::-1]\n",
    "\n",
    "# Loop through each detection\n",
    "for i in rev_det:\n",
    "    # Path to detection folder\n",
    "    dest = dirName+'detection_'+str(i) \n",
    "    \n",
    "    # Loop through all the files\n",
    "    for file in files:\n",
    "        if (file.startswith('detection_'+str(i))):\n",
    "            shutil.move(file, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Marginals and best parameters plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store median and average parameters for each profile\n",
    "med_best_par_list = []\n",
    "av_best_par_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store 3 sigma values for a\n",
    "three_sigma_a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the marginal plots for each detection\n",
    "for d in range(len(detections)):\n",
    "    # Path to detection folder\n",
    "    dest = dirName+'detection_'+str(detections[d]['Detection'])+'/'\n",
    "    \n",
    "    # Load the parameters\n",
    "    params = json.load(open(dest+'params.json'))\n",
    "    n_params = len(params)\n",
    "    \n",
    "    # Create the analyzer object\n",
    "    an = pymultinest.Analyzer(n_params = n_params, outputfiles_basename = dest+'detection_'+str(detections[d]['Detection']))\n",
    "    \n",
    "    # Get a dictionary containing information about the logZ and its errors,\n",
    "    # the individual modes and their parameters, quantiles of the parameter posteriors\n",
    "    stats = an.get_stats()\n",
    "    \n",
    "    # get the best fit (highest likelihood) point\n",
    "    bestfit_params_dict = an.get_best_fit()\n",
    "    bestfit_params = bestfit_params_dict.get('parameters')\n",
    "    \n",
    "    json.dump(stats, open(dest+'stats.json', 'w+'))\n",
    "    \n",
    "    # Create the marginal plot\n",
    "    p = pymultinest.PlotMarginal(an)\n",
    "    \n",
    "    values = an.get_equal_weighted_posterior()\n",
    "    assert n_params == len(stats['marginals'])\n",
    "    modes = stats['modes']\n",
    "    \n",
    "    # Dimensionality of the plot\n",
    "    dim2 = os.environ.get('D', '1' if n_params > 20 else '2') == '2'\n",
    "    nbins = 100 if n_params < 3 else 20\n",
    "    \n",
    "    # Set up grid layout\n",
    "    params_count2 = [0, 1, 2, 3, 4, 5, 6] # Grid for j\n",
    "    params_count_indx = 0\n",
    "    \n",
    "    if dim2:\n",
    "        plt.figure(figsize=(27*n_params, 27*n_params))\n",
    "        #for i in range(n_params):\n",
    "        for i in range(1, n_params+1, 1):\n",
    "            stepsizes = [0.1, 0.35, 0.35, 10, 10, 50, 4e-8, 0.4]\n",
    "            axis_formatters = ['%0.1f', '%0.1f', '%0.1f', '%d', '%d', '%d', '%.1e', '%0.1f']\n",
    "            \n",
    "            plt.subplot(n_params, n_params, (1 + 9*(i-1)))\n",
    "            plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "            \n",
    "            plt.xlabel(parameters[i-1], fontsize=200)\n",
    "\n",
    "            m = stats['marginals'][i-1]\n",
    "            \n",
    "            # Store 3 sigma range for a\n",
    "            if i-1 == 0:\n",
    "                three_sigma_a.append(m['3sigma'])\n",
    "            \n",
    "            plt.xlim(m['5sigma'])\n",
    "            plt.xticks(rotation=40)\n",
    "\n",
    "            oldax = plt.gca()\n",
    "            x,w,patches = oldax.hist(values[:,i-1], bins=nbins, edgecolor='grey', color='grey', histtype='stepfilled', alpha=0.2)\n",
    "            oldax.set_ylim(0, x.max())\n",
    "            oldax.tick_params(axis='both', length=30, direction='in', top=True, right=True, pad=30)\n",
    "            oldax.tick_params(axis='x', labelbottom=False, labeltop=True)\n",
    "            \n",
    "            startax, endax = oldax.get_xlim()\n",
    "            oldax.xaxis.set_ticks(np.arange(startax, endax, stepsizes[i-1]))\n",
    "            oldax.xaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[i-1])) \n",
    "            oldax.xaxis.set_label_position('top')\n",
    "            \n",
    "            plt.setp(oldax.get_xticklabels(), fontsize=160)\n",
    "            plt.setp(oldax.get_yticklabels(), fontsize=160)\n",
    "            plt.setp(oldax.xaxis.get_majorticklabels(), rotation=40, fontsize=160)\n",
    "            plt.setp(oldax.yaxis.get_majorticklabels(), fontsize=160)\n",
    "\n",
    "            newax = plt.gcf().add_axes(oldax.get_position(), sharex=oldax, frameon=False)\n",
    "            newax.tick_params(axis='x', labelbottom=False, labeltop=True)\n",
    "            plt.setp(newax.get_xticklabels(), fontsize=160)\n",
    "            plt.setp(newax.get_yticklabels(), fontsize=160)\n",
    "            p.plot_marginal(i-1, ls='-', color='blue', linewidth=3)\n",
    "            newax.set_ylim(0, 1)\n",
    "\n",
    "            ylim = newax.get_ylim()\n",
    "            y = ylim[0] + 0.05*(ylim[1] - ylim[0])\n",
    "            center = m['median']\n",
    "            low1, high1 = m['1sigma']\n",
    "            #print(center, low1, high1)\n",
    "            newax.errorbar(x=center, y=y,\n",
    "                xerr=np.transpose([[center - low1, high1 - center]]), \n",
    "                color='blue', linewidth=2, marker='s')\n",
    "            oldax.set_yticks([])\n",
    "            #newax.set_yticks([])\n",
    "            oldax.tick_params(axis='both', length=30, direction='in', right=True)\n",
    "            newax.tick_params(axis='both', length=30, direction='in', right=True, pad=30)\n",
    "            newax.yaxis.set_label_position('right')\n",
    "            newax.xaxis.set_label_position('top')\n",
    "            newax.yaxis.set_ticks(np.arange(0.2, 1.2, 0.2))\n",
    "            newax.tick_params(axis='y', labelleft=False, labelright=True)\n",
    "            newax.set_ylabel(\"Probability\", fontsize=200, labelpad=30)\n",
    "            plt.setp(newax.xaxis.get_majorticklabels(), rotation=40, fontsize=160)\n",
    "            plt.setp(newax.yaxis.get_majorticklabels(), fontsize=160)\n",
    "            ylim = oldax.get_ylim()\n",
    "            newax.set_xlim(m['5sigma'])\n",
    "            oldax.set_xlim(m['5sigma'])\n",
    "            #plt.close()\n",
    "            \n",
    "            if i == n_params:\n",
    "                break\n",
    "                \n",
    "            #for j in range(i):\n",
    "            for j in range(params_count2[params_count_indx], n_params-1):\n",
    "                stepsizes = [0.05, 0.4, 0.35, 10, 20, 40, 4e-8, 0.4]\n",
    "                axis_formatters = ['%0.2f', '%0.1f', '%0.1f', '%d', '%d', '%d', '%.1e', '%0.1f']\n",
    "            \n",
    "                plt.subplot(n_params, n_params, ((n_params + i) + j*n_params))\n",
    "                p.plot_conditional(i-1, j+1, bins=20, cmap = pl.cm.gray_r)\n",
    "                for m in modes:\n",
    "                    plt.errorbar(x=bestfit_params[i-1], y=bestfit_params[j+1], xerr=m['sigma'][i-1], yerr=m['sigma'][j+1])\n",
    "                    \n",
    "                    ########\n",
    "                if j == 6 and i != 1:\n",
    "                    plt.xlabel(parameters[i-1], fontsize=200)\n",
    "                    \n",
    "                    # x axis\n",
    "                    startax, endax = plt.gca().get_xlim()\n",
    "                    plt.gca().xaxis.set_ticks(np.arange(startax, endax, stepsizes[i-1]))\n",
    "                    plt.gca().xaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[i-1])) \n",
    "        \n",
    "                    # y axis\n",
    "                    startay, enday = plt.gca().get_ylim()\n",
    "                    plt.gca().yaxis.set_ticks(np.arange(startay, enday, stepsizes[j+1]))\n",
    "                    plt.gca().yaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[j+1])) \n",
    "                    \n",
    "                    plt.gca().axes.tick_params(axis='x', labelbottom=True)\n",
    "                    plt.gca().axes.tick_params(axis='y', labelleft=False)\n",
    "                    plt.gca().axes.tick_params(axis='both', length=20, direction='in', top=True, right=True, pad=30)\n",
    "                elif i == 1 and j != 6:\n",
    "                    plt.ylabel(parameters[j+1], fontsize=200)\n",
    "                    # x axis\n",
    "                    startax, endax = plt.gca().get_xlim()\n",
    "                    plt.gca().xaxis.set_ticks(np.arange(startax, endax, stepsizes[i-1]))\n",
    "                    plt.gca().xaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[i-1])) \n",
    "        \n",
    "                    # y axis\n",
    "                    startay, enday = plt.gca().get_ylim()\n",
    "                    plt.gca().yaxis.set_ticks(np.arange(startay, enday, stepsizes[j+1]))\n",
    "                    plt.gca().yaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[j+1])) \n",
    "                    \n",
    "                    plt.gca().axes.tick_params(axis='x', labelbottom=False)\n",
    "                    plt.gca().axes.tick_params(axis='y', labelleft=True)\n",
    "                    plt.gca().axes.tick_params(axis='both', length=20, direction='in', top=True, right=True, pad=30)\n",
    "                elif i == 1 and j == 6:\n",
    "                    plt.xlabel(parameters[i-1], fontsize=200)\n",
    "                    plt.ylabel(parameters[j+1], fontsize=200)\n",
    "                    \n",
    "                    # x axis\n",
    "                    startax, endax = plt.gca().get_xlim()\n",
    "                    plt.gca().xaxis.set_ticks(np.arange(startax, endax, stepsizes[i-1]))\n",
    "                    plt.gca().xaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[i-1])) \n",
    "        \n",
    "                    # y axis\n",
    "                    startay, enday = plt.gca().get_ylim()\n",
    "                    plt.gca().yaxis.set_ticks(np.arange(startay, enday, stepsizes[j+1]))\n",
    "                    plt.gca().yaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[j+1])) \n",
    "                    \n",
    "                    plt.gca().axes.tick_params(axis='x', labelbottom=True)\n",
    "                    plt.gca().axes.tick_params(axis='y', labelleft=True)\n",
    "                    plt.gca().axes.tick_params(axis='both', length=20, direction='in', top=True, right=True, pad=30)\n",
    "                else:   \n",
    "                    # x axis\n",
    "                    startax, endax = plt.gca().get_xlim()\n",
    "                    plt.gca().xaxis.set_ticks(np.arange(startax, endax, stepsizes[i-1]))\n",
    "                    plt.gca().xaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[i-1])) \n",
    "    \n",
    "                    # y axis\n",
    "                    startay, enday = plt.gca().get_ylim()\n",
    "                    plt.gca().yaxis.set_ticks(np.arange(startay, enday, stepsizes[j+1]))\n",
    "                    plt.gca().yaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[j+1])) \n",
    "                        \n",
    "                    plt.gca().axes.tick_params(axis='both', length=30, direction='in', top=True, right=True, pad=30)\n",
    "                    plt.gca().axes.tick_params(axis='x', labelbottom=False)\n",
    "                    plt.gca().axes.tick_params(axis='y', labelleft=False)\n",
    "                plt.xticks(rotation=40)\n",
    "                plt.setp(plt.gca().get_xticklabels(), fontsize=160)\n",
    "                plt.setp(plt.gca().get_yticklabels(), fontsize=160)\n",
    "                #plt.savefig('cond_%s_%s.pdf' % (params[i], params[j]), bbox_tight=True)\n",
    "                #plt.close()\n",
    "                \n",
    "            params_count_indx += 1\n",
    "        \n",
    "        plt.savefig(dest + 'marg'+str(detections[d]['Detection'])+'.pdf')\n",
    "        #plt.savefig(dest + 'marg'+str(detections[d]['Detection'])+'.png')\n",
    "        plt.close()\n",
    "    \n",
    "    '''\n",
    "    Storing the average parameter values\n",
    "    '''\n",
    "    # Open a text file to save the parameter results\n",
    "    av_results_txt = open(dest+'av_results_detection_'+str(detections[d]['Detection'])+'.txt', 'w+')\n",
    "\n",
    "    # List to store best parameters\n",
    "    av_best_par = []\n",
    "    \n",
    "    h = 0\n",
    "    for par in parameters:\n",
    "        av_results_txt.write('%s %.15f %.15f\\n' % (par, modes[0]['mean'][h], modes[0]['sigma'][h]))\n",
    "        av_best_par.append([modes[0]['mean'][h], modes[0]['sigma'][h]])\n",
    "        h+=1\n",
    "\n",
    "    av_results_txt.close()\n",
    "    av_best_par_list.append(av_best_par)\n",
    "    \n",
    "    '''\n",
    "    Choosing the median\n",
    "    '''\n",
    "    # Open a text file to save the parameter results_txt\n",
    "    med_results_txt = open(dest+'med_results_detection_'+str(detections[d]['Detection'])+'.txt', 'w+')\n",
    "    \n",
    "    # Write the marginal likelihood\n",
    "    med_results_txt.write('lnZ %.1f %.1f\\n'%(stats['global evidence'], stats['global evidence error']))\n",
    "    \n",
    "    # List to store best parameters\n",
    "    med_best_par = []\n",
    "    \n",
    "    # Write the parameters\n",
    "    for par, marg in zip(parameters, stats['marginals']):\n",
    "        # 1 sigma provides the lowest and highest estimates\n",
    "        lo, hi = marg['1sigma']\n",
    "        sigma = (hi - lo) / 2 # Calculate the error\n",
    "        \n",
    "        med = marg['median']\n",
    "        \n",
    "        if sigma == 0:\n",
    "            j = 3\n",
    "        else:\n",
    "            j = max(0, int(-np.floor(np.log10(sigma))) + 1)\n",
    "            \n",
    "        # Create the string to write    \n",
    "        fmt = '%%.%df' % j\n",
    "        fmts = '\\t'.join(['%-3s' + fmt + \" +- \" + fmt +'\\n'])\n",
    "        \n",
    "        med_results_txt.write('%s %.15f %.15f\\n' % (par, med, sigma))\n",
    "        \n",
    "        # Save the value and error for this parameter\n",
    "        med_best_par.append([med, sigma])\n",
    "    \n",
    "    med_results_txt.close()\n",
    "    med_best_par_list.append(med_best_par)\n",
    "    \n",
    "    '''\n",
    "    Model and integrated flux\n",
    "    '''\n",
    "    # The busy function with the best parameter\n",
    "    modelx = np.linspace(min(all_vel[d]), max(all_vel[d]), 1000)\n",
    "    modely = Bmodelx(modelx, med_best_par[0][0], med_best_par[1][0], med_best_par[2][0], med_best_par[3][0], \n",
    "                            med_best_par[4][0], med_best_par[5][0], med_best_par[6][0], med_best_par[7][0])\n",
    "    \n",
    "    # Integrated flux of data\n",
    "    Sdv_data = all_sdv[d]\n",
    "    Sdv_data_err = all_sdv_err[d]\n",
    "    \n",
    "    # Integrated flux of model\n",
    "    dvmodel = np.average(np.diff(modelx))\n",
    "    Sdv_model = np.sum(modely*dvmodel)*all_max_flux[d]\n",
    "    \n",
    "    '''\n",
    "    Plotting the median and mean parameters\n",
    "    '''\n",
    "    pl.figure(figsize=(15,7)) \n",
    "    pl.step(all_vel[d], all_flux[d], 'k', where='mid')\n",
    "    pl.errorbar(all_vel[d], all_flux[d], yerr=all_flux_err[d], fmt='', marker=None, ls='none', color='k')\n",
    "    pl.plot(modelx, modely, 'r-')\n",
    "#     pl.plot(modelx, Bmodelx(modelx, av_best_par[0][0], av_best_par[1][0], av_best_par[2][0], av_best_par[3][0], \n",
    "#                             av_best_par[4][0], av_best_par[5][0], av_best_par[6][0], av_best_par[7][0]), 'b-', \n",
    "#             alpha=0.5, label=r'Mean W$_{50}$ = %.2f $\\pm$ %.2f km/s'%(2*av_best_par[3][0], 2*av_best_par[3][1]))\n",
    "    pl.xlabel(r'Velocity [km s$^{-1}$]', fontsize=28)\n",
    "    pl.ylabel('Normalized Flux Density', fontsize=28)\n",
    "    pl.gca().tick_params(axis='both', labelsize=28)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Axes parameters\n",
    "    pl.gca().xaxis.set_minor_locator(AutoMinorLocator())\n",
    "    pl.gca().yaxis.set_minor_locator(AutoMinorLocator())\n",
    "    pl.gca().tick_params(axis='both', which='major', direction='in', length=10, top=True, right=True)\n",
    "    pl.gca().tick_params(axis='both', which='minor', direction='in', length=5, top=True, right=True)\n",
    "    #pl.legend(loc='upper right', fontsize=17)\n",
    "    \n",
    "    # Anchored text\n",
    "    textstr = '\\n'.join((\n",
    "    r'Med. W$_{50}$ = %.2f $\\pm$ %.2f km s$^{-1}$' % (2*med_best_par[3][0], 2*med_best_par[3][1], ),\n",
    "    r'$\\int S\\mathrm{dv}_\\mathrm{data}$ = %.3f $\\pm$ %.3f Jy km s$^{-1}$' % (Sdv_data, Sdv_data_err, ),\n",
    "    r'$\\int S\\mathrm{dv}_\\mathrm{model}$ = %.3f Jy km s$^{-1}$' % (Sdv_model, )))\n",
    "    pl.annotate(textstr, xy=(0.03, 0.7), xycoords='axes fraction', fontsize=17)\n",
    "    \n",
    "    pl.savefig(dest+'best_par'+str(detections[d]['Detection'])+'.png')\n",
    "    pl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to look at the marginals to see how each of the paramaters behave as a function of each other. We will have to modify the priors of $a$ for each profile to better constrain the fits.\n",
    "\n",
    "## Second run with modified priors for $a$ and $x_e$ fixed on median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/users/wanga/mightee/analysis/COSMOS_1330/masked_profiles_COSMOS_1330_output/'\n",
    "\n",
    "# Loop through each detection\n",
    "for i in range(len(detections)):\n",
    "    # Define the prior with a different paramater space for a\n",
    "    # Define the prior that transforms the unit cube into the parameter cube that is now in log space\n",
    "    # parameters are a, b1, b2, w, xe, xp, c, n\n",
    "    def prior(cube, ndim, nparams):\n",
    "        cube[0] = cube[0]*(three_sigma_a[i][1] - three_sigma_a[i][0]) + three_sigma_a[i][0] # modified prior for a within 3 sigma\n",
    "        cube[1] = cube[1] # log-uniform prior for b1 between 0 and 1\n",
    "        cube[2] = cube[2] # log-uniform prior for b2 between 0 and 1\n",
    "        cube[3] = 10**(cube[3]*3) # log-uniform prior for w between 10**(0*3)=1 and 10**(1*3)=1e3\n",
    "        cube[4] = med_best_par_list[i][4][0] # xe fixed on medians of first run\n",
    "        cube[5] = -cube[5]*600 + 300 # log-uniform prior for xp between -0*600+300=300 and -1*600+300=-300\n",
    "        cube[6] = 10**(-cube[6]*2 - 7) # log-uniform prior for c between 10**(-0*2-7)=1e-7 and 10**(-1*2-7)=1e-9\n",
    "        cube[7] = 6*cube[7] + 2 # log-uniform prior for n between 6(0)+2=2 and 6(1)+2=8\n",
    "    \n",
    "    # Create a directory for detection i's results\n",
    "    directory_i = dirName+'/detection_'+str(detections[i]['Detection'])+'/'\n",
    "    \n",
    "    vel = all_vel[i]\n",
    "    fluxdata = all_flux[i]\n",
    "    fluxerr = all_flux_err[i]\n",
    "    \n",
    "    noise = fluxerr\n",
    "    \n",
    "    # Number of dimensions our problem has\n",
    "    parameters = [r'$a$', r'$b_1$', r'$b_2$', r'$w$', r'$x_e$', r'$x_p$', r'$c$', r'$n$']\n",
    "    n_params = len(parameters)\n",
    "    \n",
    "    # Run PyMultiNest\n",
    "    pymultinest.run(loglike, prior, n_params, outputfiles_basename='mod_a_med_xe_detection_'+str(detections[i]['Detection']), resume=False, verbose=True)\n",
    "    json.dump(parameters, open(directory_i+'/mod_a_med_xe_params.json', 'w')) # Save the parameters\n",
    "    \n",
    "    # plot the distribution of a posteriori possible models\n",
    "    pl.figure(figsize=(15,7)) \n",
    "    pl.step(vel, fluxdata, '-', color='black', where='mid')\n",
    "    pl.errorbar(vel, fluxdata, yerr=fluxerr, fmt='', marker=None, ls='none', color='k')\n",
    "    pl.xlabel(r'Velocity [km s$^{-1}$]', fontsize=28)\n",
    "    pl.ylabel('Normalized Flux Density', fontsize=28)\n",
    "    pl.gca().tick_params(axis='both', labelsize=28)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Plot the distribution of a posteriori possible models\n",
    "    # Modelx is just a linear space of the velocities\n",
    "    modelx = np.linspace(min(vel), max(vel), 1000)\n",
    "\n",
    "    an = pymultinest.Analyzer(outputfiles_basename='mod_a_med_xe_detection_'+str(detections[i]['Detection']), n_params = n_params)\n",
    "    \n",
    "    # Loop through each possible model and plot it\n",
    "    for (a, b1, b2, w, xe, xp, c, n) in an.get_equal_weighted_posterior()[::100,:-1]:\n",
    "        pl.plot(modelx, Bmodelx(modelx, a, b1, b2, w, xe, xp, c, n), '-', color='red', alpha=0.3)\n",
    "        \n",
    "        # Axes parameters\n",
    "        pl.gca().xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        pl.gca().yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        pl.gca().tick_params(axis='both', which='major', direction='in', length=10, top=True, right=True)\n",
    "        pl.gca().tick_params(axis='both', which='minor', direction='in', length=5, top=True, right=True)\n",
    "\n",
    "    pl.savefig(directory_i+'mod_a_med_xe_posterior'+str(detections[i]['Detection'])+'.png')\n",
    "    pl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving the output of PyMultiNest into the relevant directories. May need to run this cell twice if errors arise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = '/users/wanga/mightee/analysis/COSMOS_1330/'\n",
    "\n",
    "# Read in all the files in the directory\n",
    "files = os.listdir(source)\n",
    "\n",
    "# Detections with two digit numbers confuse python so sort detections in reverse order\n",
    "rev_det = [detections[i]['Detection'] for i in range(len(detections))][::-1]\n",
    "\n",
    "# Loop through each detection\n",
    "for i in rev_det:\n",
    "    # Path to detection folder\n",
    "    dest = dirName+'detection_'+str(i) \n",
    "    \n",
    "    # Loop through all the files\n",
    "    for file in files:\n",
    "        if (file.startswith('mod_a_med_xe_detection_'+str(i))):\n",
    "            shutil.move(file, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store median and average parameters for each profile\n",
    "mod_a_med_xe_med_best_par_list = []\n",
    "mod_a_med_xe_av_best_par_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the marginal plots for each detection\n",
    "for d in range(len(detections)):\n",
    "    # Path to detection folder\n",
    "    dest = dirName+'detection_'+str(detections[d]['Detection'])+'/'\n",
    "    \n",
    "    # Load the parameters\n",
    "    params = json.load(open(dest+'mod_a_med_xe_params.json'))\n",
    "    n_params = len(params)\n",
    "    \n",
    "    # Create the analyzer object\n",
    "    an = pymultinest.Analyzer(n_params = n_params, outputfiles_basename = dest+'mod_a_med_xe_detection_'+str(detections[d]['Detection']))\n",
    "    \n",
    "    # Get a dictionary containing information about the logZ and its errors,\n",
    "    # the individual modes and their parameters, quantiles of the parameter posteriors\n",
    "    #stats = an.get_stats()\n",
    "    stats = an.get_stats()\n",
    "    \n",
    "    # get the best fit (highest likelihood) point\n",
    "    bestfit_params_dict = an.get_best_fit()\n",
    "    bestfit_params = bestfit_params_dict.get('parameters')\n",
    "    \n",
    "    # get the best fit (highest likelihood) point\n",
    "    bestfit_params_dict = an.get_best_fit()\n",
    "    bestfit_params = bestfit_params_dict.get('parameters')\n",
    "    \n",
    "    json.dump(stats, open(dest+'mod_a_med_xe_stats.json', 'w+'))\n",
    "    \n",
    "    # Create the marginal plot\n",
    "    p = pymultinest.PlotMarginal(an)\n",
    "    \n",
    "    values = an.get_equal_weighted_posterior()\n",
    "    assert n_params == len(stats['marginals'])\n",
    "    modes = stats['modes']\n",
    "    \n",
    "    # Dimensionality of the plot\n",
    "    dim2 = os.environ.get('D', '1' if n_params > 20 else '2') == '2'\n",
    "    nbins = 100 if n_params < 3 else 20\n",
    "    \n",
    "    # Set up grid layout\n",
    "    params_count2 = [0, 1, 2, 3, 4, 5, 6] # Grid for j\n",
    "    params_count_indx = 0\n",
    "    \n",
    "    if dim2:\n",
    "        plt.figure(figsize=(27*n_params, 27*n_params))\n",
    "        #for i in range(n_params):\n",
    "        for i in range(1, n_params+1, 1):\n",
    "            stepsizes = [0.1, 0.35, 0.35, 10, 10, 50, 4e-8, 0.4]\n",
    "            axis_formatters = ['%0.1f', '%0.1f', '%0.1f', '%d', '%d', '%d', '%.1e', '%0.1f']\n",
    "            \n",
    "            plt.subplot(n_params, n_params, (1 + 9*(i-1)))\n",
    "            plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "            \n",
    "            plt.xlabel(parameters[i-1], fontsize=160)\n",
    "\n",
    "            m = stats['marginals'][i-1]\n",
    "            \n",
    "            plt.xlim(m['5sigma'])\n",
    "            plt.xticks(rotation=40)\n",
    "\n",
    "            oldax = plt.gca()\n",
    "            x,w,patches = oldax.hist(values[:,i-1], bins=nbins, edgecolor='grey', color='grey', histtype='stepfilled', alpha=0.2)\n",
    "            oldax.set_ylim(0, x.max())\n",
    "            oldax.tick_params(axis='both', length=30, direction='in', top=True, right=True, pad=30)\n",
    "            oldax.tick_params(axis='x', labelbottom=False, labeltop=True)\n",
    "            \n",
    "            startax, endax = oldax.get_xlim()\n",
    "            oldax.xaxis.set_ticks(np.arange(startax, endax, stepsizes[i-1]))\n",
    "            oldax.xaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[i-1])) \n",
    "            oldax.xaxis.set_label_position('top')\n",
    "            \n",
    "            plt.setp(oldax.get_xticklabels(), fontsize=160)\n",
    "            plt.setp(oldax.get_yticklabels(), fontsize=160)\n",
    "            plt.setp(oldax.xaxis.get_majorticklabels(), rotation=40, fontsize=160)\n",
    "            plt.setp(oldax.yaxis.get_majorticklabels(), fontsize=160)\n",
    "\n",
    "            newax = plt.gcf().add_axes(oldax.get_position(), sharex=oldax, frameon=False)\n",
    "            newax.tick_params(axis='x', labelbottom=False, labeltop=True)\n",
    "            plt.setp(newax.get_xticklabels(), fontsize=160)\n",
    "            plt.setp(newax.get_yticklabels(), fontsize=160)\n",
    "            p.plot_marginal(i-1, ls='-', color='blue', linewidth=3)\n",
    "            newax.set_ylim(0, 1)\n",
    "\n",
    "            ylim = newax.get_ylim()\n",
    "            y = ylim[0] + 0.05*(ylim[1] - ylim[0])\n",
    "            center = m['median']\n",
    "            low1, high1 = m['1sigma']\n",
    "            #print(center, low1, high1)\n",
    "            newax.errorbar(x=center, y=y,\n",
    "                xerr=np.transpose([[center - low1, high1 - center]]), \n",
    "                color='blue', linewidth=2, marker='s')\n",
    "            oldax.set_yticks([])\n",
    "            #newax.set_yticks([])\n",
    "            oldax.tick_params(axis='both', length=30, direction='in', right=True)\n",
    "            newax.tick_params(axis='both', length=30, direction='in', right=True, pad=30)\n",
    "            newax.yaxis.set_label_position('right')\n",
    "            newax.xaxis.set_label_position('top')\n",
    "            newax.yaxis.set_ticks(np.arange(0.2, 1.2, 0.2))\n",
    "            newax.tick_params(axis='y', labelleft=False, labelright=True)\n",
    "            newax.set_ylabel(\"Probability\", fontsize=200, labelpad=30)\n",
    "            plt.setp(newax.xaxis.get_majorticklabels(), rotation=40, fontsize=160)\n",
    "            plt.setp(newax.yaxis.get_majorticklabels(), fontsize=160)\n",
    "            ylim = oldax.get_ylim()\n",
    "            newax.set_xlim(m['5sigma'])\n",
    "            oldax.set_xlim(m['5sigma'])\n",
    "            #plt.close()\n",
    "            \n",
    "            if i == n_params:\n",
    "                break\n",
    "                \n",
    "            #for j in range(i):\n",
    "            for j in range(params_count2[params_count_indx], n_params-1):\n",
    "                stepsizes = [0.05, 0.4, 0.35, 10, 20, 40, 4e-8, 0.4]\n",
    "                axis_formatters = ['%0.2f', '%0.1f', '%0.1f', '%d', '%d', '%d', '%.1e', '%0.1f']\n",
    "            \n",
    "                plt.subplot(n_params, n_params, ((n_params + i) + j*n_params))\n",
    "                p.plot_conditional(i-1, j+1, bins=20, cmap = pl.cm.gray_r)\n",
    "                for m in modes:\n",
    "                    plt.errorbar(x=bestfit_params[i-1], y=bestfit_params[j+1], xerr=m['sigma'][i-1], yerr=m['sigma'][j+1])\n",
    "                    \n",
    "                    ########\n",
    "                if j == 6 and i != 1:\n",
    "                    plt.xlabel(parameters[i-1], fontsize=200)\n",
    "                    \n",
    "                    # x axis\n",
    "                    startax, endax = plt.gca().get_xlim()\n",
    "                    plt.gca().xaxis.set_ticks(np.arange(startax, endax, stepsizes[i-1]))\n",
    "                    plt.gca().xaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[i-1])) \n",
    "        \n",
    "                    # y axis\n",
    "                    startay, enday = plt.gca().get_ylim()\n",
    "                    plt.gca().yaxis.set_ticks(np.arange(startay, enday, stepsizes[j+1]))\n",
    "                    plt.gca().yaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[j+1])) \n",
    "                    \n",
    "                    plt.gca().axes.tick_params(axis='x', labelbottom=True)\n",
    "                    plt.gca().axes.tick_params(axis='y', labelleft=False)\n",
    "                    plt.gca().axes.tick_params(axis='both', length=20, direction='in', top=True, right=True, pad=30)\n",
    "                elif i == 1 and j != 6:\n",
    "                    plt.ylabel(parameters[j+1], fontsize=200)\n",
    "                    # x axis\n",
    "                    startax, endax = plt.gca().get_xlim()\n",
    "                    plt.gca().xaxis.set_ticks(np.arange(startax, endax, stepsizes[i-1]))\n",
    "                    plt.gca().xaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[i-1])) \n",
    "        \n",
    "                    # y axis\n",
    "                    startay, enday = plt.gca().get_ylim()\n",
    "                    plt.gca().yaxis.set_ticks(np.arange(startay, enday, stepsizes[j+1]))\n",
    "                    plt.gca().yaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[j+1])) \n",
    "                    \n",
    "                    plt.gca().axes.tick_params(axis='x', labelbottom=False)\n",
    "                    plt.gca().axes.tick_params(axis='y', labelleft=True)\n",
    "                    plt.gca().axes.tick_params(axis='both', length=20, direction='in', top=True, right=True, pad=30)\n",
    "                elif i == 1 and j == 6:\n",
    "                    plt.xlabel(parameters[i-1], fontsize=200)\n",
    "                    plt.ylabel(parameters[j+1], fontsize=200)\n",
    "                    \n",
    "                    # x axis\n",
    "                    startax, endax = plt.gca().get_xlim()\n",
    "                    plt.gca().xaxis.set_ticks(np.arange(startax, endax, stepsizes[i-1]))\n",
    "                    plt.gca().xaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[i-1])) \n",
    "        \n",
    "                    # y axis\n",
    "                    startay, enday = plt.gca().get_ylim()\n",
    "                    plt.gca().yaxis.set_ticks(np.arange(startay, enday, stepsizes[j+1]))\n",
    "                    plt.gca().yaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[j+1])) \n",
    "                    \n",
    "                    plt.gca().axes.tick_params(axis='x', labelbottom=True)\n",
    "                    plt.gca().axes.tick_params(axis='y', labelleft=True)\n",
    "                    plt.gca().axes.tick_params(axis='both', length=20, direction='in', top=True, right=True, pad=30)\n",
    "                else:   \n",
    "                    # x axis\n",
    "                    startax, endax = plt.gca().get_xlim()\n",
    "                    plt.gca().xaxis.set_ticks(np.arange(startax, endax, stepsizes[i-1]))\n",
    "                    plt.gca().xaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[i-1])) \n",
    "    \n",
    "                    # y axis\n",
    "                    startay, enday = plt.gca().get_ylim()\n",
    "                    plt.gca().yaxis.set_ticks(np.arange(startay, enday, stepsizes[j+1]))\n",
    "                    plt.gca().yaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[j+1])) \n",
    "                        \n",
    "                    plt.gca().axes.tick_params(axis='both', length=30, direction='in', top=True, right=True, pad=30)\n",
    "                    plt.gca().axes.tick_params(axis='x', labelbottom=False)\n",
    "                    plt.gca().axes.tick_params(axis='y', labelleft=False)\n",
    "                plt.xticks(rotation=40)\n",
    "                plt.setp(plt.gca().get_xticklabels(), fontsize=160)\n",
    "                plt.setp(plt.gca().get_yticklabels(), fontsize=160)\n",
    "                #plt.savefig('cond_%s_%s.pdf' % (params[i], params[j]), bbox_tight=True)\n",
    "                #plt.close()\n",
    "                \n",
    "            params_count_indx += 1\n",
    "\n",
    "        plt.savefig(dest + 'mod_a_med_xe_marg'+str(detections[d]['Detection'])+'.pdf')\n",
    "        #plt.savefig(dest + 'marg'+str(detections[d]['Detection'])+'.png')\n",
    "        plt.close()\n",
    "    \n",
    "    '''\n",
    "    Storing the average parameter values\n",
    "    '''\n",
    "    # Open a text file to save the parameter results\n",
    "    av_results_txt = open(dest+'mod_a_med_xe_av_results_detection_'+str(detections[d]['Detection'])+'.txt', 'w+')\n",
    "\n",
    "    # List to store best parameters\n",
    "    av_best_par = []\n",
    "    \n",
    "    h = 0\n",
    "    for par in parameters:\n",
    "        av_results_txt.write('%s %.15f %.15f\\n' % (par, modes[0]['mean'][h], modes[0]['sigma'][h]))\n",
    "        av_best_par.append([modes[0]['mean'][h], modes[0]['sigma'][h]])\n",
    "        h+=1\n",
    "\n",
    "    av_results_txt.close()\n",
    "    mod_a_med_xe_av_best_par_list.append(av_best_par)\n",
    "    \n",
    "    '''\n",
    "    Choosing the median\n",
    "    '''\n",
    "    # Open a text file to save the parameter results_txt\n",
    "    med_results_txt = open(dest+'mod_a_med_xe_med_results_detection_'+str(detections[d]['Detection'])+'.txt', 'w+')\n",
    "    \n",
    "    # Write the marginal likelihood\n",
    "    med_results_txt.write('lnZ %.1f %.1f\\n'%(stats['global evidence'], stats['global evidence error']))\n",
    "    \n",
    "    # List to store best parameters\n",
    "    med_best_par = []\n",
    "    \n",
    "    # Write the parameters\n",
    "    for par, marg in zip(parameters, stats['marginals']):\n",
    "        # 1 sigma provides the lowest and highest estimates\n",
    "        lo, hi = marg['1sigma']\n",
    "        sigma = (hi - lo) / 2 # Calculate the error\n",
    "        \n",
    "        med = marg['median']\n",
    "        \n",
    "        if sigma == 0:\n",
    "            j = 3\n",
    "        else:\n",
    "            j = max(0, int(-np.floor(np.log10(sigma))) + 1)\n",
    "            \n",
    "        # Create the string to write    \n",
    "        fmt = '%%.%df' % j\n",
    "        fmts = '\\t'.join(['%-3s' + fmt + \" +- \" + fmt +'\\n'])\n",
    "        \n",
    "        med_results_txt.write('%s %.15f %.15f\\n' % (par, med, sigma))\n",
    "        \n",
    "        # Save the value and error for this parameter\n",
    "        med_best_par.append([med, sigma])\n",
    "    \n",
    "    med_results_txt.close()\n",
    "    mod_a_med_xe_med_best_par_list.append(med_best_par)\n",
    "\n",
    "    '''\n",
    "    Model and integrated flux\n",
    "    '''\n",
    "    # The busy function with the best parameter\n",
    "    modelx = np.linspace(min(all_vel[d]), max(all_vel[d]), 1000)\n",
    "    modely = Bmodelx(modelx, med_best_par[0][0], med_best_par[1][0], med_best_par[2][0], med_best_par[3][0], \n",
    "                            med_best_par[4][0], med_best_par[5][0], med_best_par[6][0], med_best_par[7][0])\n",
    "    \n",
    "    # Integrated flux of data\n",
    "    Sdv_data = all_sdv[d]\n",
    "    Sdv_data_err = all_sdv_err[d]\n",
    "    \n",
    "    # Integrated flux of model\n",
    "    dvmodel = np.average(np.diff(modelx))\n",
    "    Sdv_model = np.sum(modely*dvmodel)*all_max_flux[d]\n",
    "    \n",
    "    '''\n",
    "    Plotting the median and mean parameters\n",
    "    '''\n",
    "    pl.figure(figsize=(15,7)) \n",
    "    pl.step(all_vel[d], all_flux[d], 'k', where='mid')\n",
    "    pl.errorbar(all_vel[d], all_flux[d], yerr=all_flux_err[d], fmt='', marker=None, ls='none', color='k')\n",
    "    pl.plot(modelx, modely, 'r-')\n",
    "#     pl.plot(modelx, Bmodelx(modelx, av_best_par[0][0], av_best_par[1][0], av_best_par[2][0], av_best_par[3][0], \n",
    "#                             av_best_par[4][0], av_best_par[5][0], av_best_par[6][0], av_best_par[7][0]), 'b-', \n",
    "#             alpha=0.5, label=r'Mean W$_{50}$ = %.2f $\\pm$ %.2f km/s'%(2*av_best_par[3][0], 2*av_best_par[3][1]))\n",
    "    pl.xlabel(r'Velocity [km s$^{-1}$]', fontsize=28)\n",
    "    pl.ylabel('Normalized Flux Density', fontsize=28)\n",
    "    pl.gca().tick_params(axis='both', labelsize=28)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Axes parameters\n",
    "    pl.gca().xaxis.set_minor_locator(AutoMinorLocator())\n",
    "    pl.gca().yaxis.set_minor_locator(AutoMinorLocator())\n",
    "    pl.gca().tick_params(axis='both', which='major', direction='in', length=10, top=True, right=True)\n",
    "    pl.gca().tick_params(axis='both', which='minor', direction='in', length=5, top=True, right=True)\n",
    "    #pl.legend(loc='upper right', fontsize=17)\n",
    "    \n",
    "    # Anchored text\n",
    "    textstr = '\\n'.join((\n",
    "    r'Med. W$_{50}$ = %.2f $\\pm$ %.2f km s$^{-1}$' % (2*med_best_par[3][0], 2*med_best_par[3][1], ),\n",
    "    r'$\\int S\\mathrm{dv}_\\mathrm{data}$ = %.3f $\\pm$ %.3f Jy km s$^{-1}$' % (Sdv_data, Sdv_data_err, ),\n",
    "    r'$\\int S\\mathrm{dv}_\\mathrm{model}$ = %.3f Jy km s$^{-1}$' % (Sdv_model, )))\n",
    "    pl.annotate(textstr, xy=(0.03, 0.7), xycoords='axes fraction', fontsize=17)\n",
    "    \n",
    "    pl.savefig(dest+'mod_a_med_xe_best_par'+str(detections[d]['Detection'])+'.png')\n",
    "    pl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third run with modified priors for $a$, and $x_e$ and $x_p$ fixed on the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/users/wanga/mightee/analysis/COSMOS_1330/masked_profiles_COSMOS_1330_output/'\n",
    "\n",
    "# Loop through each detection\n",
    "for i in range(len(detections)):        \n",
    "    # Define the prior with a different paramater space for a\n",
    "    # Define the prior that transforms the unit cube into the parameter cube that is now in log space\n",
    "    # parameters are a, b1, b2, w, xe, xp, c, n\n",
    "    def prior(cube, ndim, nparams):\n",
    "        cube[0] = cube[0]*(three_sigma_a[i][1] - three_sigma_a[i][0]) + three_sigma_a[i][0] # modified prior for a within 3 sigma\n",
    "        cube[1] = cube[1] # log-uniform prior for b1 between 0 and 1\n",
    "        cube[2] = cube[2] # log-uniform prior for b2 between 0 and 1\n",
    "        cube[3] = 10**(cube[3]*3) # log-uniform prior for w between 10**(0*3)=1 and 10**(1*3)=1e3\n",
    "        cube[4] = mod_a_med_xe_med_best_par_list[i][4][0] # xe fixed on medians of second run\n",
    "        cube[5] = mod_a_med_xe_med_best_par_list[i][5][0] # xp fixed on medians of second run\n",
    "        cube[6] = 10**(-cube[6]*2 - 7) # log-uniform prior for c between 10**(-0*2-7)=1e-7 and 10**(-1*2-7)=1e-9\n",
    "        cube[7] = 6*cube[7] + 2 # log-uniform prior for n between 6(0)+2=2 and 6(1)+2=8\n",
    "    \n",
    "    # Create a directory for detection i's results\n",
    "    directory_i = dirName+'/detection_'+str(detections[i]['Detection'])+'/'\n",
    "    \n",
    "    vel = all_vel[i]\n",
    "    fluxdata = all_flux[i]\n",
    "    fluxerr = all_flux_err[i]\n",
    "    \n",
    "    noise = fluxerr\n",
    "    \n",
    "    # Number of dimensions our problem has\n",
    "    parameters = [r'$a$', r'$b_1$', r'$b_2$', r'$w$', r'$x_e$', r'$x_p$', r'$c$', r'$n$']\n",
    "    n_params = len(parameters)\n",
    "    \n",
    "    # Run PyMultiNest\n",
    "    pymultinest.run(loglike, prior, n_params, outputfiles_basename='mod_a_med_xexp_detection_'+str(detections[i]['Detection']), resume=False, verbose=True)\n",
    "    json.dump(parameters, open(directory_i+'/mod_a_med_xexp_params.json', 'w')) # Save the parameters\n",
    "    \n",
    "    # plot the distribution of a posteriori possible models\n",
    "    pl.figure(figsize=(15,7)) \n",
    "    pl.step(vel, fluxdata, '-', color='black', where='mid')\n",
    "    pl.errorbar(vel, fluxdata, yerr=fluxerr, fmt='', marker=None, ls='none', color='k')\n",
    "    pl.xlabel(r'Velocity [km s$^{-1}$]', fontsize=28)\n",
    "    pl.ylabel('Normalized Flux Density', fontsize=28)\n",
    "    pl.gca().tick_params(axis='both', labelsize=28)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Plot the distribution of a posteriori possible models\n",
    "    # Modelx is just a linear space of the velocities\n",
    "    modelx = np.linspace(min(vel), max(vel), 1000)\n",
    "\n",
    "    an = pymultinest.Analyzer(outputfiles_basename='mod_a_med_xexp_detection_'+str(detections[i]['Detection']), n_params = n_params)\n",
    "    \n",
    "    # Loop through each possible model and plot it\n",
    "    for (a, b1, b2, w, xe, xp, c, n) in an.get_equal_weighted_posterior()[::100,:-1]:\n",
    "        pl.plot(modelx, Bmodelx(modelx, a, b1, b2, w, xe, xp, c, n), '-', color='red', alpha=0.3)\n",
    "        \n",
    "        # Axes parameters\n",
    "        pl.gca().xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        pl.gca().yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        pl.gca().tick_params(axis='both', which='major', direction='in', length=10, top=True, right=True)\n",
    "        pl.gca().tick_params(axis='both', which='minor', direction='in', length=5, top=True, right=True)\n",
    "\n",
    "    pl.savefig(directory_i+'mod_a_med_xexp_posterior'+str(detections[i]['Detection'])+'.png')\n",
    "    pl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving the output of PyMultiNest into the relevant directories. May need to run this cell twice if errors arise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = '/users/wanga/mightee/analysis/COSMOS_1330/'\n",
    "\n",
    "# Read in all the files in the directory\n",
    "files = os.listdir(source)\n",
    "\n",
    "# Detections with two digit numbers confuse python so sort detections in reverse order\n",
    "rev_det = [detections[i]['Detection'] for i in range(len(detections))][::-1]\n",
    "\n",
    "# Loop through each detection\n",
    "for i in rev_det:\n",
    "    # Path to detection folder\n",
    "    dest = dirName+'detection_'+str(i) \n",
    "    \n",
    "    # Loop through all the files\n",
    "    for file in files:\n",
    "        if (file.startswith('mod_a_med_xexp_detection_'+str(i))):\n",
    "            shutil.move(file, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store median and average parameters for each profile\n",
    "mod_a_med_xexp_med_best_par_list = []\n",
    "mod_a_med_xexp_av_best_par_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the marginal plots for each detection\n",
    "for d in range(len(detections)):\n",
    "    # Path to detection folder\n",
    "    dest = dirName+'detection_'+str(detections[d]['Detection'])+'/'\n",
    "    \n",
    "    # Load the parameters\n",
    "    params = json.load(open(dest+'mod_a_med_xexp_params.json'))\n",
    "    n_params = len(params)\n",
    "    \n",
    "    # Create the analyzer object\n",
    "    an = pymultinest.Analyzer(n_params = n_params, outputfiles_basename = dest+'mod_a_med_xexp_detection_'+str(detections[d]['Detection']))\n",
    "    \n",
    "    # Get a dictionary containing information about the logZ and its errors,\n",
    "    # the individual modes and their parameters, quantiles of the parameter posteriors\n",
    "    #stats = an.get_stats()\n",
    "    stats = an.get_stats()\n",
    "    \n",
    "    # get the best fit (highest likelihood) point\n",
    "    bestfit_params_dict = an.get_best_fit()\n",
    "    bestfit_params = bestfit_params_dict.get('parameters')\n",
    "    \n",
    "    json.dump(stats, open(dest+'mod_a_med_xexp_stats.json', 'w+'))\n",
    "    \n",
    "    # Create the marginal plot\n",
    "    p = pymultinest.PlotMarginal(an)\n",
    "    \n",
    "    values = an.get_equal_weighted_posterior()\n",
    "    assert n_params == len(stats['marginals'])\n",
    "    modes = stats['modes']\n",
    "    \n",
    "    # Dimensionality of the plot\n",
    "    dim2 = os.environ.get('D', '1' if n_params > 20 else '2') == '2'\n",
    "    nbins = 100 if n_params < 3 else 20\n",
    "    \n",
    "    # Set up grid layout\n",
    "    params_count2 = [0, 1, 2, 3, 4, 5, 6] # Grid for j\n",
    "    params_count_indx = 0\n",
    "    \n",
    "    if dim2:\n",
    "        plt.figure(figsize=(27*n_params, 27*n_params))\n",
    "        #for i in range(n_params):\n",
    "        for i in range(1, n_params+1, 1):\n",
    "            stepsizes = [0.1, 0.35, 0.35, 10, 10, 50, 4e-8, 0.4]\n",
    "            axis_formatters = ['%0.1f', '%0.1f', '%0.1f', '%d', '%d', '%d', '%.1e', '%0.1f']\n",
    "            \n",
    "            plt.subplot(n_params, n_params, (1 + 9*(i-1)))\n",
    "            plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "            \n",
    "            plt.xlabel(parameters[i-1], fontsize=160)\n",
    "\n",
    "            m = stats['marginals'][i-1]\n",
    "            \n",
    "            plt.xlim(m['5sigma'])\n",
    "            plt.xticks(rotation=40)\n",
    "\n",
    "            oldax = plt.gca()\n",
    "            x,w,patches = oldax.hist(values[:,i-1], bins=nbins, edgecolor='grey', color='grey', histtype='stepfilled', alpha=0.2)\n",
    "            oldax.set_ylim(0, x.max())\n",
    "            oldax.tick_params(axis='both', length=30, direction='in', top=True, right=True, pad=30)\n",
    "            oldax.tick_params(axis='x', labelbottom=False, labeltop=True)\n",
    "            \n",
    "            startax, endax = oldax.get_xlim()\n",
    "            oldax.xaxis.set_ticks(np.arange(startax, endax, stepsizes[i-1]))\n",
    "            oldax.xaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[i-1])) \n",
    "            oldax.xaxis.set_label_position('top')\n",
    "            \n",
    "            plt.setp(oldax.get_xticklabels(), fontsize=160)\n",
    "            plt.setp(oldax.get_yticklabels(), fontsize=160)\n",
    "            plt.setp(oldax.xaxis.get_majorticklabels(), rotation=40, fontsize=160)\n",
    "            plt.setp(oldax.yaxis.get_majorticklabels(), fontsize=160)\n",
    "\n",
    "            newax = plt.gcf().add_axes(oldax.get_position(), sharex=oldax, frameon=False)\n",
    "            newax.tick_params(axis='x', labelbottom=False, labeltop=True)\n",
    "            plt.setp(newax.get_xticklabels(), fontsize=160)\n",
    "            plt.setp(newax.get_yticklabels(), fontsize=160)\n",
    "            p.plot_marginal(i-1, ls='-', color='blue', linewidth=3)\n",
    "            newax.set_ylim(0, 1)\n",
    "\n",
    "            ylim = newax.get_ylim()\n",
    "            y = ylim[0] + 0.05*(ylim[1] - ylim[0])\n",
    "            center = m['median']\n",
    "            low1, high1 = m['1sigma']\n",
    "            #print(center, low1, high1)\n",
    "            newax.errorbar(x=center, y=y,\n",
    "                xerr=np.transpose([[center - low1, high1 - center]]), \n",
    "                color='blue', linewidth=2, marker='s')\n",
    "            oldax.set_yticks([])\n",
    "            #newax.set_yticks([])\n",
    "            oldax.tick_params(axis='both', length=30, direction='in', right=True)\n",
    "            newax.tick_params(axis='both', length=30, direction='in', right=True, pad=30)\n",
    "            newax.yaxis.set_label_position('right')\n",
    "            newax.xaxis.set_label_position('top')\n",
    "            newax.yaxis.set_ticks(np.arange(0.2, 1.2, 0.2))\n",
    "            newax.tick_params(axis='y', labelleft=False, labelright=True)\n",
    "            newax.set_ylabel(\"Probability\", fontsize=200, labelpad=30)\n",
    "            plt.setp(newax.xaxis.get_majorticklabels(), rotation=40, fontsize=160)\n",
    "            plt.setp(newax.yaxis.get_majorticklabels(), fontsize=160)\n",
    "            ylim = oldax.get_ylim()\n",
    "            newax.set_xlim(m['5sigma'])\n",
    "            oldax.set_xlim(m['5sigma'])\n",
    "            #plt.close()\n",
    "            \n",
    "            if i == n_params:\n",
    "                break\n",
    "                \n",
    "            #for j in range(i):\n",
    "            for j in range(params_count2[params_count_indx], n_params-1):\n",
    "                stepsizes = [0.05, 0.4, 0.35, 10, 20, 40, 4e-8, 0.4]\n",
    "                axis_formatters = ['%0.2f', '%0.1f', '%0.1f', '%d', '%d', '%d', '%.1e', '%0.1f']\n",
    "            \n",
    "                plt.subplot(n_params, n_params, ((n_params + i) + j*n_params))\n",
    "                p.plot_conditional(i-1, j+1, bins=20, cmap = pl.cm.gray_r)\n",
    "                for m in modes:\n",
    "                    plt.errorbar(x=bestfit_params[i-1], y=bestfit_params[j+1], xerr=m['sigma'][i-1], yerr=m['sigma'][j+1])\n",
    "                    \n",
    "                    ########\n",
    "                if j == 6 and i != 1:\n",
    "                    plt.xlabel(parameters[i-1], fontsize=200)\n",
    "                    \n",
    "                    # x axis\n",
    "                    startax, endax = plt.gca().get_xlim()\n",
    "                    plt.gca().xaxis.set_ticks(np.arange(startax, endax, stepsizes[i-1]))\n",
    "                    plt.gca().xaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[i-1])) \n",
    "        \n",
    "                    # y axis\n",
    "                    startay, enday = plt.gca().get_ylim()\n",
    "                    plt.gca().yaxis.set_ticks(np.arange(startay, enday, stepsizes[j+1]))\n",
    "                    plt.gca().yaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[j+1])) \n",
    "                    \n",
    "                    plt.gca().axes.tick_params(axis='x', labelbottom=True)\n",
    "                    plt.gca().axes.tick_params(axis='y', labelleft=False)\n",
    "                    plt.gca().axes.tick_params(axis='both', length=20, direction='in', top=True, right=True, pad=30)\n",
    "                elif i == 1 and j != 6:\n",
    "                    plt.ylabel(parameters[j+1], fontsize=200)\n",
    "                    # x axis\n",
    "                    startax, endax = plt.gca().get_xlim()\n",
    "                    plt.gca().xaxis.set_ticks(np.arange(startax, endax, stepsizes[i-1]))\n",
    "                    plt.gca().xaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[i-1])) \n",
    "        \n",
    "                    # y axis\n",
    "                    startay, enday = plt.gca().get_ylim()\n",
    "                    plt.gca().yaxis.set_ticks(np.arange(startay, enday, stepsizes[j+1]))\n",
    "                    plt.gca().yaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[j+1])) \n",
    "                    \n",
    "                    plt.gca().axes.tick_params(axis='x', labelbottom=False)\n",
    "                    plt.gca().axes.tick_params(axis='y', labelleft=True)\n",
    "                    plt.gca().axes.tick_params(axis='both', length=20, direction='in', top=True, right=True, pad=30)\n",
    "                elif i == 1 and j == 6:\n",
    "                    plt.xlabel(parameters[i-1], fontsize=200)\n",
    "                    plt.ylabel(parameters[j+1], fontsize=200)\n",
    "                    \n",
    "                    # x axis\n",
    "                    startax, endax = plt.gca().get_xlim()\n",
    "                    plt.gca().xaxis.set_ticks(np.arange(startax, endax, stepsizes[i-1]))\n",
    "                    plt.gca().xaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[i-1])) \n",
    "        \n",
    "                    # y axis\n",
    "                    startay, enday = plt.gca().get_ylim()\n",
    "                    plt.gca().yaxis.set_ticks(np.arange(startay, enday, stepsizes[j+1]))\n",
    "                    plt.gca().yaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[j+1])) \n",
    "                    \n",
    "                    plt.gca().axes.tick_params(axis='x', labelbottom=True)\n",
    "                    plt.gca().axes.tick_params(axis='y', labelleft=True)\n",
    "                    plt.gca().axes.tick_params(axis='both', length=20, direction='in', top=True, right=True, pad=30)\n",
    "                else:   \n",
    "                    # x axis\n",
    "                    startax, endax = plt.gca().get_xlim()\n",
    "                    plt.gca().xaxis.set_ticks(np.arange(startax, endax, stepsizes[i-1]))\n",
    "                    plt.gca().xaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[i-1])) \n",
    "    \n",
    "                    # y axis\n",
    "                    startay, enday = plt.gca().get_ylim()\n",
    "                    plt.gca().yaxis.set_ticks(np.arange(startay, enday, stepsizes[j+1]))\n",
    "                    plt.gca().yaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[j+1])) \n",
    "                        \n",
    "                    plt.gca().axes.tick_params(axis='both', length=30, direction='in', top=True, right=True, pad=30)\n",
    "                    plt.gca().axes.tick_params(axis='x', labelbottom=False)\n",
    "                    plt.gca().axes.tick_params(axis='y', labelleft=False)\n",
    "                plt.xticks(rotation=40)\n",
    "                plt.setp(plt.gca().get_xticklabels(), fontsize=160)\n",
    "                plt.setp(plt.gca().get_yticklabels(), fontsize=160)\n",
    "                #plt.savefig('cond_%s_%s.pdf' % (params[i], params[j]), bbox_tight=True)\n",
    "                #plt.close()\n",
    "                \n",
    "            params_count_indx += 1\n",
    "\n",
    "        plt.savefig(dest + 'mod_a_med_xexp_marg'+str(detections[d]['Detection'])+'.pdf')\n",
    "        #plt.savefig(dest + 'marg'+str(detections[d]['Detection'])+'.png')\n",
    "        plt.close()\n",
    "    \n",
    "    '''\n",
    "    Storing the average parameter values\n",
    "    '''\n",
    "    # Open a text file to save the parameter results\n",
    "    av_results_txt = open(dest+'mod_a_med_xexp_av_results_detection_'+str(detections[d]['Detection'])+'.txt', 'w+')\n",
    "\n",
    "    # List to store best parameters\n",
    "    av_best_par = []\n",
    "    \n",
    "    h = 0\n",
    "    for par in parameters:\n",
    "        av_results_txt.write('%s %.15f %.15f\\n' % (par, modes[0]['mean'][h], modes[0]['sigma'][h]))\n",
    "        av_best_par.append([modes[0]['mean'][h], modes[0]['sigma'][h]])\n",
    "        h+=1\n",
    "\n",
    "    av_results_txt.close()\n",
    "    mod_a_med_xexp_av_best_par_list.append(av_best_par)\n",
    "    \n",
    "    '''\n",
    "    Choosing the median\n",
    "    '''\n",
    "    # Open a text file to save the parameter results_txt\n",
    "    med_results_txt = open(dest+'mod_a_med_xexp_med_results_detection_'+str(detections[d]['Detection'])+'.txt', 'w+')\n",
    "    \n",
    "    # Write the marginal likelihood\n",
    "    med_results_txt.write('lnZ %.1f %.1f\\n'%(stats['global evidence'], stats['global evidence error']))\n",
    "    \n",
    "    # List to store best parameters\n",
    "    med_best_par = []\n",
    "    \n",
    "    # Write the parameters\n",
    "    for par, marg in zip(parameters, stats['marginals']):\n",
    "        # 1 sigma provides the lowest and highest estimates\n",
    "        lo, hi = marg['1sigma']\n",
    "        sigma = (hi - lo) / 2 # Calculate the error\n",
    "        \n",
    "        med = marg['median']\n",
    "        \n",
    "        if sigma == 0:\n",
    "            j = 3\n",
    "        else:\n",
    "            j = max(0, int(-np.floor(np.log10(sigma))) + 1)\n",
    "            \n",
    "        # Create the string to write    \n",
    "        fmt = '%%.%df' % j\n",
    "        fmts = '\\t'.join(['%-3s' + fmt + \" +- \" + fmt +'\\n'])\n",
    "        \n",
    "        med_results_txt.write('%s %.15f %.15f\\n' % (par, med, sigma))\n",
    "        \n",
    "        # Save the value and error for this parameter\n",
    "        med_best_par.append([med, sigma])\n",
    "    \n",
    "    med_results_txt.close()\n",
    "    mod_a_med_xexp_med_best_par_list.append(med_best_par)\n",
    "    \n",
    "    '''\n",
    "    Model and integrated flux\n",
    "    '''\n",
    "    # The busy function with the best parameter\n",
    "    modelx = np.linspace(min(all_vel[d]), max(all_vel[d]), 1000)\n",
    "    modely = Bmodelx(modelx, med_best_par[0][0], med_best_par[1][0], med_best_par[2][0], med_best_par[3][0], \n",
    "                            med_best_par[4][0], med_best_par[5][0], med_best_par[6][0], med_best_par[7][0])\n",
    "    \n",
    "    # Integrated flux of data\n",
    "    Sdv_data = all_sdv[d]\n",
    "    Sdv_data_err = all_sdv_err[d]\n",
    "    \n",
    "    # Integrated flux of model\n",
    "    dvmodel = np.average(np.diff(modelx))\n",
    "    Sdv_model = np.sum(modely*dvmodel)*all_max_flux[d]\n",
    "    \n",
    "    '''\n",
    "    Plotting the median and mean parameters\n",
    "    '''\n",
    "    pl.figure(figsize=(15,7)) \n",
    "    pl.step(all_vel[d], all_flux[d], 'k', where='mid')\n",
    "    pl.errorbar(all_vel[d], all_flux[d], yerr=all_flux_err[d], fmt='', marker=None, ls='none', color='k')\n",
    "    pl.plot(modelx, modely, 'r-')\n",
    "#     pl.plot(modelx, Bmodelx(modelx, av_best_par[0][0], av_best_par[1][0], av_best_par[2][0], av_best_par[3][0], \n",
    "#                             av_best_par[4][0], av_best_par[5][0], av_best_par[6][0], av_best_par[7][0]), 'b-', \n",
    "#             alpha=0.5, label=r'Mean W$_{50}$ = %.2f $\\pm$ %.2f km/s'%(2*av_best_par[3][0], 2*av_best_par[3][1]))\n",
    "    pl.xlabel(r'Velocity [km s$^{-1}$]', fontsize=28)\n",
    "    pl.ylabel('Normalized Flux Density', fontsize=28)\n",
    "    pl.gca().tick_params(axis='both', labelsize=28)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Axes parameters\n",
    "    pl.gca().xaxis.set_minor_locator(AutoMinorLocator())\n",
    "    pl.gca().yaxis.set_minor_locator(AutoMinorLocator())\n",
    "    pl.gca().tick_params(axis='both', which='major', direction='in', length=10, top=True, right=True)\n",
    "    pl.gca().tick_params(axis='both', which='minor', direction='in', length=5, top=True, right=True)\n",
    "    #pl.legend(loc='upper right', fontsize=17)\n",
    "    \n",
    "    # Anchored text\n",
    "    textstr = '\\n'.join((\n",
    "    r'Med. W$_{50}$ = %.2f $\\pm$ %.2f km s$^{-1}$' % (2*med_best_par[3][0], 2*med_best_par[3][1], ),\n",
    "    r'$\\int S\\mathrm{dv}_\\mathrm{data}$ = %.3f $\\pm$ %.3f Jy km s$^{-1}$' % (Sdv_data, Sdv_data_err, ),\n",
    "    r'$\\int S\\mathrm{dv}_\\mathrm{model}$ = %.3f Jy km s$^{-1}$' % (Sdv_model, )))\n",
    "    pl.annotate(textstr, xy=(0.03, 0.7), xycoords='axes fraction', fontsize=17)\n",
    "    \n",
    "    pl.savefig(dest+'mod_a_med_xexp_best_par'+str(detections[d]['Detection'])+'.png')\n",
    "    pl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth run with $x_e$, $x_p$, $b_1$ and $b_2$ fixed on the median, and the ranges for $a$ relaxed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/users/wanga/mightee/analysis/COSMOS_1330/masked_profiles_COSMOS_1330_output/'\n",
    "\n",
    "# Loop through each detection\n",
    "for i in range(len(detections)):        \n",
    "    # Define the prior with a different paramater space for a\n",
    "    # Define the prior that transforms the unit cube into the parameter cube that is now in log space\n",
    "    # parameters are a, b1, b2, w, xe, xp, c, n\n",
    "    def prior(cube, ndim, nparams):\n",
    "        cube[0] = cube[0] # log-uniform prior for a between 0*1=0 and 1*1=1\n",
    "        cube[1] = mod_a_med_xexp_med_best_par_list[i][1][0] # b1 fixed on medians of third run\n",
    "        cube[2] = mod_a_med_xexp_med_best_par_list[i][2][0] # b2 fixed on medians of third run\n",
    "        cube[3] = 10**(cube[3]*3) # log-uniform prior for w between 10**(0*3)=1 and 10**(1*3)=1e3\n",
    "        cube[4] = mod_a_med_xexp_med_best_par_list[i][4][0] # xe fixed on medians of third run\n",
    "        cube[5] = mod_a_med_xexp_med_best_par_list[i][5][0] # xp fixed on medians of third run\n",
    "        cube[6] = 10**(-cube[6]*2 - 7) # log-uniform prior for c between 10**(-0*2-7)=1e-7 and 10**(-1*2-7)=1e-9\n",
    "        cube[7] = 6*cube[7] + 2 # log-uniform prior for n between 6(0)+2=2 and 6(1)+2=8\n",
    "    \n",
    "    # Create a directory for detection i's results\n",
    "    directory_i = dirName+'/detection_'+str(detections[i]['Detection'])+'/'\n",
    "    \n",
    "    vel = all_vel[i]\n",
    "    fluxdata = all_flux[i]\n",
    "    fluxerr = all_flux_err[i]\n",
    "    \n",
    "    noise = fluxerr\n",
    "    \n",
    "    # Number of dimensions our problem has\n",
    "    parameters = [r'$a$', r'$b_1$', r'$b_2$', r'$w$', r'$x_e$', r'$x_p$', r'$c$', r'$n$']\n",
    "    n_params = len(parameters)\n",
    "    \n",
    "    # Run PyMultiNest\n",
    "    pymultinest.run(loglike, prior, n_params, outputfiles_basename='med_xexpb1b2_detection_'+str(detections[i]['Detection']), resume=False, verbose=True)\n",
    "    json.dump(parameters, open(directory_i+'/med_xexpb1b2_params.json', 'w')) # Save the parameters\n",
    "    \n",
    "    # plot the distribution of a posteriori possible models\n",
    "    pl.figure(figsize=(15,7)) \n",
    "    pl.step(vel, fluxdata, '-', color='black', where='mid')\n",
    "    pl.errorbar(vel, fluxdata, yerr=fluxerr, fmt='', marker=None, ls='none', color='k')\n",
    "    pl.xlabel(r'Velocity [km s$^{-1}$]', fontsize=28)\n",
    "    pl.ylabel('Normalized Flux Density', fontsize=28)\n",
    "    pl.gca().tick_params(axis='both', labelsize=28)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Plot the distribution of a posteriori possible models\n",
    "    # Modelx is just a linear space of the velocities\n",
    "    modelx = np.linspace(min(vel), max(vel), 1000)\n",
    "\n",
    "    an = pymultinest.Analyzer(outputfiles_basename='med_xexpb1b2_detection_'+str(detections[i]['Detection']), n_params = n_params)\n",
    "    \n",
    "    # Loop through each possible model and plot it\n",
    "    for (a, b1, b2, w, xe, xp, c, n) in an.get_equal_weighted_posterior()[::100,:-1]:\n",
    "        pl.plot(modelx, Bmodelx(modelx, a, b1, b2, w, xe, xp, c, n), '-', color='red', alpha=0.3)\n",
    "        \n",
    "        # Axes parameters\n",
    "        pl.gca().xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        pl.gca().yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        pl.gca().tick_params(axis='both', which='major', direction='in', length=10, top=True, right=True)\n",
    "        pl.gca().tick_params(axis='both', which='minor', direction='in', length=5, top=True, right=True)\n",
    "\n",
    "    pl.savefig(directory_i+'med_xexpb1b2_posterior'+str(detections[i]['Detection'])+'.png')\n",
    "    pl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving the output of PyMultiNest into the relevant directories. May need to run this cell twice if errors arise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = '/users/wanga/mightee/analysis/COSMOS_1330/'\n",
    "\n",
    "# Read in all the files in the directory\n",
    "files = os.listdir(source)\n",
    "\n",
    "# Detections with two digit numbers confuse python so sort detections in reverse order\n",
    "rev_det = [detections[i]['Detection'] for i in range(len(detections))][::-1]\n",
    "\n",
    "# Loop through each detection\n",
    "for i in rev_det:\n",
    "    # Path to detection folder\n",
    "    dest = dirName+'detection_'+str(i) \n",
    "    \n",
    "    # Loop through all the files\n",
    "    for file in files:\n",
    "        if (file.startswith('med_xexpb1b2_detection_'+str(i))):\n",
    "            shutil.move(file, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store median and average parameters for each profile\n",
    "med_xexpb1b2_med_best_par_list = []\n",
    "med_xexpb1b2_av_best_par_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the marginal plots for each detection\n",
    "for d in range(len(detections)):\n",
    "    # Path to detection folder\n",
    "    dest = dirName+'detection_'+str(detections[d]['Detection'])+'/'\n",
    "    \n",
    "    # Load the parameters\n",
    "    params = json.load(open(dest+'med_xexpb1b2_params.json'))\n",
    "    n_params = len(params)\n",
    "    \n",
    "    # Create the analyzer object\n",
    "    an = pymultinest.Analyzer(n_params = n_params, outputfiles_basename = dest+'med_xexpb1b2_detection_'+str(detections[d]['Detection']))\n",
    "    \n",
    "    # Get a dictionary containing information about the logZ and its errors,\n",
    "    # the individual modes and their parameters, quantiles of the parameter posteriors\n",
    "    #stats = an.get_stats()\n",
    "    stats = an.get_stats()\n",
    "    \n",
    "    # get the best fit (highest likelihood) point\n",
    "    bestfit_params_dict = an.get_best_fit()\n",
    "    bestfit_params = bestfit_params_dict.get('parameters')\n",
    "    \n",
    "    json.dump(stats, open(dest+'med_xexpb1b2_stats.json', 'w+'))\n",
    "    \n",
    "    # Create the marginal plot\n",
    "    p = pymultinest.PlotMarginal(an)\n",
    "    \n",
    "    values = an.get_equal_weighted_posterior()\n",
    "    assert n_params == len(stats['marginals'])\n",
    "    modes = stats['modes']\n",
    "    \n",
    "    # Dimensionality of the plot\n",
    "    dim2 = os.environ.get('D', '1' if n_params > 20 else '2') == '2'\n",
    "    nbins = 100 if n_params < 3 else 20\n",
    "    \n",
    "    # Set up grid layout\n",
    "    params_count2 = [0, 1, 2, 3, 4, 5, 6] # Grid for j\n",
    "    params_count_indx = 0\n",
    "    \n",
    "    if dim2:\n",
    "        plt.figure(figsize=(27*n_params, 27*n_params))\n",
    "        #for i in range(n_params):\n",
    "        for i in range(1, n_params+1, 1):\n",
    "            stepsizes = [0.1, 0.35, 0.35, 10, 10, 50, 4e-8, 0.4]\n",
    "            axis_formatters = ['%0.1f', '%0.1f', '%0.1f', '%d', '%d', '%d', '%.1e', '%0.1f']\n",
    "            \n",
    "            plt.subplot(n_params, n_params, (1 + 9*(i-1)))\n",
    "            plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "            \n",
    "            plt.xlabel(parameters[i-1], fontsize=160)\n",
    "\n",
    "            m = stats['marginals'][i-1]\n",
    "            \n",
    "            plt.xlim(m['5sigma'])\n",
    "            plt.xticks(rotation=40)\n",
    "\n",
    "            oldax = plt.gca()\n",
    "            x,w,patches = oldax.hist(values[:,i-1], bins=nbins, edgecolor='grey', color='grey', histtype='stepfilled', alpha=0.2)\n",
    "            oldax.set_ylim(0, x.max())\n",
    "            oldax.tick_params(axis='both', length=30, direction='in', top=True, right=True, pad=30)\n",
    "            oldax.tick_params(axis='x', labelbottom=False, labeltop=True)\n",
    "            \n",
    "            startax, endax = oldax.get_xlim()\n",
    "            oldax.xaxis.set_ticks(np.arange(startax, endax, stepsizes[i-1]))\n",
    "            oldax.xaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[i-1])) \n",
    "            oldax.xaxis.set_label_position('top')\n",
    "            \n",
    "            plt.setp(oldax.get_xticklabels(), fontsize=160)\n",
    "            plt.setp(oldax.get_yticklabels(), fontsize=160)\n",
    "            plt.setp(oldax.xaxis.get_majorticklabels(), rotation=40, fontsize=160)\n",
    "            plt.setp(oldax.yaxis.get_majorticklabels(), fontsize=160)\n",
    "\n",
    "            newax = plt.gcf().add_axes(oldax.get_position(), sharex=oldax, frameon=False)\n",
    "            newax.tick_params(axis='x', labelbottom=False, labeltop=True)\n",
    "            plt.setp(newax.get_xticklabels(), fontsize=160)\n",
    "            plt.setp(newax.get_yticklabels(), fontsize=160)\n",
    "            p.plot_marginal(i-1, ls='-', color='blue', linewidth=3)\n",
    "            newax.set_ylim(0, 1)\n",
    "\n",
    "            ylim = newax.get_ylim()\n",
    "            y = ylim[0] + 0.05*(ylim[1] - ylim[0])\n",
    "            center = m['median']\n",
    "            low1, high1 = m['1sigma']\n",
    "            #print(center, low1, high1)\n",
    "            newax.errorbar(x=center, y=y,\n",
    "                xerr=np.transpose([[center - low1, high1 - center]]), \n",
    "                color='blue', linewidth=2, marker='s')\n",
    "            oldax.set_yticks([])\n",
    "            #newax.set_yticks([])\n",
    "            oldax.tick_params(axis='both', length=30, direction='in', right=True)\n",
    "            newax.tick_params(axis='both', length=30, direction='in', right=True, pad=30)\n",
    "            newax.yaxis.set_label_position('right')\n",
    "            newax.xaxis.set_label_position('top')\n",
    "            newax.yaxis.set_ticks(np.arange(0.2, 1.2, 0.2))\n",
    "            newax.tick_params(axis='y', labelleft=False, labelright=True)\n",
    "            newax.set_ylabel(\"Probability\", fontsize=200, labelpad=30)\n",
    "            plt.setp(newax.xaxis.get_majorticklabels(), rotation=40, fontsize=160)\n",
    "            plt.setp(newax.yaxis.get_majorticklabels(), fontsize=160)\n",
    "            ylim = oldax.get_ylim()\n",
    "            newax.set_xlim(m['5sigma'])\n",
    "            oldax.set_xlim(m['5sigma'])\n",
    "            #plt.close()\n",
    "            \n",
    "            if i == n_params:\n",
    "                break\n",
    "                \n",
    "            #for j in range(i):\n",
    "            for j in range(params_count2[params_count_indx], n_params-1):\n",
    "                stepsizes = [0.05, 0.4, 0.35, 10, 20, 40, 4e-8, 0.4]\n",
    "                axis_formatters = ['%0.2f', '%0.1f', '%0.1f', '%d', '%d', '%d', '%.1e', '%0.1f']\n",
    "            \n",
    "                plt.subplot(n_params, n_params, ((n_params + i) + j*n_params))\n",
    "                p.plot_conditional(i-1, j+1, bins=20, cmap = pl.cm.gray_r)\n",
    "                for m in modes:\n",
    "                    plt.errorbar(x=bestfit_params[i-1], y=bestfit_params[j+1], xerr=m['sigma'][i-1], yerr=m['sigma'][j+1])\n",
    "                    \n",
    "                    ########\n",
    "                if j == 6 and i != 1:\n",
    "                    plt.xlabel(parameters[i-1], fontsize=200)\n",
    "                    \n",
    "                    # x axis\n",
    "                    startax, endax = plt.gca().get_xlim()\n",
    "                    plt.gca().xaxis.set_ticks(np.arange(startax, endax, stepsizes[i-1]))\n",
    "                    plt.gca().xaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[i-1])) \n",
    "        \n",
    "                    # y axis\n",
    "                    startay, enday = plt.gca().get_ylim()\n",
    "                    plt.gca().yaxis.set_ticks(np.arange(startay, enday, stepsizes[j+1]))\n",
    "                    plt.gca().yaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[j+1])) \n",
    "                    \n",
    "                    plt.gca().axes.tick_params(axis='x', labelbottom=True)\n",
    "                    plt.gca().axes.tick_params(axis='y', labelleft=False)\n",
    "                    plt.gca().axes.tick_params(axis='both', length=20, direction='in', top=True, right=True, pad=30)\n",
    "                elif i == 1 and j != 6:\n",
    "                    plt.ylabel(parameters[j+1], fontsize=200)\n",
    "                    # x axis\n",
    "                    startax, endax = plt.gca().get_xlim()\n",
    "                    plt.gca().xaxis.set_ticks(np.arange(startax, endax, stepsizes[i-1]))\n",
    "                    plt.gca().xaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[i-1])) \n",
    "        \n",
    "                    # y axis\n",
    "                    startay, enday = plt.gca().get_ylim()\n",
    "                    plt.gca().yaxis.set_ticks(np.arange(startay, enday, stepsizes[j+1]))\n",
    "                    plt.gca().yaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[j+1])) \n",
    "                    \n",
    "                    plt.gca().axes.tick_params(axis='x', labelbottom=False)\n",
    "                    plt.gca().axes.tick_params(axis='y', labelleft=True)\n",
    "                    plt.gca().axes.tick_params(axis='both', length=20, direction='in', top=True, right=True, pad=30)\n",
    "                elif i == 1 and j == 6:\n",
    "                    plt.xlabel(parameters[i-1], fontsize=200)\n",
    "                    plt.ylabel(parameters[j+1], fontsize=200)\n",
    "                    \n",
    "                    # x axis\n",
    "                    startax, endax = plt.gca().get_xlim()\n",
    "                    plt.gca().xaxis.set_ticks(np.arange(startax, endax, stepsizes[i-1]))\n",
    "                    plt.gca().xaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[i-1])) \n",
    "        \n",
    "                    # y axis\n",
    "                    startay, enday = plt.gca().get_ylim()\n",
    "                    plt.gca().yaxis.set_ticks(np.arange(startay, enday, stepsizes[j+1]))\n",
    "                    plt.gca().yaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[j+1])) \n",
    "                    \n",
    "                    plt.gca().axes.tick_params(axis='x', labelbottom=True)\n",
    "                    plt.gca().axes.tick_params(axis='y', labelleft=True)\n",
    "                    plt.gca().axes.tick_params(axis='both', length=20, direction='in', top=True, right=True, pad=30)\n",
    "                else:   \n",
    "                    # x axis\n",
    "                    startax, endax = plt.gca().get_xlim()\n",
    "                    plt.gca().xaxis.set_ticks(np.arange(startax, endax, stepsizes[i-1]))\n",
    "                    plt.gca().xaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[i-1])) \n",
    "    \n",
    "                    # y axis\n",
    "                    startay, enday = plt.gca().get_ylim()\n",
    "                    plt.gca().yaxis.set_ticks(np.arange(startay, enday, stepsizes[j+1]))\n",
    "                    plt.gca().yaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[j+1])) \n",
    "                        \n",
    "                    plt.gca().axes.tick_params(axis='both', length=30, direction='in', top=True, right=True, pad=30)\n",
    "                    plt.gca().axes.tick_params(axis='x', labelbottom=False)\n",
    "                    plt.gca().axes.tick_params(axis='y', labelleft=False)\n",
    "                plt.xticks(rotation=40)\n",
    "                plt.setp(plt.gca().get_xticklabels(), fontsize=160)\n",
    "                plt.setp(plt.gca().get_yticklabels(), fontsize=160)\n",
    "                #plt.savefig('cond_%s_%s.pdf' % (params[i], params[j]), bbox_tight=True)\n",
    "                #plt.close()\n",
    "                \n",
    "            params_count_indx += 1\n",
    "\n",
    "        plt.savefig(dest + 'med_xexpb1b2_marg'+str(detections[d]['Detection'])+'.pdf')\n",
    "        #plt.savefig(dest + 'marg'+str(detections[d]['Detection'])+'.png')\n",
    "        plt.close()\n",
    "    \n",
    "    '''\n",
    "    Storing the average parameter values\n",
    "    '''\n",
    "    # Open a text file to save the parameter results\n",
    "    av_results_txt = open(dest+'med_xexpb1b2_av_results_detection_'+str(detections[d]['Detection'])+'.txt', 'w+')\n",
    "\n",
    "    # List to store best parameters\n",
    "    av_best_par = []\n",
    "    \n",
    "    h = 0\n",
    "    for par in parameters:\n",
    "        av_results_txt.write('%s %.15f %.15f\\n' % (par, modes[0]['mean'][h], modes[0]['sigma'][h]))\n",
    "        av_best_par.append([modes[0]['mean'][h], modes[0]['sigma'][h]])\n",
    "        h+=1\n",
    "\n",
    "    av_results_txt.close()\n",
    "    med_xexpb1b2_av_best_par_list.append(av_best_par)\n",
    "    \n",
    "    '''\n",
    "    Choosing the median\n",
    "    '''\n",
    "    # Open a text file to save the parameter results_txt\n",
    "    med_results_txt = open(dest+'med_xexpb1b2_med_results_detection_'+str(detections[d]['Detection'])+'.txt', 'w+')\n",
    "    \n",
    "    # Write the marginal likelihood\n",
    "    med_results_txt.write('lnZ %.1f %.1f\\n'%(stats['global evidence'], stats['global evidence error']))\n",
    "    \n",
    "    # List to store best parameters\n",
    "    med_best_par = []\n",
    "    \n",
    "    # Write the parameters\n",
    "    for par, marg in zip(parameters, stats['marginals']):\n",
    "        # 1 sigma provides the lowest and highest estimates\n",
    "        lo, hi = marg['1sigma']\n",
    "        sigma = (hi - lo) / 2 # Calculate the error\n",
    "        \n",
    "        med = marg['median']\n",
    "        \n",
    "        if sigma == 0:\n",
    "            j = 3\n",
    "        else:\n",
    "            j = max(0, int(-np.floor(np.log10(sigma))) + 1)\n",
    "            \n",
    "        # Create the string to write    \n",
    "        fmt = '%%.%df' % j\n",
    "        fmts = '\\t'.join(['%-3s' + fmt + \" +- \" + fmt +'\\n'])\n",
    "        \n",
    "        med_results_txt.write('%s %.15f %.15f\\n' % (par, med, sigma))\n",
    "        \n",
    "        # Save the value and error for this parameter\n",
    "        med_best_par.append([med, sigma])\n",
    "    \n",
    "    med_results_txt.close()\n",
    "    med_xexpb1b2_med_best_par_list.append(med_best_par)\n",
    "    \n",
    "    '''\n",
    "    Model and integrated flux\n",
    "    '''\n",
    "    # The busy function with the best parameter\n",
    "    modelx = np.linspace(min(all_vel[d]), max(all_vel[d]), 1000)\n",
    "    modely = Bmodelx(modelx, med_best_par[0][0], med_best_par[1][0], med_best_par[2][0], med_best_par[3][0], \n",
    "                            med_best_par[4][0], med_best_par[5][0], med_best_par[6][0], med_best_par[7][0])\n",
    "    \n",
    "    # Integrated flux of data\n",
    "    Sdv_data = all_sdv[d]\n",
    "    Sdv_data_err = all_sdv_err[d]\n",
    "    \n",
    "    # Integrated flux of model\n",
    "    dvmodel = np.average(np.diff(modelx))\n",
    "    Sdv_model = np.sum(modely*dvmodel)*all_max_flux[d]\n",
    "    \n",
    "    '''\n",
    "    Plotting the median and mean parameters\n",
    "    '''\n",
    "    pl.figure(figsize=(15,7)) \n",
    "    pl.step(all_vel[d], all_flux[d], 'k', where='mid')\n",
    "    pl.errorbar(all_vel[d], all_flux[d], yerr=all_flux_err[d], fmt='', marker=None, ls='none', color='k')\n",
    "    pl.plot(modelx, modely, 'r-')\n",
    "#     pl.plot(modelx, Bmodelx(modelx, av_best_par[0][0], av_best_par[1][0], av_best_par[2][0], av_best_par[3][0], \n",
    "#                             av_best_par[4][0], av_best_par[5][0], av_best_par[6][0], av_best_par[7][0]), 'b-', \n",
    "#             alpha=0.5, label=r'Mean W$_{50}$ = %.2f $\\pm$ %.2f km/s'%(2*av_best_par[3][0], 2*av_best_par[3][1]))\n",
    "    pl.xlabel(r'Velocity [km s$^{-1}$]', fontsize=28)\n",
    "    pl.ylabel('Normalized Flux Density', fontsize=28)\n",
    "    pl.gca().tick_params(axis='both', labelsize=28)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Axes parameters\n",
    "    pl.gca().xaxis.set_minor_locator(AutoMinorLocator())\n",
    "    pl.gca().yaxis.set_minor_locator(AutoMinorLocator())\n",
    "    pl.gca().tick_params(axis='both', which='major', direction='in', length=10, top=True, right=True)\n",
    "    pl.gca().tick_params(axis='both', which='minor', direction='in', length=5, top=True, right=True)\n",
    "    #pl.legend(loc='upper right', fontsize=17)\n",
    "    \n",
    "    # Anchored text\n",
    "    textstr = '\\n'.join((\n",
    "    r'Med. W$_{50}$ = %.2f $\\pm$ %.2f km s$^{-1}$' % (2*med_best_par[3][0], 2*med_best_par[3][1], ),\n",
    "    r'$\\int S\\mathrm{dv}_\\mathrm{data}$ = %.3f $\\pm$ %.3f Jy km s$^{-1}$' % (Sdv_data, Sdv_data_err, ),\n",
    "    r'$\\int S\\mathrm{dv}_\\mathrm{model}$ = %.3f Jy km s$^{-1}$' % (Sdv_model, )))\n",
    "    pl.annotate(textstr, xy=(0.03, 0.7), xycoords='axes fraction', fontsize=17)\n",
    "    \n",
    "    pl.savefig(dest+'med_xexpb1b2_best_par'+str(detections[d]['Detection'])+'.png')\n",
    "    pl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fifth run with $b_1$, $b_2$, $x_e$, $x_p$ and $n$ fixed on the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store paramaters of fit with integrated flux that best matches data\n",
    "chi_best_fits = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store integrated fluxes\n",
    "sdv_models = []\n",
    "sdv_sampled_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = '/users/wanga/mightee/analysis/COSMOS_1330/masked_profiles_COSMOS_1330_output/'\n",
    "\n",
    "# Loop through each detection\n",
    "for i in range(len(detections)): \n",
    "    # Define the prior with a different paramater space for a\n",
    "    # Define the prior that transforms the unit cube into the parameter cube that is now in log space\n",
    "    # parameters are a, b1, b2, w, xe, xp, c, n\n",
    "    def prior(cube, ndim, nparams):\n",
    "        cube[0] = cube[0] # log-uniform prior for a between 0*1=0 and 1*1=1\n",
    "        cube[1] = med_xexpb1b2_med_best_par_list[i][1][0] # b1 fixed on medians of fourth run\n",
    "        cube[2] = med_xexpb1b2_med_best_par_list[i][2][0] # b2 fixed on medians of fourth run\n",
    "        cube[3] = 10**(cube[3]*3) # log-uniform prior for w between 10**(0*3)=1 and 10**(1*3)=1e3\n",
    "        cube[4] = med_xexpb1b2_med_best_par_list[i][4][0] # xe fixed on medians of fourth run\n",
    "        cube[5] = med_xexpb1b2_med_best_par_list[i][5][0] # xp fixed on medians of fourth run\n",
    "        cube[6] = 10**(-cube[6]*2 - 7) # log-uniform prior for c between 10**(-0*2-7)=1e-7 and 10**(-1*2-7)=1e-9\n",
    "        cube[7] = med_xexpb1b2_med_best_par_list[i][7][0] # n fixed on medians of fourth run\n",
    "    \n",
    "    # Create a directory for detection i's results\n",
    "    directory_i = dirName+'/detection_'+str(detections[i]['Detection'])+'/'\n",
    "    \n",
    "    vel = all_vel[i]\n",
    "    fluxdata = all_flux[i]\n",
    "    fluxerr = all_flux_err[i]\n",
    "    \n",
    "    noise = fluxerr\n",
    "    \n",
    "    # Number of dimensions our problem has\n",
    "    parameters = [r'$a$', r'$b_1$', r'$b_2$', r'$w$', r'$x_e$', r'$x_p$', r'$c$', r'$n$']\n",
    "    n_params = len(parameters)\n",
    "    \n",
    "    # Run PyMultiNest\n",
    "    pymultinest.run(loglike, prior, n_params, outputfiles_basename='med_b1b2xexpn_detection_'+str(detections[i]['Detection']), resume=False, verbose=True)\n",
    "    json.dump(parameters, open(directory_i+'/med_b1b2xexpn_params.json', 'w')) # Save the parameters\n",
    "    \n",
    "#     # plot the distribution of a posteriori possible models\n",
    "#     pl.figure(figsize=(15,7)) \n",
    "#     pl.step(vel, fluxdata, '-', color='black', where='mid')\n",
    "#     pl.errorbar(vel, fluxdata, yerr=fluxerr, fmt='', marker=None, ls='none', color='k')\n",
    "#     pl.xlabel('Velocity (km/s)', fontsize=20)\n",
    "#     pl.ylabel('Normalized Flux Density', fontsize=20)\n",
    "    \n",
    "    # Plot the distribution of a posteriori possible models\n",
    "    # Modelx is just a linear space of the velocities\n",
    "    modelx = np.linspace(min(vel), max(vel), 1000)\n",
    "\n",
    "    an = pymultinest.Analyzer(outputfiles_basename='med_b1b2xexpn_detection_'+str(detections[i]['Detection']), n_params = n_params)\n",
    "    \n",
    "    # Integrated flux of data\n",
    "    Sdv_data = all_sdv[i]\n",
    "    Sdv_data_err = all_sdv_err[i]\n",
    "\n",
    "    # Counter\n",
    "    fit_count = 0\n",
    "    \n",
    "    # List to store the integrated fluxes\n",
    "    det_sdv_fits = []\n",
    "    \n",
    "    # Previous sdv, dummy variable\n",
    "    # Want to store sdv of fit that best matches data\n",
    "    prev_sdv = 100\n",
    "    prev_sdv_44 = 100\n",
    "    \n",
    "    det_chi_fits = []\n",
    "    \n",
    "    # Loop through each possible model and plot it\n",
    "    for (a, b1, b2, w, xe, xp, c, n) in an.get_equal_weighted_posterior()[::100,:-1]:\n",
    "        # Store first three fits for the average\n",
    "        if fit_count < 4:\n",
    "            det_chi_fits.append([a, b1, b2, w, xe, xp, c, n])\n",
    "\n",
    "        modely = Bmodelx(modelx, a, b1, b2, w, xe, xp, c, n)\n",
    "        \n",
    "        # Sample the model at every 44 km/s to simulate the resolution of MIGHTEE 4k data\n",
    "        res = -1*np.average(np.diff(np.array(vel))) # Size of the channel\n",
    "        diff = modelx[1] - modelx[0] # Initial resolution of the linear space\n",
    "        dchan = int(res/diff) # Step size for the loop\n",
    "        obs_vel_44kms = [] # List to store the sampled velocity with minimum resolution of 44 km/s\n",
    "        obs_flux_44kms = [] # List to store corresponding fluxes\n",
    "\n",
    "        # Loop through the fluxes and velocities\n",
    "        for dat in range(0, len(modelx), dchan):\n",
    "            obs_vel_44kms.append(modelx[dat])\n",
    "            obs_flux_44kms.append(modely[dat])\n",
    "\n",
    "        # Integrated flux of model 44 km/s res\n",
    "        dvmodel_44 = np.average(np.diff(np.array(obs_vel_44kms)))#np.average(np.diff(modelx))\n",
    "        Sdv_model_44 = np.sum(np.array(obs_flux_44kms)*dvmodel_44)*all_max_flux[i]#np.sum(modely*dvmodel)*all_max_flux[d]\n",
    "        # Compare to data sdv\n",
    "        sdv_diff_44 = np.absolute(Sdv_data - Sdv_model_44)\n",
    "        if prev_sdv_44 > sdv_diff_44:\n",
    "            prev_sdv_44 = sdv_diff_44\n",
    "            sdv_count_44 = fit_count\n",
    "            final_sdv_44 = Sdv_model_44\n",
    "            #print('sdv_44 match', [a, b1, b2, w, xe, xp, c, n])\n",
    "        \n",
    "        # Integrated flux of model not sampled\n",
    "        dvmodel = np.average(np.diff(modelx))\n",
    "        Sdv_model = np.sum(modely*dvmodel)*all_max_flux[i]\n",
    "        # Compare to data sdv\n",
    "        sdv_diff = np.absolute(Sdv_data - Sdv_model)\n",
    "        if prev_sdv > sdv_diff:\n",
    "            prev_sdv = sdv_diff\n",
    "            sdv_count = fit_count\n",
    "            final_sdv = Sdv_model\n",
    "        \n",
    "        det_sdv_fits.append(Sdv_model_44)\n",
    "        #print(str(Sdv_data)+'+/-'+str(Sdv_data_err)+', '+str(Sdv_model_44)+', '+str(Sdv_model))\n",
    "\n",
    "#         # Calculate the chi squared per dof\n",
    "#         O = fluxdata\n",
    "#         C = Bmodelx(vel, a, b1, b2, w, xe, xp, c, n)\n",
    "#         chi_sqr = np.sum(pow(O - C,2))\n",
    "#         print(chi_sqr)\n",
    "\n",
    "        fit_count += 1\n",
    "\n",
    "    # Store averages in list\n",
    "    chi_best_fits.append([np.average(np.array([i[0] for i in det_chi_fits])),\n",
    "                         np.average(np.array([i[1] for i in det_chi_fits])),\n",
    "                         np.average(np.array([i[2] for i in det_chi_fits])),\n",
    "                         np.average(np.array([i[3] for i in det_chi_fits])),\n",
    "                         np.average(np.array([i[4] for i in det_chi_fits])),\n",
    "                         np.average(np.array([i[5] for i in det_chi_fits])),\n",
    "                         np.average(np.array([i[6] for i in det_chi_fits])),\n",
    "                         np.average(np.array([i[7] for i in det_chi_fits]))])\n",
    "\n",
    "    # Counter variable\n",
    "    count2 = 0\n",
    "    \n",
    "    # Plot the posteriors\n",
    "    pl.figure(figsize=(15,7)) \n",
    "    pl.step(vel, fluxdata, '-', color='black', where='mid')\n",
    "    pl.errorbar(vel, fluxdata, yerr=fluxerr, fmt='', marker=None, ls='none', color='k')\n",
    "    pl.xlabel(r'Velocity [km s$^{-1}$]', fontsize=28)\n",
    "    pl.ylabel('Normalized Flux Density', fontsize=28)\n",
    "    pl.gca().tick_params(axis='both', labelsize=28)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Axes parameters\n",
    "    pl.gca().xaxis.set_minor_locator(AutoMinorLocator())\n",
    "    pl.gca().yaxis.set_minor_locator(AutoMinorLocator())\n",
    "    pl.gca().tick_params(axis='both', which='major', direction='in', length=10, top=True, right=True)\n",
    "    pl.gca().tick_params(axis='both', which='minor', direction='in', length=5, top=True, right=True)\n",
    "    \n",
    "    for (a, b1, b2, w, xe, xp, c, n) in an.get_equal_weighted_posterior()[::100,:-1]:\n",
    "        modely = Bmodelx(modelx, a, b1, b2, w, xe, xp, c, n)\n",
    "        \n",
    "        # Fit with sdv matching data\n",
    "        if count2 == sdv_count:\n",
    "            pl.plot(modelx, modely, '-', color='blue', alpha=0.6, label=r'$\\int S\\mathrm{dv}$ match from non-sampled fit')\n",
    "            sdv_models.append([a, b1, b2, w, xe, xp, c, n, final_sdv])\n",
    "        \n",
    "        if count2 == sdv_count_44:\n",
    "            pl.plot(modelx, modely, '-', color='green', alpha=0.6, label=r'$\\int S\\mathrm{dv}$ match from sampled fit')\n",
    "            sdv_sampled_models.append([a, b1, b2, w, xe, xp, c, n, final_sdv_44])\n",
    "            #print('sdv_44 match post', [a, b1, b2, w, xe, xp, c, n])\n",
    "            \n",
    "        else:\n",
    "            pl.plot(modelx, modely, '-', color='red', alpha=0.2)\n",
    "        \n",
    "        count2 += 1\n",
    "        \n",
    "    pl.legend(loc='upper left', frameon=False, fontsize=15)\n",
    "    pl.savefig(directory_i+'med_b1b2xexpn_posterior'+str(detections[i]['Detection'])+'.png')\n",
    "    pl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving the output of PyMultiNest into the relevant directories. May need to run this cell twice if errors arise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = '/users/wanga/mightee/analysis/COSMOS_1330/'\n",
    "\n",
    "# Read in all the files in the directory\n",
    "files = os.listdir(source)\n",
    "\n",
    "# Detections with two digit numbers confuse python so sort detections in reverse order\n",
    "rev_det = [detections[i]['Detection'] for i in range(len(detections))][::-1]\n",
    "\n",
    "# Loop through each detection\n",
    "for i in rev_det:\n",
    "    # Path to detection folder\n",
    "    dest = dirName+'detection_'+str(i) \n",
    "    \n",
    "    # Loop through all the files\n",
    "    for file in files:\n",
    "        if (file.startswith('med_b1b2xexpn_detection_'+str(i))):\n",
    "            shutil.move(file, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store maximum likelihood best parameters\n",
    "max_likelihood_list = []\n",
    "\n",
    "# List to store median and average parameters for each profile\n",
    "med_b1b2xexpn_med_best_par_list = []\n",
    "med_b1b2xexpn_av_best_par_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the marginal plots for each detection\n",
    "for d in range(len(detections)):\n",
    "    # Path to detection folder\n",
    "    dest = dirName+'detection_'+str(detections[d]['Detection'])+'/'\n",
    "    \n",
    "    # Load the parameters\n",
    "    params = json.load(open(dest+'med_b1b2xexpn_params.json'))\n",
    "    n_params = len(params)\n",
    "    \n",
    "    # Create the analyzer object\n",
    "    an = pymultinest.Analyzer(n_params = n_params, outputfiles_basename = dest+'med_b1b2xexpn_detection_'+str(detections[d]['Detection']))\n",
    "    \n",
    "    # Get a dictionary containing information about the logZ and its errors,\n",
    "    # the individual modes and their parameters, quantiles of the parameter posteriors\n",
    "    #stats = an.get_stats()\n",
    "    stats = an.get_stats()\n",
    "    \n",
    "    # get the best fit (highest likelihood) point\n",
    "    bestfit_params_dict = an.get_best_fit()\n",
    "    bestfit_params = bestfit_params_dict.get('parameters')\n",
    "    \n",
    "    json.dump(stats, open(dest+'med_b1b2xexpn_stats.json', 'w+'))\n",
    "    \n",
    "    # Create the marginal plot\n",
    "    p = pymultinest.PlotMarginal(an)\n",
    "    \n",
    "    values = an.get_equal_weighted_posterior()\n",
    "    assert n_params == len(stats['marginals'])\n",
    "    modes = stats['modes']\n",
    "    \n",
    "    # Dimensionality of the plot\n",
    "    dim2 = os.environ.get('D', '1' if n_params > 20 else '2') == '2'\n",
    "    nbins = 100 if n_params < 3 else 20\n",
    "    \n",
    "    # Set up grid layout\n",
    "    params_count2 = [0, 1, 2, 3, 4, 5, 6] # Grid for j\n",
    "    params_count_indx = 0\n",
    "    \n",
    "    if dim2:\n",
    "        plt.figure(figsize=(27*n_params, 27*n_params))\n",
    "        #for i in range(n_params):\n",
    "        for i in range(1, n_params+1, 1):\n",
    "            stepsizes = [0.1, 0.35, 0.35, 10, 10, 50, 4e-8, 0.4]\n",
    "            axis_formatters = ['%0.1f', '%0.1f', '%0.1f', '%d', '%d', '%d', '%.1e', '%0.1f']\n",
    "            \n",
    "            plt.subplot(n_params, n_params, (1 + 9*(i-1)))\n",
    "            plt.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "            \n",
    "            plt.xlabel(parameters[i-1], fontsize=160)\n",
    "\n",
    "            m = stats['marginals'][i-1]\n",
    "            \n",
    "            plt.xlim(m['5sigma'])\n",
    "            plt.xticks(rotation=40)\n",
    "\n",
    "            oldax = plt.gca()\n",
    "            x,w,patches = oldax.hist(values[:,i-1], bins=nbins, edgecolor='grey', color='grey', histtype='stepfilled', alpha=0.2)\n",
    "            oldax.set_ylim(0, x.max())\n",
    "            oldax.tick_params(axis='both', length=30, direction='in', top=True, right=True, pad=30)\n",
    "            oldax.tick_params(axis='x', labelbottom=False, labeltop=True)\n",
    "            \n",
    "            startax, endax = oldax.get_xlim()\n",
    "            oldax.xaxis.set_ticks(np.arange(startax, endax, stepsizes[i-1]))\n",
    "            oldax.xaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[i-1])) \n",
    "            oldax.xaxis.set_label_position('top')\n",
    "            \n",
    "            plt.setp(oldax.get_xticklabels(), fontsize=160)\n",
    "            plt.setp(oldax.get_yticklabels(), fontsize=160)\n",
    "            plt.setp(oldax.xaxis.get_majorticklabels(), rotation=40, fontsize=160)\n",
    "            plt.setp(oldax.yaxis.get_majorticklabels(), fontsize=160)\n",
    "\n",
    "            newax = plt.gcf().add_axes(oldax.get_position(), sharex=oldax, frameon=False)\n",
    "            newax.tick_params(axis='x', labelbottom=False, labeltop=True)\n",
    "            plt.setp(newax.get_xticklabels(), fontsize=160)\n",
    "            plt.setp(newax.get_yticklabels(), fontsize=160)\n",
    "            p.plot_marginal(i-1, ls='-', color='blue', linewidth=3)\n",
    "            newax.set_ylim(0, 1)\n",
    "\n",
    "            ylim = newax.get_ylim()\n",
    "            y = ylim[0] + 0.05*(ylim[1] - ylim[0])\n",
    "            center = m['median']\n",
    "            low1, high1 = m['1sigma']\n",
    "            #print(center, low1, high1)\n",
    "            newax.errorbar(x=center, y=y,\n",
    "                xerr=np.transpose([[center - low1, high1 - center]]), \n",
    "                color='blue', linewidth=2, marker='s')\n",
    "            oldax.set_yticks([])\n",
    "            #newax.set_yticks([])\n",
    "            oldax.tick_params(axis='both', length=30, direction='in', right=True)\n",
    "            newax.tick_params(axis='both', length=30, direction='in', right=True, pad=30)\n",
    "            newax.yaxis.set_label_position('right')\n",
    "            newax.xaxis.set_label_position('top')\n",
    "            newax.yaxis.set_ticks(np.arange(0.2, 1.2, 0.2))\n",
    "            newax.tick_params(axis='y', labelleft=False, labelright=True)\n",
    "            newax.set_ylabel(\"Probability\", fontsize=200, labelpad=30)\n",
    "            plt.setp(newax.xaxis.get_majorticklabels(), rotation=40, fontsize=160)\n",
    "            plt.setp(newax.yaxis.get_majorticklabels(), fontsize=160)\n",
    "            ylim = oldax.get_ylim()\n",
    "            newax.set_xlim(m['5sigma'])\n",
    "            oldax.set_xlim(m['5sigma'])\n",
    "            #plt.close()\n",
    "            \n",
    "            if i == n_params:\n",
    "                break\n",
    "                \n",
    "            #for j in range(i):\n",
    "            for j in range(params_count2[params_count_indx], n_params-1):\n",
    "                stepsizes = [0.05, 0.4, 0.35, 10, 20, 40, 4e-8, 0.4]\n",
    "                axis_formatters = ['%0.2f', '%0.1f', '%0.1f', '%d', '%d', '%d', '%.1e', '%0.1f']\n",
    "            \n",
    "                plt.subplot(n_params, n_params, ((n_params + i) + j*n_params))\n",
    "                p.plot_conditional(i-1, j+1, bins=20, cmap = pl.cm.gray_r)\n",
    "                for m in modes:\n",
    "                    plt.errorbar(x=bestfit_params[i-1], y=bestfit_params[j+1], xerr=m['sigma'][i-1], yerr=m['sigma'][j+1])\n",
    "                    \n",
    "                    ########\n",
    "                if j == 6 and i != 1:\n",
    "                    plt.xlabel(parameters[i-1], fontsize=200)\n",
    "                    \n",
    "                    # x axis\n",
    "                    startax, endax = plt.gca().get_xlim()\n",
    "                    plt.gca().xaxis.set_ticks(np.arange(startax, endax, stepsizes[i-1]))\n",
    "                    plt.gca().xaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[i-1])) \n",
    "        \n",
    "                    # y axis\n",
    "                    startay, enday = plt.gca().get_ylim()\n",
    "                    plt.gca().yaxis.set_ticks(np.arange(startay, enday, stepsizes[j+1]))\n",
    "                    plt.gca().yaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[j+1])) \n",
    "                    \n",
    "                    plt.gca().axes.tick_params(axis='x', labelbottom=True)\n",
    "                    plt.gca().axes.tick_params(axis='y', labelleft=False)\n",
    "                    plt.gca().axes.tick_params(axis='both', length=20, direction='in', top=True, right=True, pad=30)\n",
    "                elif i == 1 and j != 6:\n",
    "                    plt.ylabel(parameters[j+1], fontsize=200)\n",
    "                    # x axis\n",
    "                    startax, endax = plt.gca().get_xlim()\n",
    "                    plt.gca().xaxis.set_ticks(np.arange(startax, endax, stepsizes[i-1]))\n",
    "                    plt.gca().xaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[i-1])) \n",
    "        \n",
    "                    # y axis\n",
    "                    startay, enday = plt.gca().get_ylim()\n",
    "                    plt.gca().yaxis.set_ticks(np.arange(startay, enday, stepsizes[j+1]))\n",
    "                    plt.gca().yaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[j+1])) \n",
    "                    \n",
    "                    plt.gca().axes.tick_params(axis='x', labelbottom=False)\n",
    "                    plt.gca().axes.tick_params(axis='y', labelleft=True)\n",
    "                    plt.gca().axes.tick_params(axis='both', length=20, direction='in', top=True, right=True, pad=30)\n",
    "                elif i == 1 and j == 6:\n",
    "                    plt.xlabel(parameters[i-1], fontsize=200)\n",
    "                    plt.ylabel(parameters[j+1], fontsize=200)\n",
    "                    \n",
    "                    # x axis\n",
    "                    startax, endax = plt.gca().get_xlim()\n",
    "                    plt.gca().xaxis.set_ticks(np.arange(startax, endax, stepsizes[i-1]))\n",
    "                    plt.gca().xaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[i-1])) \n",
    "        \n",
    "                    # y axis\n",
    "                    startay, enday = plt.gca().get_ylim()\n",
    "                    plt.gca().yaxis.set_ticks(np.arange(startay, enday, stepsizes[j+1]))\n",
    "                    plt.gca().yaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[j+1])) \n",
    "                    \n",
    "                    plt.gca().axes.tick_params(axis='x', labelbottom=True)\n",
    "                    plt.gca().axes.tick_params(axis='y', labelleft=True)\n",
    "                    plt.gca().axes.tick_params(axis='both', length=20, direction='in', top=True, right=True, pad=30)\n",
    "                else:   \n",
    "                    # x axis\n",
    "                    startax, endax = plt.gca().get_xlim()\n",
    "                    plt.gca().xaxis.set_ticks(np.arange(startax, endax, stepsizes[i-1]))\n",
    "                    plt.gca().xaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[i-1])) \n",
    "    \n",
    "                    # y axis\n",
    "                    startay, enday = plt.gca().get_ylim()\n",
    "                    plt.gca().yaxis.set_ticks(np.arange(startay, enday, stepsizes[j+1]))\n",
    "                    plt.gca().yaxis.set_major_formatter(mtick.FormatStrFormatter(axis_formatters[j+1])) \n",
    "                        \n",
    "                    plt.gca().axes.tick_params(axis='both', length=30, direction='in', top=True, right=True, pad=30)\n",
    "                    plt.gca().axes.tick_params(axis='x', labelbottom=False)\n",
    "                    plt.gca().axes.tick_params(axis='y', labelleft=False)\n",
    "                plt.xticks(rotation=40)\n",
    "                plt.setp(plt.gca().get_xticklabels(), fontsize=160)\n",
    "                plt.setp(plt.gca().get_yticklabels(), fontsize=160)\n",
    "                #plt.savefig('cond_%s_%s.pdf' % (params[i], params[j]), bbox_tight=True)\n",
    "                #plt.close()\n",
    "                \n",
    "            params_count_indx += 1\n",
    "\n",
    "        plt.savefig(dest + 'med_b1b2xexpn_marg'+str(detections[d]['Detection'])+'.pdf')\n",
    "        #plt.savefig(dest + 'marg'+str(detections[d]['Detection'])+'.png')\n",
    "        plt.close()\n",
    "        \n",
    "    '''\n",
    "    Storing the best fits based on the maximum likelihood\n",
    "    '''\n",
    "    # Open a text file to save the parameter results\n",
    "    maxlik_results_txt = open(dest+'med_b1b2xexpn_maxlik_results_detection_'+str(detections[d]['Detection'])+'.txt', 'w+')\n",
    "    \n",
    "    h = 0\n",
    "    for par in parameters:\n",
    "        maxlik_results_txt.write('%s %.15f %.15f\\n' % (par, bestfit_params[h], 0))\n",
    "        h+=1\n",
    "\n",
    "    maxlik_results_txt.close()\n",
    "    max_likelihood_list.append(bestfit_params)\n",
    "        \n",
    "    '''\n",
    "    Storing the best fits based on the integrated fluxes\n",
    "    '''\n",
    "    # Open a text file to save the parameter results\n",
    "    sdv_results_txt = open(dest+'med_b1b2xexpn_sdv_results_detection_'+str(detections[d]['Detection'])+'.txt', 'w+')\n",
    "    \n",
    "    h = 0\n",
    "    for par in parameters:\n",
    "        sdv_results_txt.write('%s %.15f %.15f %.15f %.15f\\n' % (par, sdv_models[d][h], 0, sdv_sampled_models[d][h], 0))\n",
    "        h+=1\n",
    "    sdv_results_txt.write('sdv %.15f %.15f %.15f %.15f\\n' % (sdv_models[d][8], 0, sdv_sampled_models[d][8], 0))\n",
    "    sdv_results_txt.close()\n",
    "    \n",
    "    '''\n",
    "    Storing the average parameter values\n",
    "    '''\n",
    "    # Open a text file to save the parameter results\n",
    "    av_results_txt = open(dest+'med_b1b2xexpn_av_results_detection_'+str(detections[d]['Detection'])+'.txt', 'w+')\n",
    "\n",
    "    # List to store best parameters\n",
    "    av_best_par = []\n",
    "    \n",
    "    h = 0\n",
    "    for par in parameters:\n",
    "#         av_results_txt.write('%s %.15f %.15f\\n' % (par, modes[0]['mean'][h], modes[0]['sigma'][h]))\n",
    "#         av_best_par.append([modes[0]['mean'][h], modes[0]['sigma'][h]])\n",
    "        av_results_txt.write('%s %.15f %.15f\\n' % (par, chi_best_fits[d][h], 0))\n",
    "        av_best_par.append([chi_best_fits[d][h], 0])\n",
    "        h+=1\n",
    "\n",
    "    av_results_txt.close()\n",
    "    med_b1b2xexpn_av_best_par_list.append(av_best_par)\n",
    "    \n",
    "    '''\n",
    "    Choosing the median\n",
    "    '''\n",
    "    # Open a text file to save the parameter results_txt\n",
    "    med_results_txt = open(dest+'med_b1b2xexpn_med_results_detection_'+str(detections[d]['Detection'])+'.txt', 'w+')\n",
    "    \n",
    "    # Write the marginal likelihood\n",
    "    med_results_txt.write('lnZ %.1f %.1f\\n'%(stats['global evidence'], stats['global evidence error']))\n",
    "    \n",
    "    # List to store best parameters\n",
    "    med_best_par = []\n",
    "    \n",
    "    # Write the parameters\n",
    "    for par, marg in zip(parameters, stats['marginals']):\n",
    "        # 1 sigma provides the lowest and highest estimates\n",
    "        lo, hi = marg['1sigma']\n",
    "        sigma = (hi - lo) / 2 # Calculate the error\n",
    "        \n",
    "        med = marg['median']\n",
    "        \n",
    "        if sigma == 0:\n",
    "            j = 3\n",
    "        else:\n",
    "            j = max(0, int(-np.floor(np.log10(sigma))) + 1)\n",
    "            \n",
    "        # Create the string to write    \n",
    "        fmt = '%%.%df' % j\n",
    "        fmts = '\\t'.join(['%-3s' + fmt + \" +- \" + fmt +'\\n'])\n",
    "        \n",
    "        med_results_txt.write('%s %.15f %.15f\\n' % (par, med, sigma))\n",
    "        \n",
    "        # Save the value and error for this parameter\n",
    "        med_best_par.append([med, sigma])\n",
    "    \n",
    "    med_results_txt.close()\n",
    "    med_b1b2xexpn_med_best_par_list.append(med_best_par)\n",
    "    \n",
    "    '''\n",
    "    Model x values\n",
    "    '''\n",
    "    # The busy function with the best parameter\n",
    "    modelx = np.linspace(min(all_vel[d]), max(all_vel[d]), 1000)\n",
    "    dvmodel = np.average(np.diff(np.array(modelx)))\n",
    "    \n",
    "    '''\n",
    "    Plotting \n",
    "    '''\n",
    "    pl.figure(figsize=(15,7)) \n",
    "    # Data\n",
    "    # Integrated flux of data\n",
    "    Sdv_data = all_sdv[d]\n",
    "    Sdv_data_err = all_sdv_err[d]\n",
    "    pl.step(all_vel[d], all_flux[d], 'k', where='mid', label=r'$\\int S\\mathrm{dv}_\\mathrm{data}$ = %.3f $\\pm$ %.3f Jy km s$^{-1}$' % (Sdv_data, Sdv_data_err))\n",
    "    pl.errorbar(all_vel[d], all_flux[d], yerr=all_flux_err[d], fmt='', marker=None, ls='none', color='k')\n",
    "    \n",
    "    # Maximum likelihood\n",
    "    modely_maxlik = Bmodelx(modelx, bestfit_params[0], bestfit_params[1], bestfit_params[2], bestfit_params[3], \n",
    "                            bestfit_params[4], bestfit_params[5], bestfit_params[6], bestfit_params[7])\n",
    "    # Integrated flux of maximum likelihood model\n",
    "    Sdv_model_maxlik = np.sum(modely_maxlik*dvmodel)*all_max_flux[d]\n",
    "    pl.plot(modelx, modely_maxlik, '--', color='fuchsia', alpha=0.7, label=r'$\\int S\\mathrm{dv}_\\mathrm{max. \\ likelihood}$ = %.3f Jy km s$^{-1}$' % (Sdv_model_maxlik))\n",
    "    \n",
    "    # Median\n",
    "    modely_med = Bmodelx(modelx, med_best_par[0][0], med_best_par[1][0], med_best_par[2][0], med_best_par[3][0], \n",
    "                            med_best_par[4][0], med_best_par[5][0], med_best_par[6][0], med_best_par[7][0])\n",
    "    # Integrated flux of median model\n",
    "    Sdv_model_med = np.sum(modely_med*dvmodel)*all_max_flux[d]\n",
    "    pl.plot(modelx, modely_med, 'b-', alpha=0.7, label=r'$\\int S\\mathrm{dv}_\\mathrm{med}$ = %.3f Jy km s$^{-1}$' % (Sdv_model_med))\n",
    "    \n",
    "    # Mean        \n",
    "    modely_mean = Bmodelx(modelx, av_best_par[0][0], av_best_par[1][0], av_best_par[2][0], av_best_par[3][0], \n",
    "                            av_best_par[4][0], av_best_par[5][0], av_best_par[6][0], med_best_par[7][0])\n",
    "    # Integrated flux of mean model\n",
    "    Sdv_model_mean = np.sum(modely_mean*dvmodel)*all_max_flux[d]\n",
    "    pl.plot(modelx, modely_mean, 'c--', alpha=0.7, label=r'$\\int S\\mathrm{dv}_\\mathrm{mean}$ = %.3f Jy km s$^{-1}$' % (Sdv_model_mean)) \n",
    "            \n",
    "    # Non sampled fit with closest matching Sdv   \n",
    "    modely_sdv = Bmodelx(modelx, sdv_models[d][0], sdv_models[d][1], sdv_models[d][2], sdv_models[d][3], \n",
    "                            sdv_models[d][4], sdv_models[d][5], sdv_models[d][6], sdv_models[d][7])\n",
    "    pl.plot(modelx, modely_sdv, 'r-', alpha=0.7, label=r'$\\int S\\mathrm{dv}_\\mathrm{non-sampled \\ fit}$ = %.3f Jy km s$^{-1}$' % (sdv_models[d][8]))  \n",
    "    \n",
    "    # Sampled fit with closest matching Sdv\n",
    "    modely_sampled_sdv = Bmodelx(modelx, sdv_sampled_models[d][0], sdv_sampled_models[d][1], sdv_sampled_models[d][2], sdv_sampled_models[d][3], \n",
    "                            sdv_sampled_models[d][4], sdv_sampled_models[d][5], sdv_sampled_models[d][6], sdv_sampled_models[d][7])\n",
    "    pl.plot(modelx, modely_sampled_sdv, 'g-', alpha=0.7, label=r'$\\int S\\mathrm{dv}_\\mathrm{sampled \\ fit}$ = %.3f Jy km s$^{-1}$' % (sdv_sampled_models[d][8]))  \n",
    "            \n",
    "    pl.xlabel(r'Velocity [km s$^{-1}$]', fontsize=28)\n",
    "    pl.ylabel('Normalized Flux Density', fontsize=28)\n",
    "    pl.gca().tick_params(axis='both', labelsize=28)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Axes parameters\n",
    "    pl.gca().xaxis.set_minor_locator(AutoMinorLocator())\n",
    "    pl.gca().yaxis.set_minor_locator(AutoMinorLocator())\n",
    "    pl.gca().tick_params(axis='both', which='major', direction='in', length=10, top=True, right=True)\n",
    "    pl.gca().tick_params(axis='both', which='minor', direction='in', length=5, top=True, right=True)\n",
    "    pl.legend(loc='upper left', fontsize=15, frameon=False)\n",
    "    \n",
    "    # Anchored text\n",
    "#     textstr = '\\n'.join((\n",
    "#     r'Av. W$_{50}$ = %.2f $\\pm$ %.2f km s$^{-1}$' % (2*av_best_par[3][0], 2*av_best_par[3][1], ),\n",
    "#     r'$\\int S\\mathrm{dv}_\\mathrm{data}$ = %.3f $\\pm$ %.3f Jy km s$^{-1}$' % (Sdv_data, Sdv_data_err, ),\n",
    "#     r'$\\int S\\mathrm{dv}_\\mathrm{model}$ = %.3f Jy km s$^{-1}$' % (Sdv_model, )))\n",
    "#     pl.annotate(textstr, xy=(0.03, 0.7), xycoords='axes fraction', fontsize=17)\n",
    "    \n",
    "    pl.tight_layout()\n",
    "    \n",
    "    pl.savefig(dest+'med_b1b2xexpn_best_par'+str(detections[d]['Detection'])+'.png')\n",
    "    pl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyMultiNest",
   "language": "python",
   "name": "pymultinest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
